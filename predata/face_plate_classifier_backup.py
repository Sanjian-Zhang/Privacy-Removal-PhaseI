#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨
ä½¿ç”¨RetinaFaceæ£€æµ‹æ­£è„¸ï¼Œä½¿ç”¨YOLOv8æ£€æµ‹è½¦ç‰Œ
è¦æ±‚: è‡³å°‘2å¼ æ­£è„¸ + è‡³å°‘1å¼ è½¦ç‰Œ
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm
import logging
import gc
from collections import defaultdict

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åº“"""
    missing_deps = []
    
    try:
        from retinaface import RetinaFace
        print("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    try:
        from ultralytics import YOLO
        print("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    try:
        import easyocr
        print("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        print("è¯·å®‰è£…ç¼ºå°‘çš„åº“:")
        for dep in missing_deps:
            print(f"  pip install {dep}")
        return False
    
    return True

# æ£€æŸ¥ä¾èµ–
if not check_dependencies():
    exit(1)

# æ­£å¼å¯¼å…¥
from retinaface import RetinaFace
from ultralytics import YOLO
import easyocr

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === ç›´æ¥åœ¨ä»£ç ä¸­è®¾ç½®å‚æ•° ===
# ç›®å½•é…ç½®
INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames23/output_unique'
OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames23/output_unique/classified_frames23'  # ä¿®æ”¹è¾“å‡ºè·¯å¾„åˆ°æ ¹ç›®å½•ä¸‹
PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'

# æ£€æµ‹è¦æ±‚
MIN_FRONTAL_FACES = 2
MIN_LICENSE_PLATES = 1
ALLOW_THREE_CLEAR_FACES = True  # å…è®¸3å¼ æ¸…æ™°äººè„¸æ›¿ä»£2å¼ æ­£è„¸
ALLOW_TEXT_RECOGNITION = True   # å…è®¸æ–‡å­—è¯†åˆ«æ›¿ä»£è½¦ç‰Œ

# æ£€æµ‹é˜ˆå€¼
YAW_ANGLE_THRESHOLD = 35.0
MIN_FACE_CONFIDENCE = 0.8
MIN_PLATE_CONFIDENCE = 0.5
MIN_FACE_SIZE = 60
MIN_PLATE_SIZE = 50
MIN_FACE_CLARITY_SCORE = 30.0  # æ¸…æ™°åº¦åˆ†æ•°é˜ˆå€¼
MAX_FACE_DISTANCE_RATIO = 0.3  # æœ€å¤§è·ç¦»æ¯”ä¾‹
FACE_AREA_THRESHOLD = 3600     # æœ€å°äººè„¸é¢ç§¯(åƒç´ Â²)
MIN_TEXT_CONFIDENCE = 0.5      # æ–‡å­—è¯†åˆ«æœ€å°ç½®ä¿¡åº¦
MIN_TEXT_LENGTH = 3            # æœ€å°æ–‡å­—é•¿åº¦

# å›¾åƒå¤„ç†å‚æ•°
MAX_IMAGE_SIZE = (1280, 720)
SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

# æ€§èƒ½å‚æ•°
VERBOSE_LOGGING = True
GC_FREQUENCY = 100
PROGRESS_UPDATE_FREQUENCY = 50

# è¾“å‡ºå­ç›®å½•
QUALIFIED_DIR = os.path.join(OUTPUT_BASE_DIR, "qualified")         # ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡(æ€»åˆ†>5)
NO_CONTENT_DIR = os.path.join(OUTPUT_BASE_DIR, "no_content")       # æ— ä»»ä½•æœ‰æ•ˆå†…å®¹
INSUFFICIENT_SCORE_DIR = os.path.join(OUTPUT_BASE_DIR, "insufficient_score")  # åˆ†æ•°ä¸å¤Ÿ
ANALYSIS_DIR = os.path.join(OUTPUT_BASE_DIR, "analysis")           # åˆ†æç»“æœ

class FacePlateClassifier:
    """æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        self.start_time = time.time()
        self.stats = {
            'qualified': 0,           # ç¬¦åˆæ¡ä»¶(æ€»åˆ†>5)
            'no_content': 0,          # æ— ä»»ä½•æœ‰æ•ˆå†…å®¹
            'insufficient_score': 0,  # åˆ†æ•°ä¸å¤Ÿ
            'failed': 0               # å¤„ç†å¤±è´¥
        }
        
        # è¯¦ç»†åˆ†æç»“æœ
        self.analysis_results = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_output_dirs()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        # åˆå§‹åŒ–OCR
        self._initialize_ocr()
        
        logger.info("ğŸš€ æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _create_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        dirs = [QUALIFIED_DIR, NO_CONTENT_DIR, INSUFFICIENT_SCORE_DIR, ANALYSIS_DIR]
        
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
            logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹"""
        try:
            # æµ‹è¯•RetinaFace
            logger.info("ğŸ” åˆå§‹åŒ–RetinaFaceæ¨¡å‹...")
            test_img = np.ones((100, 100, 3), dtype=np.uint8) * 128
            RetinaFace.detect_faces(test_img)
            logger.info("âœ… RetinaFaceæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹
            logger.info("ğŸš— åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
            if not os.path.exists(PLATE_MODEL_PATH):
                raise FileNotFoundError(f"è½¦ç‰Œæ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {PLATE_MODEL_PATH}")
            
            self.plate_model = YOLO(PLATE_MODEL_PATH)
            logger.info("âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _initialize_ocr(self):
        """åˆå§‹åŒ–OCRæ¨¡å‹"""
        try:
            if ALLOW_TEXT_RECOGNITION:
                logger.info("ğŸ“ åˆå§‹åŒ–EasyOCRæ¨¡å‹...")
                self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])  # æ”¯æŒä¸­æ–‡ç®€ä½“å’Œè‹±æ–‡
                logger.info("âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.ocr_reader = None
                logger.info("ğŸ“ æ–‡å­—è¯†åˆ«åŠŸèƒ½å·²ç¦ç”¨")
        except Exception as e:
            logger.error(f"âŒ OCRæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ocr_reader = None
    
    def calculate_face_clarity(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """
        è®¡ç®—äººè„¸åŒºåŸŸçš„æ¸…æ™°åº¦
        ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è®¡ç®—æ¸…æ™°åº¦åˆ†æ•°
        """
        try:
            x1, y1, x2, y2 = bbox
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            h, w = image.shape[:2]
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w, int(x2)), min(h, int(y2))
            
            if x2 <= x1 or y2 <= y1:
                return 0.0
            
            # æå–äººè„¸åŒºåŸŸ
            face_region = image[y1:y2, x1:x2]
            
            if face_region.size == 0:
                return 0.0
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(face_region.shape) == 3:
                gray_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_region
            
            # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è®¡ç®—æ¸…æ™°åº¦
            laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
            
            # é¢å¤–çš„æ¸…æ™°åº¦æŒ‡æ ‡ï¼šæ¢¯åº¦å¹…å€¼
            grad_x = cv2.Sobel(gray_face, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray_face, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            gradient_mean = np.mean(gradient_magnitude)
            
            # ç»¼åˆæ¸…æ™°åº¦åˆ†æ•° (æ‹‰æ™®æ‹‰æ–¯æ–¹å·® + æ¢¯åº¦å‡å€¼)
            clarity_score = laplacian_var + gradient_mean * 0.1
            
            return float(clarity_score)
            
        except Exception as e:
            logger.debug(f"æ¸…æ™°åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_face_distance_score(self, bbox: Tuple[int, int, int, int], img_size: Tuple[int, int]) -> float:
        """
        è®¡ç®—äººè„¸è·ç¦»åˆ†æ•°
        åŸºäºäººè„¸åœ¨å›¾åƒä¸­çš„å¤§å°ç›¸å¯¹äºå›¾åƒå¤§å°çš„æ¯”ä¾‹
        """
        try:
            x1, y1, x2, y2 = bbox
            face_width = x2 - x1
            face_height = y2 - y1
            face_area = face_width * face_height
            
            img_width, img_height = img_size
            img_area = img_width * img_height
            
            # è®¡ç®—äººè„¸é¢ç§¯å å›¾åƒé¢ç§¯çš„æ¯”ä¾‹
            area_ratio = face_area / img_area
            
            # è·ç¦»åˆ†æ•°ï¼šé¢ç§¯æ¯”ä¾‹è¶Šå¤§ï¼Œè·ç¦»è¶Šè¿‘ï¼Œåˆ†æ•°è¶Šé«˜
            distance_score = area_ratio
            
            return float(distance_score)
            
        except Exception as e:
            logger.debug(f"è·ç¦»åˆ†æ•°è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def is_face_clear_and_close(self, image: np.ndarray, bbox: Tuple[int, int, int, int], img_size: Tuple[int, int]) -> Tuple[bool, Dict]:
        """
        åˆ¤æ–­äººè„¸æ˜¯å¦æ¸…æ™°ä¸”è·ç¦»åˆé€‚
        """
        try:
            # è®¡ç®—æ¸…æ™°åº¦åˆ†æ•°
            clarity_score = self.calculate_face_clarity(image, bbox)
            
            # è®¡ç®—è·ç¦»åˆ†æ•°
            distance_score = self.calculate_face_distance_score(bbox, img_size)
            
            # è®¡ç®—äººè„¸é¢ç§¯
            x1, y1, x2, y2 = bbox
            face_area = (x2 - x1) * (y2 - y1)
            
            # åˆ¤æ–­æ¡ä»¶
            is_clear = clarity_score >= MIN_FACE_CLARITY_SCORE
            is_close = distance_score >= MAX_FACE_DISTANCE_RATIO
            is_large_enough = face_area >= FACE_AREA_THRESHOLD
            
            # ç»¼åˆåˆ¤æ–­
            is_good_quality = is_clear and (is_close or is_large_enough)
            
            quality_info = {
                'clarity_score': clarity_score,
                'distance_score': distance_score,
                'face_area': face_area,
                'is_clear': is_clear,
                'is_close': is_close,
                'is_large_enough': is_large_enough,
                'is_good_quality': is_good_quality
            }
            
            return is_good_quality, quality_info
            
        except Exception as e:
            logger.debug(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return False, {'error': str(e)}
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            # RetinaFaceå…³é”®ç‚¹ï¼šleft_eye, right_eye, nose, mouth_left, mouth_right
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            # è®¡ç®—çœ¼éƒ¨ä¸­å¿ƒ
            eye_center = (left_eye + right_eye) / 2
            
            # è®¡ç®—çœ¼éƒ¨å‘é‡
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:  # çœ¼éƒ¨å¤ªå°
                return 90.0  # è¿”å›å¤§è§’åº¦ï¼Œè¡¨ç¤ºä¸æ˜¯æ­£è„¸
            
            # è®¡ç®—é¼»å­ç›¸å¯¹äºçœ¼éƒ¨ä¸­å¿ƒçš„æ°´å¹³åç§»
            horizontal_offset = nose[0] - eye_center[0]
            
            # å½’ä¸€åŒ–åç§»é‡
            normalized_offset = horizontal_offset / eye_width
            
            # å°†åç§»é‡è½¬æ¢ä¸ºè§’åº¦ï¼ˆç»éªŒå…¬å¼ï¼‰
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0  # è¿”å›å¤§è§’åº¦
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            # RetinaFaceå…³é”®ç‚¹ï¼šleft_eye, right_eye, nose, mouth_left, mouth_right
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            # è®¡ç®—çœ¼éƒ¨ä¸­å¿ƒ
            eye_center = (left_eye + right_eye) / 2
            
            # è®¡ç®—çœ¼éƒ¨å‘é‡
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:  # çœ¼éƒ¨å¤ªå°
                return 90.0  # è¿”å›å¤§è§’åº¦ï¼Œè¡¨ç¤ºä¸æ˜¯æ­£è„¸
            
            # è®¡ç®—é¼»å­ç›¸å¯¹äºçœ¼éƒ¨ä¸­å¿ƒçš„æ°´å¹³åç§»
            horizontal_offset = nose[0] - eye_center[0]
            
            # å½’ä¸€åŒ–åç§»é‡
            normalized_offset = horizontal_offset / eye_width
            
            # å°†åç§»é‡è½¬æ¢ä¸ºè§’åº¦ï¼ˆç»éªŒå…¬å¼ï¼‰
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0  # è¿”å›å¤§è§’åº¦
    
    def detect_faces(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨RetinaFaceæ£€æµ‹æ­£è„¸ï¼Œæ·»åŠ æ¸…æ™°åº¦å’Œè·ç¦»è¿‡æ»¤"""
        try:
            # æ£€æµ‹äººè„¸
            detections = RetinaFace.detect_faces(image_path)
            
            if not isinstance(detections, dict) or len(detections) == 0:
                return 0, []
            
            # è¯»å–å›¾åƒè·å–å°ºå¯¸
            img = cv2.imread(image_path)
            if img is None:
                return 0, []
            
            img_height, img_width = img.shape[:2]
            img_size = (img_width, img_height)
            
            frontal_faces = []
            all_clear_faces = []  # æ‰€æœ‰æ¸…æ™°çš„äººè„¸ï¼ˆä¸é™è§’åº¦ï¼‰
            
            for face_key, face_data in detections.items():
                try:
                    # è·å–ç½®ä¿¡åº¦
                    confidence = face_data.get('score', 0.0)
                    if confidence < MIN_FACE_CONFIDENCE:
                        continue
                    
                    # è·å–é¢éƒ¨åŒºåŸŸå’Œå…³é”®ç‚¹
                    facial_area = face_data['facial_area']
                    landmarks = face_data.get('landmarks', {})
                    
                    if not landmarks:
                        continue
                    
                    # æ£€æŸ¥äººè„¸å¤§å°
                    x1, y1, x2, y2 = facial_area
                    face_width = x2 - x1
                    face_height = y2 - y1
                    
                    if min(face_width, face_height) < MIN_FACE_SIZE:
                        continue
                    
                    # æ£€æŸ¥äººè„¸æ¸…æ™°åº¦å’Œè·ç¦»
                    is_good_quality, quality_info = self.is_face_clear_and_close(img, facial_area, img_size)
                    
                    if not is_good_quality:
                        continue  # è·³è¿‡æ¨¡ç³Šæˆ–è¿œè·ç¦»çš„äººè„¸
                    
                    # è®¡ç®—yawè§’åº¦
                    yaw_angle = self.calculate_yaw_angle(landmarks)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ­£è„¸
                    is_frontal = yaw_angle <= YAW_ANGLE_THRESHOLD
                    
                    face_info = {
                        'confidence': confidence,
                        'yaw_angle': yaw_angle,
                        'is_frontal': is_frontal,
                        'facial_area': facial_area,
                        'face_size': (face_width, face_height),
                        'quality_info': quality_info
                    }
                    
                    # æ·»åŠ åˆ°æ¸…æ™°äººè„¸åˆ—è¡¨
                    all_clear_faces.append(face_info)
                    
                    # å¦‚æœæ˜¯æ­£è„¸ï¼Œæ·»åŠ åˆ°æ­£è„¸åˆ—è¡¨
                    if is_frontal:
                        frontal_faces.append(face_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æäººè„¸å¤±è´¥: {e}")
                    continue
            
            # å¦‚æœå¯ç”¨äº†"ä¸‰å¼ æ¸…æ™°äººè„¸ä¹Ÿç¬¦åˆè¦æ±‚"çš„é€‰é¡¹
            if ALLOW_THREE_CLEAR_FACES and len(all_clear_faces) >= 3 and len(frontal_faces) < MIN_FRONTAL_FACES:
                logger.debug(f"æ£€æµ‹åˆ°{len(all_clear_faces)}å¼ æ¸…æ™°äººè„¸ï¼Œæ»¡è¶³æ›¿ä»£è¦æ±‚")
                # è¿”å›æ¸…æ™°äººè„¸æ•°é‡ï¼Œä½†æ ‡è®°ä¸ºç¬¦åˆè¦æ±‚
                return len(all_clear_faces), all_clear_faces
            
            return len(frontal_faces), frontal_faces
            
        except Exception as e:
            logger.debug(f"äººè„¸æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_license_plates(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨YOLOæ£€æµ‹è½¦ç‰Œ"""
        try:
            # ä½¿ç”¨YOLOæ£€æµ‹
            results = self.plate_model(image_path, verbose=False)
            
            if not results or len(results) == 0:
                return 0, []
            
            result = results[0]  # è·å–ç¬¬ä¸€ä¸ªç»“æœ
            
            if result.boxes is None or len(result.boxes) == 0:
                return 0, []
            
            plates = []
            
            for box in result.boxes:
                try:
                    # è·å–ç½®ä¿¡åº¦å’Œè¾¹ç•Œæ¡†
                    confidence = float(box.conf[0])
                    if confidence < MIN_PLATE_CONFIDENCE:
                        continue
                    
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    plate_width = x2 - x1
                    plate_height = y2 - y1
                    
                    # æ£€æŸ¥è½¦ç‰Œå¤§å°
                    if min(plate_width, plate_height) < MIN_PLATE_SIZE:
                        continue
                    
                    plate_info = {
                        'confidence': confidence,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'plate_size': (float(plate_width), float(plate_height))
                    }
                    
                    plates.append(plate_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æè½¦ç‰Œå¤±è´¥: {e}")
                    continue
            
            return len(plates), plates
            
        except Exception as e:
            logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_text(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨OCRæ£€æµ‹å›¾åƒä¸­çš„æ–‡å­—"""
        try:
            if not ALLOW_TEXT_RECOGNITION or self.ocr_reader is None:
                return 0, []
            
            # è¯»å–å›¾åƒ
            img = cv2.imread(image_path)
            if img is None:
                return 0, []
            
            # ä½¿ç”¨OCRæ£€æµ‹æ–‡å­—
            results = self.ocr_reader.readtext(img)
            
            if not results:
                return 0, []
            
            valid_texts = []
            
            for bbox, text, confidence in results:
                try:
                    # è¿‡æ»¤ç½®ä¿¡åº¦å’Œæ–‡å­—é•¿åº¦
                    if confidence < MIN_TEXT_CONFIDENCE:
                        continue
                    
                    # æ¸…ç†æ–‡å­—å†…å®¹
                    cleaned_text = text.strip()
                    if len(cleaned_text) < MIN_TEXT_LENGTH:
                        continue
                    
                    # è¿‡æ»¤æ‰åªåŒ…å«ç¬¦å·çš„æ–‡å­—
                    if cleaned_text.replace(' ', '').replace('.', '').replace('-', '').replace('_', ''):
                        text_info = {
                            'text': cleaned_text,
                            'confidence': confidence,
                            'bbox': bbox
                        }
                        valid_texts.append(text_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†ææ–‡å­—å¤±è´¥: {e}")
                    continue
            
            return len(valid_texts), valid_texts
            
        except Exception as e:
            logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def classify_image(self, image_path: str) -> Tuple[str, Dict]:
        """åˆ†ç±»å•å¼ å›¾åƒï¼Œä½¿ç”¨æ–°çš„è®¡åˆ†ç³»ç»Ÿ"""
        try:
            filename = os.path.basename(image_path)
            
            # æ£€æµ‹äººè„¸
            frontal_count, face_details = self.detect_faces(image_path)
            
            # æ£€æµ‹è½¦ç‰Œ
            plate_count, plate_details = self.detect_license_plates(image_path)
            
            # æ£€æµ‹æ–‡å­—
            text_count, text_details = self.detect_text(image_path)
            
            # æ–°è®¡åˆ†ç³»ç»Ÿ
            score = 0
            score_details = []
            
            # æ¸…æ™°çš„äººæ­£è„¸ï¼šä¸€å¼ è®°2åˆ†
            if frontal_count > 0:
                face_score = frontal_count * 2
                score += face_score
                score_details.append(f"æ¸…æ™°æ­£è„¸ {frontal_count} å¼  = {face_score} åˆ†")
            
            # æ¸…æ™°çš„è½¦ç‰Œï¼šä¸€å¼ è®°1åˆ†
            if plate_count > 0:
                plate_score = plate_count * 1
                score += plate_score
                score_details.append(f"æ¸…æ™°è½¦ç‰Œ {plate_count} å¼  = {plate_score} åˆ†")
            
            # èƒ½è¯†åˆ«çš„æ–‡å­—ï¼šè®°1åˆ†ï¼ˆæ— è®ºå¤šå°‘æ®µæ–‡å­—ï¼‰
            if text_count > 0:
                text_score = 1
                score += text_score
                score_details.append(f"å¯è¯†åˆ«æ–‡å­— = {text_score} åˆ†")
            
            # åˆ¤æ–­æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼ˆæ€»åˆ†>5ï¼‰
            meets_requirements = score > 5
            
            # åˆ›å»ºåˆ†æç»“æœ
            analysis = {
                'filename': filename,
                'frontal_faces': frontal_count,
                'license_plates': plate_count,
                'text_count': text_count,
                'total_score': score,
                'score_details': score_details,
                'meets_requirements': meets_requirements,
                'face_details': face_details,
                'plate_details': plate_details,
                'text_details': text_details,
                'timestamp': time.time()
            }
            
            # åˆ†ç±»é€»è¾‘
            if meets_requirements:
                category = 'qualified'
                analysis['qualification_reason'] = f'æ€»åˆ† {score} åˆ† > 5 åˆ†ï¼Œç¬¦åˆè¦æ±‚'
            else:
                # è¯¦ç»†åˆ†ç±»ä¸ç¬¦åˆè¦æ±‚çš„åŸå› 
                if frontal_count == 0 and plate_count == 0 and text_count == 0:
                    category = 'no_content'
                    analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ† â‰¤ 5 åˆ†ï¼Œæ— ä»»ä½•æœ‰æ•ˆå†…å®¹'
                else:
                    category = 'insufficient_score'
                    analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ† â‰¤ 5 åˆ†ï¼Œä¸ç¬¦åˆè¦æ±‚'
            
            analysis['category'] = category
            
            return category, analysis
            
        except Exception as e:
            logger.error(f"âŒ å›¾åƒåˆ†ç±»å¤±è´¥ {image_path}: {e}")
            return 'failed', {'filename': os.path.basename(image_path), 'error': str(e)}
    
    def copy_image_to_category(self, image_path: str, category: str) -> bool:
        """å¤åˆ¶å›¾åƒåˆ°å¯¹åº”åˆ†ç±»ç›®å½•"""
        try:
            filename = os.path.basename(image_path)
            
            # ç¡®å®šç›®æ ‡ç›®å½•
            category_dirs = {
                'qualified': QUALIFIED_DIR,
                'no_content': NO_CONTENT_DIR,
                'insufficient_score': INSUFFICIENT_SCORE_DIR
            }
            
            if category not in category_dirs:
                return False
            
            output_dir = category_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            # ç§»åŠ¨æ–‡ä»¶
            shutil.move(image_path, output_path)
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def get_image_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        files = []
        input_path = Path(INPUT_DIR)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
            return []
        
        logger.info(f"ğŸ” æ‰«æç›®å½•: {INPUT_DIR}")
        
        for ext in SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            files.extend(input_path.glob(pattern))
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²è·¯å¾„å¹¶æ’åº
        image_files = sorted([str(f) for f in files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœåˆ°JSONæ–‡ä»¶"""
        try:
            # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
            analysis_file = os.path.join(ANALYSIS_DIR, "classification_analysis.json")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
            summary = {
                'total_processed': len(self.analysis_results),
                'statistics': self.stats.copy(),
                'processing_time': time.time() - self.start_time,
                'configuration': {
                    'min_frontal_faces': MIN_FRONTAL_FACES,
                    'min_license_plates': MIN_LICENSE_PLATES,
                    'yaw_angle_threshold': YAW_ANGLE_THRESHOLD,
                    'min_face_confidence': MIN_FACE_CONFIDENCE,
                    'min_plate_confidence': MIN_PLATE_CONFIDENCE
                },
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(ANALYSIS_DIR, "classification_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        total_processed = sum(self.stats.values())
        
        logger.info("="*80)
        logger.info("ğŸ‰ æ­£è„¸å’Œè½¦ç‰Œåˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        logger.info("ç¬¦åˆæ¡ä»¶çš„ä¸‰ç§æƒ…å†µ:")
        logger.info("  1. ä¸‰å¼ æ¸…æ™°çš„æ­£è„¸")
        logger.info("  2. 2å¼ æ­£è„¸ + 1å¼ è½¦ç‰Œ")  
        logger.info("  3. å›¾ç‰‡ä¸­æœ‰å¯è¯†åˆ«çš„æ–‡å­—")
        logger.info(f"âœ… ç¬¦åˆæ¡ä»¶: {self.stats['qualified']:,}")
        logger.info(f"ğŸ‘¤ æ— äººè„¸: {self.stats['no_faces']:,}")
        logger.info(f"ğŸ˜ æ­£è„¸ä¸å¤Ÿ: {self.stats['insufficient_faces']:,}")
        logger.info(f"ï¿½ æ— è½¦ç‰Œä¸”æ— æ–‡å­—: {self.stats['no_plates_or_text']:,}")
        logger.info(f"â“ å…¶ä»–é—®é¢˜: {self.stats['other_issues']:,}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,}")
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,}")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            avg_speed = total_processed / processing_time
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            # æˆåŠŸç‡ç»Ÿè®¡
            success_rate = (self.stats['qualified'] / total_processed) * 100
            logger.info(f"ğŸ“ˆ ç¬¦åˆæ¡ä»¶æ¯”ä¾‹: {success_rate:.1f}%")
        
        # æ˜¾ç¤ºå„ç›®å½•æ–‡ä»¶æ•°é‡
        def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        total_processed = sum(self.stats.values())
        
        logger.info("="*80)
        logger.info("ğŸ‰ æ­£è„¸å’Œè½¦ç‰Œåˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        logger.info("æ–°çš„è®¡åˆ†ç³»ç»Ÿ:")
        logger.info("  - ä¸€å¼ æ¸…æ™°æ­£è„¸ = 2åˆ†")
        logger.info("  - ä¸€å¼ æ¸…æ™°è½¦ç‰Œ = 1åˆ†")  
        logger.info("  - èƒ½è¯†åˆ«çš„æ–‡å­— = 1åˆ†")
        logger.info("  - æ€»åˆ† > 5åˆ† = ç¬¦åˆè¦æ±‚")
        logger.info(f"âœ… ç¬¦åˆæ¡ä»¶(>5åˆ†): {self.stats['qualified']:,}")
        logger.info(f"âŒ æ— ä»»ä½•å†…å®¹: {self.stats['no_content']:,}")
        logger.info(f"âŒ åˆ†æ•°ä¸å¤Ÿ(â‰¤5åˆ†): {self.stats['insufficient_score']:,}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,}")
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,}")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            avg_speed = total_processed / processing_time
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            # æˆåŠŸç‡ç»Ÿè®¡
            success_rate = (self.stats['qualified'] / total_processed) * 100
            logger.info(f"ğŸ“ˆ ç¬¦åˆæ¡ä»¶æ¯”ä¾‹: {success_rate:.1f}%")
        
        # æ˜¾ç¤ºå„ç›®å½•æ–‡ä»¶æ•°é‡
        logger.info("
ğŸ“‚ å„åˆ†ç±»ç›®å½•ç»Ÿè®¡:")
        categories = [
            ("ç¬¦åˆæ¡ä»¶", QUALIFIED_DIR),
            ("æ— ä»»ä½•å†…å®¹", NO_CONTENT_DIR),
            ("åˆ†æ•°ä¸å¤Ÿ", INSUFFICIENT_SCORE_DIR)
        ]
        
        for name, dir_path in categories:
            if os.path.exists(dir_path):
                count = len([f for f in os.listdir(dir_path) 
                           if f.lower().endswith(tuple(SUPPORTED_FORMATS))])
                logger.info(f"  ğŸ“ {name}: {count} å¼ å›¾ç‰‡")
        
        logger.info("="*80)
        categories = [
            ("ç¬¦åˆæ¡ä»¶", QUALIFIED_DIR),
            ("æ— äººè„¸", NO_FACES_DIR),
            ("æ­£è„¸ä¸å¤Ÿ", INSUFFICIENT_FACES_DIR),
            ("æ— è½¦ç‰Œ", NO_PLATES_DIR)
        ]
        
        for name, dir_path in categories:
            if os.path.exists(dir_path):
                count = len([f for f in os.listdir(dir_path) 
                           if f.lower().endswith(tuple(SUPPORTED_FORMATS))])
                logger.info(f"  ğŸ“ {name}: {count} å¼ å›¾ç‰‡")
        
        logger.info("="*80)
    
    def run(self):
        """è¿è¡Œåˆ†ç±»å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_BASE_DIR}")
        logger.info(f"ğŸ‘¥ æœ€å°æ­£è„¸æ•°é‡: {MIN_FRONTAL_FACES}")
        logger.info(f"ğŸš— æœ€å°è½¦ç‰Œæ•°é‡: {MIN_LICENSE_PLATES}")
        logger.info(f"âœ¨ å…è®¸3å¼ æ¸…æ™°äººè„¸æ›¿ä»£: {'æ˜¯' if ALLOW_THREE_CLEAR_FACES else 'å¦'}")
        logger.info(f"ï¿½ å…è®¸æ–‡å­—è¯†åˆ«æ›¿ä»£: {'æ˜¯' if ALLOW_TEXT_RECOGNITION else 'å¦'}")
        logger.info(f"ï¿½ğŸ“ yawè§’åº¦é˜ˆå€¼: {YAW_ANGLE_THRESHOLD}Â°")
        logger.info(f"ğŸ¯ äººè„¸ç½®ä¿¡åº¦é˜ˆå€¼: {MIN_FACE_CONFIDENCE}")
        logger.info(f"ğŸ¯ è½¦ç‰Œç½®ä¿¡åº¦é˜ˆå€¼: {MIN_PLATE_CONFIDENCE}")
        logger.info(f"ğŸ¯ æ–‡å­—è¯†åˆ«ç½®ä¿¡åº¦é˜ˆå€¼: {MIN_TEXT_CONFIDENCE}")
        logger.info(f"ğŸ” æœ€å°æ¸…æ™°åº¦åˆ†æ•°: {MIN_FACE_CLARITY_SCORE}")
        logger.info(f"ğŸ“ æœ€å°äººè„¸é¢ç§¯: {FACE_AREA_THRESHOLD}pxÂ²")
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files()
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return
        
        # å¼€å§‹å¤„ç†
        try:
            with tqdm(
                total=len(image_files),
                desc="åˆ†ç±»è¿›åº¦",
                ncols=120,
                bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
            ) as pbar:
                
                for i, image_path in enumerate(image_files):
                    try:
                        # åˆ†ç±»å›¾åƒ
                        category, analysis = self.classify_image(image_path)
                        
                        if category != 'failed':
                            # å¤åˆ¶åˆ°å¯¹åº”ç›®å½•
                            if self.copy_image_to_category(image_path, category):
                                self.stats[category] += 1
                            else:
                                self.stats['failed'] += 1
                                analysis['copy_failed'] = True
                        else:
                            self.stats['failed'] += 1
                        
                        # ä¿å­˜åˆ†æç»“æœ
                        self.analysis_results.append(analysis)
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        pbar.update(1)
                        
                        # æ›´æ–°æè¿°
                        if i % PROGRESS_UPDATE_FREQUENCY == 0 and i > 0:
                            stats_str = f"âœ…{self.stats['qualified']} ğŸ‘¤{self.stats['no_faces']} ğŸ˜{self.stats['insufficient_faces']} ğŸš—{self.stats['no_plates']}"
                            pbar.set_description(f"åˆ†ç±»è¿›åº¦ ({stats_str})")
                        
                        # å®šæœŸå†…å­˜æ¸…ç†
                        if i % GC_FREQUENCY == 0 and i > 0:
                            gc.collect()
                    
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
                        self.stats['failed'] += 1
                        pbar.update(1)
        
        finally:
            # ä¿å­˜ç»“æœå’Œç»Ÿè®¡
            self.save_analysis_results()
            self.print_final_statistics()

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(INPUT_DIR):
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
            return
        
        # æ£€æŸ¥è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        if not os.path.exists(PLATE_MODEL_PATH):
            logger.error(f"âŒ è½¦ç‰Œæ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {PLATE_MODEL_PATH}")
            return
        
        # åˆ›å»ºåˆ†ç±»å™¨å¹¶è¿è¡Œ
        classifier = FacePlateClassifier()
        classifier.run()
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
