#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import torch
import os
from pathlib import Path
from typing import Tuple, Dict, List
import shutil
import json
from datetime import datetime

class StrictSimilarityDetector:
    """è¶…ä¸¥æ ¼ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨ - å¤§å¹…å‡å°‘è¯¯åˆ¤"""
    
    def __init__(self, 
                 psnr_threshold=60.0,        # æé«˜åˆ°60ï¼ˆåŸ50ï¼‰
                 ssim_threshold=0.85,        # æé«˜åˆ°0.85ï¼ˆåŸ0.7ï¼‰
                 composite_threshold=75.0,   # æé«˜åˆ°75ï¼ˆåŸ65ï¼‰
                 hist_threshold=0.9,         # æ–°å¢ç›´æ–¹å›¾ä¸¥æ ¼é˜ˆå€¼
                 conditions_required=3):      # è¦æ±‚æ»¡è¶³3ä¸ªæ¡ä»¶ï¼ˆåŸ2ä¸ªï¼‰
        
        self.psnr_threshold = psnr_threshold
        self.ssim_threshold = ssim_threshold  
        self.composite_threshold = composite_threshold
        self.hist_threshold = hist_threshold
        self.conditions_required = conditions_required
        
        # GPUæ£€æµ‹
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_comparisons': 0,
            'similar_found': 0,
            'strict_rejections': 0,
            'processing_time': 0
        }
    
    def calculate_psnr_gpu(self, img1, img2):
        """GPUåŠ é€ŸPSNRè®¡ç®—"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬æ¢ä¸ºtorch tensor
        img1_tensor = torch.from_numpy(img1.astype(np.float32)).to(self.device)
        img2_tensor = torch.from_numpy(img2.astype(np.float32)).to(self.device)
        
        # è®¡ç®—MSE
        mse = torch.mean((img1_tensor - img2_tensor) ** 2)
        
        if mse == 0:
            return float('inf')
        
        max_pixel = 255.0
        psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))
        return psnr.cpu().item()
    
    def calculate_ssim_opencv(self, img1, img2):
        """ä½¿ç”¨OpenCVè®¡ç®—SSIMï¼ˆæ›´å‡†ç¡®ï¼‰"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬æ¢ä¸ºç°åº¦
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        # ä½¿ç”¨é«˜æ–¯çª—å£è®¡ç®—SSIM
        C1 = (0.01 * 255) ** 2
        C2 = (0.03 * 255) ** 2
        
        gray1 = gray1.astype(np.float64)
        gray2 = gray2.astype(np.float64)
        
        mu1 = cv2.GaussianBlur(gray1, (11, 11), 1.5)
        mu2 = cv2.GaussianBlur(gray2, (11, 11), 1.5)
        
        mu1_sq = mu1 ** 2
        mu2_sq = mu2 ** 2
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = cv2.GaussianBlur(gray1 ** 2, (11, 11), 1.5) - mu1_sq
        sigma2_sq = cv2.GaussianBlur(gray2 ** 2, (11, 11), 1.5) - mu2_sq
        sigma12 = cv2.GaussianBlur(gray1 * gray2, (11, 11), 1.5) - mu1_mu2
        
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        
        return np.mean(ssim_map)
    
    def calculate_histogram_similarity_strict(self, img1, img2):
        """æ›´ä¸¥æ ¼çš„ç›´æ–¹å›¾ç›¸ä¼¼åº¦è®¡ç®—"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # å¤šé€šé“ç›´æ–¹å›¾æ¯”è¾ƒ
        similarities = []
        
        # RGBå„é€šé“ç›´æ–¹å›¾
        for i in range(3):
            hist1 = cv2.calcHist([img1], [i], None, [256], [0, 256])
            hist2 = cv2.calcHist([img2], [i], None, [256], [0, 256])
            
            # æ ‡å‡†åŒ–
            hist1 = cv2.normalize(hist1, hist1).flatten()
            hist2 = cv2.normalize(hist2, hist2).flatten()
            
            # ä½¿ç”¨å·´æ°è·ç¦»ï¼ˆæ›´ä¸¥æ ¼ï¼‰
            similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)
            similarities.append(1.0 - similarity)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
        
        # HSVç©ºé—´ç›´æ–¹å›¾
        hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)
        hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)
        
        hist_hsv1 = cv2.calcHist([hsv1], [0, 1], None, [180, 256], [0, 180, 0, 256])
        hist_hsv2 = cv2.calcHist([hsv2], [0, 1], None, [180, 256], [0, 180, 0, 256])
        
        hsv_similarity = cv2.compareHist(hist_hsv1, hist_hsv2, cv2.HISTCMP_CORREL)
        
        # ç»¼åˆè¯„åˆ†
        rgb_avg = np.mean(similarities)
        final_similarity = (rgb_avg * 0.6 + hsv_similarity * 0.4)
        
        return max(0, final_similarity)
    
    def calculate_structural_difference(self, img1, img2):
        """è®¡ç®—ç»“æ„å·®å¼‚åº¦ï¼ˆè¾¹ç¼˜æ£€æµ‹å¯¹æ¯”ï¼‰"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬ç°åº¦
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        # Cannyè¾¹ç¼˜æ£€æµ‹
        edges1 = cv2.Canny(gray1, 50, 150)
        edges2 = cv2.Canny(gray2, 50, 150)
        
        # è®¡ç®—è¾¹ç¼˜ç›¸ä¼¼åº¦
        edge_diff = np.abs(edges1.astype(np.float32) - edges2.astype(np.float32))
        edge_similarity = 1.0 - (np.mean(edge_diff) / 255.0)
        
        return edge_similarity
    
    def quick_similarity_check(self, img_path1, img_path2):
        """å¿«é€Ÿé¢„æ£€æŸ¥ - é¿å…ä¸å¿…è¦çš„è¯¦ç»†è®¡ç®—"""
        try:
            # æ–‡ä»¶å¤§å°å¿«é€Ÿæ£€æŸ¥
            size1 = img_path1.stat().st_size
            size2 = img_path2.stat().st_size
            size_ratio = min(size1, size2) / max(size1, size2)
            
            # å¦‚æœæ–‡ä»¶å¤§å°å·®å¼‚è¶…è¿‡50%ï¼Œä¸å¤ªå¯èƒ½æ˜¯ç›¸ä¼¼å›¾ç‰‡
            if size_ratio < 0.5:
                return False
            
            # è¯»å–å›¾åƒå¹¶å¿«é€Ÿæ£€æŸ¥åˆ†è¾¨ç‡
            img1 = cv2.imread(str(img_path1))
            img2 = cv2.imread(str(img_path2))
            
            if img1 is None or img2 is None:
                return False
            
            h1, w1 = img1.shape[:2]
            h2, w2 = img2.shape[:2]
            
            # åˆ†è¾¨ç‡å·®å¼‚æ£€æŸ¥
            res_ratio = min(w1*h1, w2*h2) / max(w1*h1, w2*h2)
            if res_ratio < 0.7:  # åˆ†è¾¨ç‡å·®å¼‚è¶…è¿‡30%
                return False
            
            # å¿«é€Ÿç›´æ–¹å›¾æ£€æŸ¥ï¼ˆåªæ£€æŸ¥ä¸€ä¸ªé€šé“ï¼‰
            hist1 = cv2.calcHist([img1], [0], None, [64], [0, 256])  # é™ä½ç²¾åº¦
            hist2 = cv2.calcHist([img2], [0], None, [64], [0, 256])
            
            hist1 = cv2.normalize(hist1, hist1).flatten()
            hist2 = cv2.normalize(hist2, hist2).flatten()
            
            # å¿«é€Ÿç›¸å…³æ€§æ£€æŸ¥
            correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            
            # å¦‚æœè¿åŸºæœ¬çš„ç›´æ–¹å›¾ç›¸å…³æ€§éƒ½å¾ˆä½ï¼Œè·³è¿‡è¯¦ç»†æ£€æŸ¥
            return correlation > 0.6
            
        except Exception:
            return True  # å‡ºé”™æ—¶ç»§ç»­è¯¦ç»†æ£€æŸ¥
    
    def are_images_strictly_similar(self, img_path1, img_path2):
        """è¶…ä¸¥æ ¼ç›¸ä¼¼åº¦åˆ¤å®š - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            # ğŸš€ å¿«é€Ÿé¢„æ£€æŸ¥
            if not self.quick_similarity_check(img_path1, img_path2):
                return False, 0, {}
            
            # è¯»å–å›¾åƒ
            img1 = cv2.imread(str(img_path1))
            img2 = cv2.imread(str(img_path2))
            
            if img1 is None or img2 is None:
                return False, 0, {}
            
            # 1. PSNRæ£€æµ‹
            psnr = self.calculate_psnr_gpu(img1, img2)
            is_similar_psnr = psnr > self.psnr_threshold
            
            # 2. SSIMæ£€æµ‹ï¼ˆæ›´ä¸¥æ ¼ï¼‰
            ssim = self.calculate_ssim_opencv(img1, img2)
            is_similar_ssim = ssim > self.ssim_threshold
            
            # 3. ç›´æ–¹å›¾ç›¸ä¼¼åº¦ï¼ˆæ›´ä¸¥æ ¼ï¼‰
            hist_sim = self.calculate_histogram_similarity_strict(img1, img2)
            is_similar_hist = hist_sim > self.hist_threshold
            
            # 4. ç»“æ„ç›¸ä¼¼åº¦ï¼ˆæ–°å¢ï¼‰
            struct_sim = self.calculate_structural_difference(img1, img2)
            is_similar_struct = struct_sim > 0.8
            
            # 5. å¤åˆè¯„åˆ†ï¼ˆæ›´ä¸¥æ ¼æƒé‡ï¼‰
            psnr_normalized = min(psnr / 70.0, 1.0)  # æé«˜åŸºå‡†åˆ°70
            composite_score = (psnr_normalized * 0.3 + ssim * 0.3 + hist_sim * 0.25 + struct_sim * 0.15) * 100
            is_similar_composite = composite_score > self.composite_threshold
            
            # ä¸¥æ ¼æ¡ä»¶æ£€æŸ¥
            conditions = [is_similar_psnr, is_similar_ssim, is_similar_hist, is_similar_struct, is_similar_composite]
            conditions_met = sum(conditions)
            
            # å¿…é¡»æ»¡è¶³æ‰€æœ‰ä¸»è¦æ¡ä»¶
            is_similar = conditions_met >= self.conditions_required and is_similar_psnr and is_similar_ssim
            
            details = {
                'psnr': psnr,
                'ssim': ssim,
                'hist_similarity': hist_sim,
                'structural_similarity': struct_sim,
                'composite_score': composite_score,
                'conditions_met': f"{conditions_met}/5",
                'is_similar_breakdown': {
                    'psnr': is_similar_psnr,
                    'ssim': is_similar_ssim,
                    'histogram': is_similar_hist,
                    'structural': is_similar_struct,
                    'composite': is_similar_composite
                }
            }
            
            self.stats['total_comparisons'] += 1
            if is_similar:
                self.stats['similar_found'] += 1
            else:
                self.stats['strict_rejections'] += 1
                
            return is_similar, composite_score, details
            
        except Exception as e:
            print(f"âŒ æ¯”è¾ƒå¤±è´¥ {img_path1} vs {img_path2}: {e}")
            return False, 0, {}
    
    def extract_frame_number(self, filename):
        """ä»æ–‡ä»¶åä¸­æå–å¸§ç¼–å·"""
        import re
        # åŒ¹é… video40_frame_000xxx.jpg æ ¼å¼
        match = re.search(r'video\d+_frame_(\d+)\.jpg', filename)
        if match:
            return int(match.group(1))
        return 0
    
    def detect_and_remove_strict_duplicates(self, directory_path, output_dir=None, nearby_range=5):
        """ä¸¥æ ¼æ£€æµ‹å¹¶ç§»é™¤é‡å¤å›¾ç‰‡ - åªæ¯”è¾ƒç›¸è¿‘ç¼–å·çš„å›¾ç‰‡"""
        directory = Path(directory_path)
        if not directory.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = [f for f in directory.glob("*") if f.suffix.lower() in image_extensions]
        
        if len(image_files) < 2:
            print("ğŸ“ å›¾ç‰‡æ•°é‡ä¸è¶³ï¼Œæ— éœ€æ£€æµ‹")
            return
        
        # æŒ‰å¸§ç¼–å·æ’åº
        image_files.sort(key=lambda x: self.extract_frame_number(x.name))
        
        # æ˜¾ç¤ºå¸§ç¼–å·èŒƒå›´
        frame_numbers = [self.extract_frame_number(f.name) for f in image_files]
        print(f"ğŸ” æ™ºèƒ½æ£€æµ‹ {len(image_files)} å¼ å›¾ç‰‡ (å¸§ç¼–å·: {min(frame_numbers)}-{max(frame_numbers)})")
        print(f"ğŸ¯ åªæ¯”è¾ƒç›¸è¿‘ Â±{nearby_range} å¸§å†…çš„å›¾ç‰‡")
        
        # è®¡ç®—å®é™…æ¯”è¾ƒæ¬¡æ•°
        total_comparisons = 0
        for i in range(len(image_files)):
            for j in range(i+1, min(i+1+nearby_range, len(image_files))):
                total_comparisons += 1
        
        print(f"ğŸ“Š æ™ºèƒ½æ¯”è¾ƒæ¬¡æ•°: {total_comparisons} (ç›¸æ¯”å…¨æ¯”è¾ƒèŠ‚çœ: {((len(image_files)*(len(image_files)-1)//2 - total_comparisons)/(len(image_files)*(len(image_files)-1)//2)*100):.1f}%)")
        print(f"âš™ï¸ å½“å‰é˜ˆå€¼ - PSNR: {self.psnr_threshold}, SSIM: {self.ssim_threshold}, å¤åˆ: {self.composite_threshold}")
        print(f"ğŸ¯ è¦æ±‚æ»¡è¶³ {self.conditions_required}/5 ä¸ªæ¡ä»¶")
        print()
        
        duplicate_groups = []
        processed = set()
        comparison_count = 0
        
        for i, img1 in enumerate(image_files):
            if str(img1) in processed:
                continue
                
            current_group = [img1]
            processed.add(str(img1))
            
            frame_num1 = self.extract_frame_number(img1.name)
            print(f"ğŸ” æ£€æµ‹å›¾ç‰‡ {i+1}/{len(image_files)}: {img1.name} (å¸§å·: {frame_num1})")
            
            # åªæ¯”è¾ƒç›¸è¿‘çš„å›¾ç‰‡
            for j in range(i+1, min(i+1+nearby_range, len(image_files))):
                img2 = image_files[j]
                if str(img2) in processed:
                    continue
                
                frame_num2 = self.extract_frame_number(img2.name)
                frame_diff = abs(frame_num2 - frame_num1)
                
                comparison_count += 1
                
                # æ˜¾ç¤ºæ¯”è¾ƒä¿¡æ¯
                print(f"  ğŸ“Š æ¯”è¾ƒ {img2.name} (å¸§å·®: {frame_diff}) [{comparison_count}/{total_comparisons}]", end="")
                
                is_similar, score, details = self.are_images_strictly_similar(img1, img2)
                
                if is_similar:
                    print(f" âœ… ç›¸ä¼¼!")
                    print(f"     ğŸ“Š PSNR: {details['psnr']:.1f}, SSIM: {details['ssim']:.3f}")
                    print(f"     ğŸ“Š å¤åˆåˆ†: {details['composite_score']:.1f}, æ¡ä»¶: {details['conditions_met']}")
                    current_group.append(img2)
                    processed.add(str(img2))
                else:
                    print(f" âŒ ä¸åŒ")
            
            if len(current_group) > 1:
                duplicate_groups.append(current_group)
                print(f"  ğŸ“ ç›¸ä¼¼ç»„å¤§å°: {len(current_group)}")
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = ((i + 1) / len(image_files)) * 100
            print(f"  ğŸ“Š æ€»è¿›åº¦: {i+1}/{len(image_files)} ({progress:.1f}%)")
            print()
        
        print(f"ğŸ“Š æ™ºèƒ½æ¯”è¾ƒå®Œæˆ! å®é™…æ¯”è¾ƒ: {comparison_count}/{total_comparisons}")
        
        # å¤„ç†é‡å¤ç»„
        if not duplicate_groups:
            print("âœ… æœªå‘ç°ç›¸ä¼¼çš„ç›¸é‚»å¸§å›¾ç‰‡ï¼æ‰€æœ‰å›¾ç‰‡éƒ½è¶³å¤Ÿç‹¬ç‰¹ã€‚")
            
            # å¦‚æœæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œå¤åˆ¶æ‰€æœ‰æ–‡ä»¶
            if output_dir:
                output_path = Path(output_dir)
                output_path.mkdir(parents=True, exist_ok=True)
                for img in image_files:
                    shutil.copy2(img, output_path / img.name)
                print(f"ğŸ“ æ‰€æœ‰ {len(image_files)} å¼ å›¾ç‰‡å·²å¤åˆ¶åˆ°: {output_path}")
            return
        
        print(f"\nğŸ¯ å‘ç° {len(duplicate_groups)} ä¸ªç›¸ä¼¼çš„ç›¸é‚»å¸§ç»„:")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = None
        if output_dir:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
        
        kept_files = []
        removed_files = []
        
        for i, group in enumerate(duplicate_groups):
            frame_numbers_in_group = [self.extract_frame_number(img.name) for img in group]
            print(f"\nğŸ“ å¤„ç†ç›¸ä¼¼ç»„ {i+1}/{len(duplicate_groups)}: {len(group)} å¼ ç›¸é‚»å¸§")
            print(f"   ğŸ“Š å¸§ç¼–å·èŒƒå›´: {min(frame_numbers_in_group)}-{max(frame_numbers_in_group)}")
            
            # é€‰æ‹©æœ€ä½³å›¾ç‰‡
            best_img = self.select_best_image_strict(group)
            
            for img in group:
                frame_num = self.extract_frame_number(img.name)
                if img == best_img:
                    kept_files.append(img)
                    if output_path:
                        shutil.copy2(img, output_path / img.name)
                    print(f"  âœ… ä¿ç•™: {img.name} (å¸§å·: {frame_num})")
                else:
                    removed_files.append(img)
                    print(f"  ğŸ—‘ï¸ ç§»é™¤: {img.name} (å¸§å·: {frame_num})")
        
        # å¤åˆ¶éé‡å¤æ–‡ä»¶
        if output_path:
            for img in image_files:
                if not any(img in group for group in duplicate_groups):
                    shutil.copy2(img, output_path / img.name)
                    kept_files.append(img)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'timestamp': datetime.now().isoformat(),
            'input_directory': str(directory),
            'output_directory': str(output_path) if output_path else None,
            'detection_method': 'nearby_frames_only',
            'nearby_range': nearby_range,
            'detection_settings': {
                'psnr_threshold': self.psnr_threshold,
                'ssim_threshold': self.ssim_threshold,
                'composite_threshold': self.composite_threshold,
                'hist_threshold': self.hist_threshold,
                'conditions_required': self.conditions_required
            },
            'statistics': self.stats,
            'frame_analysis': {
                'frame_range': f"{min(frame_numbers)}-{max(frame_numbers)}",
                'total_frames': len(image_files),
                'comparisons_made': comparison_count,
                'comparisons_saved': (len(image_files)*(len(image_files)-1)//2) - comparison_count,
                'efficiency_gain': f"{((len(image_files)*(len(image_files)-1)//2 - comparison_count)/(len(image_files)*(len(image_files)-1)//2)*100):.1f}%"
            },
            'results': {
                'total_images': len(image_files),
                'total_comparisons': comparison_count,
                'duplicate_groups': len(duplicate_groups),
                'images_kept': len(kept_files),
                'images_removed': len(removed_files),
                'reduction_rate': f"{(len(removed_files)/len(image_files)*100):.1f}%"
            },
            'duplicate_groups': [
                {
                    'group_id': i+1,
                    'images': [str(img) for img in group],
                    'frame_numbers': [self.extract_frame_number(img.name) for img in group],
                    'kept_image': str(self.select_best_image_strict(group))
                }
                for i, group in enumerate(duplicate_groups)
            ]
        }
        
        report_path = output_path / "nearby_frames_similarity_report.json" if output_path else Path(directory) / "nearby_frames_similarity_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ‰ æ™ºèƒ½ç›¸é‚»å¸§ç­›é€‰å®Œæˆ!")
        print(f"   ğŸ“Š æ€»å›¾ç‰‡æ•°: {len(image_files)}")
        print(f"   ğŸ” å®é™…æ¯”è¾ƒ: {comparison_count}")
        print(f"   âš¡ æ•ˆç‡æå‡: {((len(image_files)*(len(image_files)-1)//2 - comparison_count)/(len(image_files)*(len(image_files)-1)//2)*100):.1f}%")
        print(f"   ğŸ“ ç›¸ä¼¼ç»„æ•°: {len(duplicate_groups)}")  
        print(f"   âœ… ä¿ç•™å›¾ç‰‡: {len(kept_files)}")
        print(f"   ğŸ—‘ï¸ ç§»é™¤å›¾ç‰‡: {len(removed_files)}")
        print(f"   ğŸ“‰ å‹ç¼©ç‡: {(len(removed_files)/len(image_files)*100):.1f}%")
        print(f"   ğŸ“‹ æŠ¥å‘Šä¿å­˜: {report_path}")
        
        if output_path:
            print(f"   ğŸ“ ç­›é€‰ç»“æœ: {output_path}")
            
        # æ˜¾ç¤ºå¸§åˆ†å¸ƒç»Ÿè®¡
        if duplicate_groups:
            print(f"\nğŸ“Š ç›¸ä¼¼å¸§åˆ†å¸ƒ:")
            for i, group in enumerate(duplicate_groups):
                frame_nums = [self.extract_frame_number(img.name) for img in group]
                print(f"   ç»„{i+1}: å¸§{min(frame_nums)}-{max(frame_nums)} ({len(group)}å¼ )")
        
        print(f"\nğŸ’¡ å»ºè®®: å¦‚éœ€æ›´ä¸¥æ ¼ç­›é€‰ï¼Œå¯è°ƒæ•´ç›¸é‚»èŒƒå›´å‚æ•° (å½“å‰: Â±{nearby_range})")
    
    def select_best_image_strict(self, image_group):
        """ä¸¥æ ¼é€‰æ‹©æœ€ä½³å›¾ç‰‡ - é’ˆå¯¹qualifiedå›¾ç‰‡ä¼˜åŒ–"""
        best_img = None
        best_score = 0
        
        print(f"  ğŸ” è¯„ä¼° {len(image_group)} å¼ ç›¸ä¼¼å›¾ç‰‡...")
        
        for img_path in image_group:
            try:
                # è¯»å–å›¾åƒ
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                # æ–‡ä»¶å¤§å°æƒé‡
                file_size = img_path.stat().st_size
                size_score = min(file_size / 500000, 1.0)  # 500KBåŸºå‡†
                
                # å›¾åƒæ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                clarity = cv2.Laplacian(gray, cv2.CV_64F).var()
                clarity_score = min(clarity / 500, 1.0)  # 500åŸºå‡†
                
                # åˆ†è¾¨ç‡æƒé‡
                height, width = img.shape[:2]
                resolution_score = min((width * height) / 8000000, 1.0)  # 8MPåŸºå‡†
                
                # å›¾åƒå¯¹æ¯”åº¦
                contrast = np.std(gray)
                contrast_score = min(contrast / 50, 1.0)  # 50åŸºå‡†
                
                # è¾¹ç¼˜å¯†åº¦
                edges = cv2.Canny(gray, 50, 150)
                edge_density = np.sum(edges > 0) / (width * height)
                edge_score = min(edge_density * 10, 1.0)
                
                # é¢œè‰²ä¸°å¯Œåº¦ï¼ˆé¥±å’Œåº¦ï¼‰
                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
                saturation = np.mean(hsv[:, :, 1])
                saturation_score = min(saturation / 100, 1.0)
                
                # ç»¼åˆè¯„åˆ†ï¼ˆé’ˆå¯¹qualifiedå›¾ç‰‡ä¼˜åŒ–æƒé‡ï¼‰
                score = (clarity_score * 0.4 +         # æ¸…æ™°åº¦æœ€é‡è¦
                        contrast_score * 0.2 +         # å¯¹æ¯”åº¦
                        edge_score * 0.15 +            # è¾¹ç¼˜ä¿¡æ¯
                        resolution_score * 0.15 +      # åˆ†è¾¨ç‡
                        saturation_score * 0.05 +      # é¢œè‰²ä¸°å¯Œåº¦
                        size_score * 0.05)             # æ–‡ä»¶å¤§å°
                
                print(f"    ğŸ“Š {img_path.name}: æ¸…æ™°åº¦={clarity:.0f}, å¯¹æ¯”åº¦={contrast:.1f}, "
                      f"è¾¹ç¼˜å¯†åº¦={edge_density:.3f}, æ€»åˆ†={score:.3f}")
                
                if score > best_score:
                    best_score = score
                    best_img = img_path
                    
            except Exception as e:
                print(f"âš ï¸ è¯„ä¼°å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
                continue
        
        if best_img:
            print(f"  âœ… æœ€ä½³å›¾ç‰‡: {best_img.name} (åˆ†æ•°: {best_score:.3f})")
        
        return best_img or image_group[0]

def process_qualified_images():
    """ä¸“é—¨å¤„ç†qualifiedç›®å½•çš„å›¾ç‰‡ - æ™ºèƒ½ç›¸é‚»å¸§æ¯”è¾ƒ"""
    # å›ºå®šçš„qualifiedç›®å½•è·¯å¾„
    qualified_dir = "/home/zhiqics/sanjian/predata/output_frames40/qualified"
    output_dir = "/home/zhiqics/sanjian/predata/output_frames40/final_unique"
    
    print("ğŸ¯ ä¸“é—¨å¤„ç†qualifiedå›¾ç‰‡ - æ™ºèƒ½ç›¸é‚»å¸§æ¨¡å¼")
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {qualified_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("ğŸ’¡ åªæ¯”è¾ƒå¸§ç¼–å·ç›¸è¿‘çš„å›¾ç‰‡ï¼Œå¤§å¹…æå‡å¤„ç†é€Ÿåº¦")
    print()
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not Path(qualified_dir).exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {qualified_dir}")
        return
    
    # ä½¿ç”¨è¶…ä¸¥æ ¼å‚æ•°ï¼ˆé’ˆå¯¹qualifiedå›¾ç‰‡ï¼‰
    detector = StrictSimilarityDetector(
        psnr_threshold=65.0,        # è¶…é«˜PSNRè¦æ±‚
        ssim_threshold=0.9,         # è¶…é«˜SSIMè¦æ±‚
        composite_threshold=80.0,   # è¶…é«˜å¤åˆè¯„åˆ†
        hist_threshold=0.95,        # è¶…ä¸¥æ ¼ç›´æ–¹å›¾é˜ˆå€¼
        conditions_required=4       # è¦æ±‚æ»¡è¶³4/5ä¸ªæ¡ä»¶
    )
    
    print("âš™ï¸ è¶…ä¸¥æ ¼å‚æ•°è®¾ç½®:")
    print(f"   - PSNRé˜ˆå€¼: {detector.psnr_threshold}")
    print(f"   - SSIMé˜ˆå€¼: {detector.ssim_threshold}")
    print(f"   - å¤åˆè¯„åˆ†: {detector.composite_threshold}")
    print(f"   - ç›´æ–¹å›¾é˜ˆå€¼: {detector.hist_threshold}")
    print(f"   - æ¡ä»¶è¦æ±‚: {detector.conditions_required}/5")
    print(f"   - ç›¸é‚»èŒƒå›´: Â±5 å¸§")
    print()
    
    # å¼€å§‹æ™ºèƒ½å¤„ç†
    detector.detect_and_remove_strict_duplicates(qualified_dir, output_dir, nearby_range=5)

def main():
    """ä¸»å‡½æ•° - æ”¯æŒäº¤äº’æ¨¡å¼å’Œå‘½ä»¤è¡Œæ¨¡å¼"""
    import argparse
    import sys
    
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›´æ¥å¤„ç†qualifiedç›®å½•
    if len(sys.argv) == 1:
        process_qualified_images()
        return
    
    # å‘½ä»¤è¡Œæ¨¡å¼
    parser = argparse.ArgumentParser(description="è¶…ä¸¥æ ¼ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨ - æ™ºèƒ½ç›¸é‚»å¸§æ¨¡å¼")
    parser.add_argument('input_dir', nargs='?', help='è¾“å…¥å›¾ç‰‡ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤å¤„ç†qualifiedç›®å½•ï¼‰')
    parser.add_argument('-o', '--output', help='è¾“å‡ºç›®å½•ï¼ˆç­›é€‰åçš„å›¾ç‰‡ï¼‰')
    parser.add_argument('--psnr', type=float, default=65.0, help='PSNRé˜ˆå€¼ (é»˜è®¤: 65.0)')
    parser.add_argument('--ssim', type=float, default=0.9, help='SSIMé˜ˆå€¼ (é»˜è®¤: 0.9)')
    parser.add_argument('--composite', type=float, default=80.0, help='å¤åˆè¯„åˆ†é˜ˆå€¼ (é»˜è®¤: 80.0)')
    parser.add_argument('--hist', type=float, default=0.95, help='ç›´æ–¹å›¾é˜ˆå€¼ (é»˜è®¤: 0.95)')
    parser.add_argument('--conditions', type=int, default=4, help='å¿…é¡»æ»¡è¶³çš„æ¡ä»¶æ•° (é»˜è®¤: 4/5)')
    parser.add_argument('--range', type=int, default=5, help='ç›¸é‚»å¸§æ¯”è¾ƒèŒƒå›´ (é»˜è®¤: 5)')
    parser.add_argument('--qualified', action='store_true', help='ç›´æ¥å¤„ç†qualifiedç›®å½•')
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šå¤„ç†qualifiedæˆ–æ²¡æœ‰è¾“å…¥ç›®å½•ï¼Œå¤„ç†qualified
    if args.qualified or not args.input_dir:
        process_qualified_images()
        return
    
    # å¤„ç†æŒ‡å®šç›®å½•
    detector = StrictSimilarityDetector(
        psnr_threshold=args.psnr,
        ssim_threshold=args.ssim,
        composite_threshold=args.composite,
        hist_threshold=args.hist,
        conditions_required=args.conditions
    )
    
    detector.detect_and_remove_strict_duplicates(args.input_dir, args.output, nearby_range=args.range)

if __name__ == "__main__":
    main()