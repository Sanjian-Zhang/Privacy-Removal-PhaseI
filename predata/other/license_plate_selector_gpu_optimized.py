#!/usr/bin/env python3
"""
GPUä¼˜åŒ–ç‰ˆè½¦ç‰Œæ£€æµ‹è„šæœ¬ - å–æ¶ˆå†…å­˜é™åˆ¶ï¼Œå…¨é¢GPUåŠ é€Ÿ
ä¸“é—¨é’ˆå¯¹è½¦ç‰Œæ£€æµ‹è¿›è¡Œä¼˜åŒ–ï¼Œæä¾›æ›´é«˜çš„æ£€æµ‹ç²¾åº¦å’Œé€Ÿåº¦
"""

import os
import cv2
import shutil
import argparse
import gc
import psutil
import torch
import datetime
from pathlib import Path
from ultralytics import YOLO
import numpy as np
from tqdm import tqdm

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            gpu_free = (torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_reserved(i)) / (1024**3)
            print(f"ğŸš€ GPU {i}: {gpu_name} - æ€»å†…å­˜: {gpu_memory:.1f}GB, å¯ç”¨: {gpu_free:.1f}GB")
        return True
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPUï¼Œå°†ä½¿ç”¨CPU")
        return False

def load_license_plate_model(use_gpu=True, gpu_id=None):
    """åŠ è½½ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹"""
    # æŸ¥æ‰¾ license_plate_detector.pt æ¨¡å‹
    model_paths = [
        './license_plate_detector.pt',
        './models/license_plate_detector.pt',
        './Automatic-License-Plate-Recognition-using-YOLOv8/license_plate_detector.pt',
        '../Automatic-License-Plate-Recognition-using-YOLOv8/license_plate_detector.pt',
    ]
    
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print("âŒ æœªæ‰¾åˆ° license_plate_detector.pt æ¨¡å‹æ–‡ä»¶")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€ï¼š")
        for path in model_paths:
            print(f"   - {path}")
        raise FileNotFoundError("license_plate_detector.pt not found")
    
    print(f"ğŸ¯ åŠ è½½ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹: {model_path}")
    model = YOLO(model_path)
    
    # è®¾ç½®è®¾å¤‡
    if use_gpu and torch.cuda.is_available():
        if gpu_id is not None:
            device = f'cuda:{gpu_id}'
            print(f"ğŸ¯ æŒ‡å®šä½¿ç”¨GPU {gpu_id}")
        else:
            device = 'cuda'
        
        try:
            model.to(device)
            gpu_name = torch.cuda.get_device_name(device)
            gpu_memory = torch.cuda.get_device_properties(device).total_memory / (1024**3)
            gpu_used = torch.cuda.memory_allocated(device) / (1024**3)
            print(f"ğŸš€ æ¨¡å‹å·²åŠ è½½åˆ°{device}: {gpu_name}")
            print(f"ğŸ’¾ GPUå†…å­˜: {gpu_used:.1f}GB / {gpu_memory:.1f}GB")
            
            # GPUé¢„çƒ­ - ä½¿ç”¨æ›´å¤§çš„å¼ é‡è¿›è¡Œé¢„çƒ­
            print("ğŸ”¥ GPUé¢„çƒ­ä¸­...")
            dummy_img = torch.randn(4, 3, 640, 640).to(device)  # å¢åŠ æ‰¹æ¬¡å¤§å°
            with torch.no_grad():
                _ = model(dummy_img, verbose=False)
            del dummy_img
            torch.cuda.empty_cache()
            print("âœ… GPUé¢„çƒ­å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ GPUåŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            device = 'cpu'
            model.to(device)
    else:
        device = 'cpu'
        print("ğŸ’» ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
    
    return model, device

def calculate_sharpness(image_region):
    """è®¡ç®—å›¾åƒåŒºåŸŸçš„æ¸…æ™°åº¦ï¼ˆä½¿ç”¨GPUåŠ é€Ÿï¼‰"""
    if torch.cuda.is_available():
        # GPUåŠ é€Ÿç‰ˆæœ¬
        gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
        gray_tensor = torch.from_numpy(gray).float().cuda()
        # ä½¿ç”¨Sobelç®—å­è®¡ç®—æ¢¯åº¦
        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).cuda().unsqueeze(0).unsqueeze(0)
        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).cuda().unsqueeze(0).unsqueeze(0)
        
        gray_tensor = gray_tensor.unsqueeze(0).unsqueeze(0)
        grad_x = torch.nn.functional.conv2d(gray_tensor, sobel_x, padding=1)
        grad_y = torch.nn.functional.conv2d(gray_tensor, sobel_y, padding=1)
        
        gradient_magnitude = torch.sqrt(grad_x**2 + grad_y**2)
        sharpness = torch.var(gradient_magnitude).item()
        
        del gray_tensor, grad_x, grad_y, gradient_magnitude
        torch.cuda.empty_cache()
        return sharpness
    else:
        # CPUç‰ˆæœ¬
        gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
        return cv2.Laplacian(gray, cv2.CV_64F).var()

def calculate_contrast(image_region):
    """è®¡ç®—å›¾åƒåŒºåŸŸçš„å¯¹æ¯”åº¦ï¼ˆä½¿ç”¨GPUåŠ é€Ÿï¼‰"""
    if torch.cuda.is_available():
        # GPUåŠ é€Ÿç‰ˆæœ¬
        gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
        gray_tensor = torch.from_numpy(gray).float().cuda()
        contrast = torch.std(gray_tensor).item()
        del gray_tensor
        torch.cuda.empty_cache()
        return contrast
    else:
        # CPUç‰ˆæœ¬
        gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
        return gray.std()

def evaluate_plate_quality(img, bbox, min_width=60, min_height=15, min_sharpness=50, min_contrast=15):
    """è¯„ä¼°è½¦ç‰Œè´¨é‡"""
    x1, y1, x2, y2 = bbox
    width = x2 - x1
    height = y2 - y1
    
    # åŸºæœ¬å°ºå¯¸æ£€æŸ¥
    if width < min_width or height < min_height:
        return False, f"å°ºå¯¸è¿‡å°: {width}x{height}"
    
    # é•¿å®½æ¯”æ£€æŸ¥ï¼ˆè½¦ç‰Œé€šå¸¸æ˜¯æ¨ªå‘çš„ï¼‰
    aspect_ratio = width / height
    if aspect_ratio < 1.5 or aspect_ratio > 8:
        return False, f"é•¿å®½æ¯”å¼‚å¸¸: {aspect_ratio:.2f}"
    
    # æå–è½¦ç‰ŒåŒºåŸŸ
    plate_region = img[y1:y2, x1:x2]
    if plate_region.size == 0:
        return False, "è½¦ç‰ŒåŒºåŸŸä¸ºç©º"
    
    # è®¡ç®—æ¸…æ™°åº¦å’Œå¯¹æ¯”åº¦
    sharpness = calculate_sharpness(plate_region)
    contrast = calculate_contrast(plate_region)
    
    # è´¨é‡æ£€æŸ¥
    if sharpness < min_sharpness:
        return False, f"æ¸…æ™°åº¦ä¸è¶³: {sharpness:.1f} < {min_sharpness}"
    
    if contrast < min_contrast:
        return False, f"å¯¹æ¯”åº¦ä¸è¶³: {contrast:.1f} < {min_contrast}"
    
    return True, {
        "width": width,
        "height": height,
        "aspect_ratio": aspect_ratio,
        "sharpness": sharpness,
        "contrast": contrast,
        "area": width * height
    }

def detect_license_plates_batch(image_paths, model, device, conf_threshold=0.3):
    """æ‰¹é‡æ£€æµ‹å›¾ç‰‡ä¸­çš„è½¦ç‰Œï¼ˆGPUä¼˜åŒ–ï¼‰"""
    results = []
    
    # é¢„åŠ è½½å›¾åƒ
    images = []
    valid_paths = []
    
    for img_path in image_paths:
        img = cv2.imread(str(img_path))
        if img is not None:
            images.append(img)
            valid_paths.append(img_path)
    
    if not images:
        return results
    
    try:
        # æ‰¹é‡æ¨ç†
        batch_results = model(images, conf=conf_threshold, device=device, verbose=False)
        
        for i, (result, img_path, img) in enumerate(zip(batch_results, valid_paths, images)):
            detected_plates = []
            
            if result.boxes is not None:
                for box in result.boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œç½®ä¿¡åº¦
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    
                    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                    x1, y1, x2, y2 = max(0, int(x1)), max(0, int(y1)), min(img.shape[1], int(x2)), min(img.shape[0], int(y2))
                    
                    detected_plates.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(conf)
                    })
            
            results.append({
                'path': img_path,
                'image': img,
                'has_plates': len(detected_plates) > 0,
                'plates': detected_plates
            })
    
    except Exception as e:
        print(f"âŒ æ‰¹é‡æ£€æµ‹å¤±è´¥: {e}")
        # å›é€€åˆ°å•å¼ å¤„ç†
        for img_path, img in zip(valid_paths, images):
            try:
                result = model(img, conf=conf_threshold, device=device, verbose=False)[0]
                detected_plates = []
                
                if result.boxes is not None:
                    for box in result.boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = box.conf[0].cpu().numpy()
                        x1, y1, x2, y2 = max(0, int(x1)), max(0, int(y1)), min(img.shape[1], int(x2)), min(img.shape[0], int(y2))
                        
                        detected_plates.append({
                            'bbox': [x1, y1, x2, y2],
                            'confidence': float(conf)
                        })
                
                results.append({
                    'path': img_path,
                    'image': img,
                    'has_plates': len(detected_plates) > 0,
                    'plates': detected_plates
                })
            except Exception as e2:
                print(f"âŒ å•å¼ æ£€æµ‹å¤±è´¥ {img_path}: {e2}")
                results.append({
                    'path': img_path,
                    'image': img,
                    'has_plates': False,
                    'plates': []
                })
    
    return results

def process_images(input_dir, output_dir, model, device, conf_threshold=0.3, 
                  min_sharpness=50, min_contrast=15, copy_mode=True, batch_size=64):
    """å¤„ç†å›¾ç‰‡ç›®å½•ï¼ŒæŒ‘é€‰æœ‰è½¦ç‰Œçš„å›¾ç‰‡ï¼ˆGPUä¼˜åŒ–ï¼Œæ— å†…å­˜é™åˆ¶ï¼‰"""
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºè¾“å‡ºå­ç›®å½•
    selected_dir = output_path / "selected_plates"
    annotated_dir = output_path / "annotated"
    rejected_dir = output_path / "rejected" if not copy_mode else None
    stats_dir = output_path / "stats"
    
    selected_dir.mkdir(exist_ok=True)
    annotated_dir.mkdir(exist_ok=True)
    stats_dir.mkdir(exist_ok=True)
    if rejected_dir:
        rejected_dir.mkdir(exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    image_files = [f for f in input_path.iterdir() 
                  if f.is_file() and f.suffix.lower() in image_extensions]
    
    if not image_files:
        print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ“ å¤„ç† {len(image_files)} å¼ å›¾ç‰‡ï¼ˆæ‰¹å¤„ç†å¤§å°: {batch_size}ï¼‰...")
    print(f"ğŸ¯ è½¦ç‰Œæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    print(f"ğŸ“ æœ€å°æ¸…æ™°åº¦: {min_sharpness}")
    print(f"ğŸ” æœ€å°å¯¹æ¯”åº¦: {min_contrast}")
    print(f"ğŸš€ GPUä¼˜åŒ–æ¨¡å¼ - æ— å†…å­˜é™åˆ¶")
    print(f"ğŸ“¸ å›¾ç‰‡ä¿æŒåŸå§‹å¤§å°å’Œè´¨é‡ - æ— å‹ç¼©")
    
    selected_count = 0
    rejected_count = 0
    total_plates = 0
    processed_count = 0
    
    # ç”¨äºç»Ÿè®¡çš„æ•°æ®
    detection_stats = []
    
    # åˆ†æ‰¹å¤„ç†å›¾ç‰‡ï¼ˆGPUä¼˜åŒ–ï¼‰
    total_batches = (len(image_files) + batch_size - 1) // batch_size
    
    for i in range(0, len(image_files), batch_size):
        batch_files = image_files[i:i + batch_size]
        current_batch = i // batch_size + 1
        
        print(f"\nğŸš€ å¤„ç†æ‰¹æ¬¡ {current_batch}/{total_batches} - GPUåŠ é€Ÿæ‰¹å¤„ç†...")
        
        # æ‰¹é‡æ£€æµ‹è½¦ç‰Œ
        batch_results = detect_license_plates_batch(batch_files, model, device, conf_threshold)
        
        # å¤„ç†æ‰¹é‡ç»“æœ
        for result in tqdm(batch_results, desc=f"æ‰¹æ¬¡ {current_batch} è´¨é‡è¯„ä¼°"):
            processed_count += 1
            img_file = result['path']
            img = result['image']
            has_plates = result['has_plates']
            plates_info = result['plates']
            
            if img is None:
                rejected_count += 1
                continue
            
            # è¯„ä¼°æ£€æµ‹åˆ°çš„è½¦ç‰Œè´¨é‡
            valid_plates = []
            if has_plates:
                for plate in plates_info:
                    bbox = plate['bbox']
                    confidence = plate['confidence']
                    
                    # è´¨é‡è¯„ä¼°
                    is_good, quality_result = evaluate_plate_quality(
                        img, bbox, min_sharpness=min_sharpness, min_contrast=min_contrast
                    )
                    
                    if is_good:
                        plate['quality'] = quality_result
                        valid_plates.append(plate)
                        total_plates += 1
            
            # è®°å½•æ£€æµ‹ç»Ÿè®¡
            detection_stats.append({
                'file': img_file.name,
                'detected_plates': len(plates_info) if has_plates else 0,
                'valid_plates': len(valid_plates),
                'selected': len(valid_plates) > 0
            })
            
            if valid_plates:
                selected_count += 1
                
                # å¤åˆ¶/ç§»åŠ¨åŸå›¾åˆ°é€‰ä¸­ç›®å½•ï¼Œä¿æŒåŸå§‹æ ¼å¼å’Œè´¨é‡
                if copy_mode:
                    shutil.copy2(img_file, selected_dir / img_file.name)
                else:
                    shutil.move(str(img_file), selected_dir / img_file.name)
                
                # åˆ›å»ºæ ‡æ³¨å›¾ç‰‡ï¼Œä¿æŒåŸå§‹å°ºå¯¸å’Œè´¨é‡
                annotated_img = img.copy()
                for plate in valid_plates:
                    x1, y1, x2, y2 = plate['bbox']
                    conf = plate['confidence']
                    quality = plate['quality']
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆæ ¹æ®å›¾ç‰‡å¤§å°è°ƒæ•´çº¿æ¡ç²—ç»†ï¼‰
                    line_thickness = max(2, min(img.shape[0], img.shape[1]) // 500)
                    cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), line_thickness)
                    
                    # æ ¹æ®å›¾ç‰‡å°ºå¯¸è°ƒæ•´å­—ä½“å¤§å°
                    font_scale = max(0.5, min(img.shape[0], img.shape[1]) / 1000)
                    font_thickness = max(1, int(font_scale * 2))
                    
                    # æ·»åŠ è¯¦ç»†æ ‡ç­¾
                    label = f"è½¦ç‰Œ {conf:.2f}"
                    quality_label = f"æ¸…æ™°åº¦:{quality['sharpness']:.0f} å¯¹æ¯”åº¦:{quality['contrast']:.0f}"
                    
                    # è®¡ç®—æ–‡å­—ä½ç½®ï¼Œç¡®ä¿åœ¨å›¾ç‰‡èŒƒå›´å†…
                    text_y1 = max(30, y1 - 10)
                    text_y2 = max(50, y1 + 10) if text_y1 == 30 else y1 - 30
                    
                    cv2.putText(annotated_img, label, (x1, text_y1), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), font_thickness)
                    cv2.putText(annotated_img, quality_label, (x1, text_y2), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (0, 255, 0), max(1, font_thickness - 1))
                
                # ä¿å­˜æ ‡æ³¨å›¾ç‰‡ï¼Œä¿æŒåŸå§‹è´¨é‡ï¼ˆæ— å‹ç¼©ï¼‰
                # è·å–åŸå§‹å›¾ç‰‡çš„æ‰©å±•å
                original_ext = img_file.suffix.lower()
                
                if original_ext in ['.jpg', '.jpeg']:
                    # å¯¹äºJPEGæ ¼å¼ï¼Œä½¿ç”¨æœ€é«˜è´¨é‡è®¾ç½®
                    cv2.imwrite(str(annotated_dir / img_file.name), annotated_img, 
                               [cv2.IMWRITE_JPEG_QUALITY, 100])
                elif original_ext == '.png':
                    # å¯¹äºPNGæ ¼å¼ï¼Œä½¿ç”¨æ— æŸå‹ç¼©
                    cv2.imwrite(str(annotated_dir / img_file.name), annotated_img, 
                               [cv2.IMWRITE_PNG_COMPRESSION, 0])
                else:
                    # å…¶ä»–æ ¼å¼ç›´æ¥ä¿å­˜
                    cv2.imwrite(str(annotated_dir / img_file.name), annotated_img)
                
            else:
                rejected_count += 1
                if rejected_dir and not copy_mode:
                    shutil.move(str(img_file), rejected_dir / img_file.name)
        
        # æ˜¾ç¤ºå½“å‰è¿›åº¦å’Œå†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_usage = psutil.virtual_memory().used / (1024**3)
        gpu_info = ""
        if device != 'cpu':
            gpu_memory_used = torch.cuda.memory_allocated() / (1024**3)
            gpu_memory_total = torch.cuda.get_device_properties(device).total_memory / (1024**3)
            gpu_info = f", GPU: {gpu_memory_used:.1f}GB/{gpu_memory_total:.1f}GB"
        
        print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_usage:.1f}GB{gpu_info}")
        print(f"ğŸ“Š å½“å‰è¿›åº¦: å·²å¤„ç† {processed_count}/{len(image_files)} å¼ ï¼Œé€‰ä¸­ {selected_count} å¼ ")
        print(f"âš¡ å½“å‰é€‰ä¸­ç‡: {selected_count/processed_count*100:.1f}%")
        
        # å®šæœŸæ¸…ç†GPUå†…å­˜ï¼ˆä½†ä¸å¼ºåˆ¶é™åˆ¶ï¼‰
        if device != 'cpu' and current_batch % 5 == 0:
            torch.cuda.empty_cache()
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = stats_dir / "detection_stats.txt"
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("GPUä¼˜åŒ–è½¦ç‰Œæ£€æµ‹ç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n")
        f.write(f"å¤„ç†æ—¶é—´: {datetime.datetime.now()}\n")
        f.write(f"å¤„ç†æ¨¡å¼: GPUä¼˜åŒ–æ‰¹å¤„ç†ï¼ˆæ— å†…å­˜é™åˆ¶ï¼‰\n")
        f.write(f"å›¾ç‰‡è´¨é‡: ä¿æŒåŸå§‹å¤§å°å’Œè´¨é‡ï¼ˆæ— å‹ç¼©ï¼‰\n")
        f.write(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
        f.write(f"æ‰¹å¤„ç†å¤§å°: {batch_size}\n")
        f.write(f"æ€»å›¾ç‰‡æ•°: {len(image_files)}\n")
        f.write(f"é€‰ä¸­å›¾ç‰‡: {selected_count}\n")
        f.write(f"æ‹’ç»å›¾ç‰‡: {rejected_count}\n")
        f.write(f"æ£€æµ‹åˆ°è½¦ç‰Œæ€»æ•°: {total_plates}\n")
        f.write(f"é€‰ä¸­ç‡: {selected_count/len(image_files)*100:.1f}%\n")
        f.write(f"æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}\n")
        f.write(f"æ¸…æ™°åº¦é˜ˆå€¼: {min_sharpness}\n")
        f.write(f"å¯¹æ¯”åº¦é˜ˆå€¼: {min_contrast}\n")
        f.write("\nè¯¦ç»†ç»“æœ:\n")
        for stat in detection_stats:
            status = "âœ…" if stat['selected'] else "âŒ"
            f.write(f"{status} {stat['file']}: æ£€æµ‹{stat['detected_plates']}ä¸ªï¼Œæœ‰æ•ˆ{stat['valid_plates']}ä¸ª\n")
    
    print(f"\nğŸ‰ GPUä¼˜åŒ–å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(f"   - æ€»å›¾ç‰‡æ•°ï¼š{len(image_files)}")
    print(f"   - æœ‰è½¦ç‰Œå›¾ç‰‡ï¼š{selected_count}")
    print(f"   - æ— è½¦ç‰Œå›¾ç‰‡ï¼š{rejected_count}")
    print(f"   - æ£€æµ‹åˆ°è½¦ç‰Œæ€»æ•°ï¼š{total_plates}")
    print(f"   - é€‰ä¸­ç‡ï¼š{selected_count/len(image_files)*100:.1f}%")
    print(f"   - å¹³å‡æ¯å¼ å›¾ç‰‡è½¦ç‰Œæ•°ï¼š{total_plates/selected_count if selected_count > 0 else 0:.1f}")
    print(f"\nğŸ“ è¾“å‡ºç›®å½•ï¼š")
    print(f"   - é€‰ä¸­å›¾ç‰‡ï¼š{selected_dir}")
    print(f"   - æ ‡æ³¨å›¾ç‰‡ï¼š{annotated_dir}")
    print(f"   - ç»Ÿè®¡æ–‡ä»¶ï¼š{stats_file}")
    if rejected_dir:
        print(f"   - æ‹’ç»å›¾ç‰‡ï¼š{rejected_dir}")

def main():
    parser = argparse.ArgumentParser(description="GPUä¼˜åŒ–è½¦ç‰Œæ£€æµ‹è„šæœ¬ - æ— å†…å­˜é™åˆ¶")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡ç›®å½•")
    parser.add_argument("--output", "-o", default="./license_plate_results_gpu", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--conf", type=float, default=0.3, help="è½¦ç‰Œæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)")
    parser.add_argument("--sharpness", type=float, default=50, help="æœ€å°æ¸…æ™°åº¦é˜ˆå€¼")
    parser.add_argument("--contrast", type=float, default=15, help="æœ€å°å¯¹æ¯”åº¦é˜ˆå€¼")
    parser.add_argument("--copy", action="store_true", help="å¤åˆ¶æ¨¡å¼ï¼ˆé»˜è®¤ç§»åŠ¨æ¨¡å¼ï¼‰")
    parser.add_argument("--no_gpu", action="store_true", help="ç¦ç”¨GPUï¼Œå¼ºåˆ¶ä½¿ç”¨CPU")
    parser.add_argument("--gpu_id", type=int, default=None, help="æŒ‡å®šä½¿ç”¨çš„GPU ID (0, 1, 2...)")
    parser.add_argument("--batch_size", type=int, default=128, help="GPUä¼˜åŒ–æ‰¹å¤„ç†å¤§å°ï¼ˆæ¨è128-256ï¼‰")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    gpu_available = check_gpu_availability()
    use_gpu = gpu_available and not args.no_gpu
    
    # æ˜¾ç¤ºåˆå§‹å†…å­˜çŠ¶æ€
    initial_memory = psutil.virtual_memory().used / (1024**3)
    print(f"ğŸš€ å¼€å§‹GPUä¼˜åŒ–å¤„ç†ï¼Œå½“å‰å†…å­˜ä½¿ç”¨: {initial_memory:.1f}GB")
    
    if use_gpu:
        print("âš¡ å¯ç”¨GPUåŠ é€Ÿæ¨¡å¼ - æ— å†…å­˜é™åˆ¶")
        # è®¾ç½®PyTorch GPUä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
    else:
        print("ğŸ’» ä½¿ç”¨CPUæ¨¡å¼")
    
    try:
        # åŠ è½½ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        model, device = load_license_plate_model(use_gpu, args.gpu_id)
        
        # å¤„ç†å›¾ç‰‡
        process_images(
            input_dir=args.input,
            output_dir=args.output,
            model=model,
            device=device,
            conf_threshold=args.conf,
            min_sharpness=args.sharpness,
            min_contrast=args.contrast,
            copy_mode=args.copy,
            batch_size=args.batch_size
        )
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†GPUå†…å­˜
        if use_gpu:
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPUå†…å­˜æ¸…ç†å®Œæˆ")

if __name__ == "__main__":
    main()
