#!/usr/bin/env python3
"""
ä½¿ç”¨ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹ license_plate_detector.pt æŒ‘é€‰æœ‰è½¦ç‰Œçš„å›¾ç‰‡
ä¸“é—¨é’ˆå¯¹è½¦ç‰Œæ£€æµ‹è¿›è¡Œä¼˜åŒ–ï¼Œæä¾›æ›´é«˜çš„æ£€æµ‹ç²¾åº¦
"""

import os
import cv2
import shutil
import argparse
import gc
import psutil
import torch
import datetime
from pathlib import Path
from ultralytics import YOLO
import numpy as np
from tqdm import tqdm

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else "Unknown"
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3) if gpu_count > 0 else 0
        print(f"ğŸš€ æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU: {gpu_name} ({gpu_memory:.1f}GB)")
        return True
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°å¯ç”¨çš„GPUï¼Œå°†ä½¿ç”¨CPU")
        return False

def load_license_plate_model(use_gpu=True, gpu_id=None):
    """åŠ è½½ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹"""
    # æŸ¥æ‰¾ license_plate_detector.pt æ¨¡å‹
    model_paths = [
        './license_plate_detector.pt',
        './models/license_plate_detector.pt',
        './Automatic-License-Plate-Recognition-using-YOLOv8/license_plate_detector.pt',
        '../Automatic-License-Plate-Recognition-using-YOLOv8/license_plate_detector.pt',
    ]
    
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print("âŒ æœªæ‰¾åˆ° license_plate_detector.pt æ¨¡å‹æ–‡ä»¶")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€ï¼š")
        for path in model_paths:
            print(f"   - {path}")
        raise FileNotFoundError("license_plate_detector.pt not found")
    
    print(f"ğŸ¯ åŠ è½½ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹: {model_path}")
    model = YOLO(model_path)
    
    # è®¾ç½®è®¾å¤‡
    if use_gpu and torch.cuda.is_available():
        if gpu_id is not None:
            device = f'cuda:{gpu_id}'
            print(f"ğŸ¯ æŒ‡å®šä½¿ç”¨GPU {gpu_id}")
        else:
            device = 'cuda'
        
        try:
            model.to(device)
            gpu_name = torch.cuda.get_device_name(device)
            gpu_memory = torch.cuda.get_device_properties(device).total_memory / (1024**3)
            gpu_used = torch.cuda.memory_allocated(device) / (1024**3)
            print(f"ğŸš€ æ¨¡å‹å·²åŠ è½½åˆ°{device}: {gpu_name}")
            print(f"ğŸ’¾ GPUå†…å­˜: {gpu_used:.1f}GB / {gpu_memory:.1f}GB")
            
            # GPUé¢„çƒ­
            print("ğŸ”¥ GPUé¢„çƒ­ä¸­...")
            dummy_img = torch.randn(1, 3, 640, 640).to(device)
            with torch.no_grad():
                _ = model(dummy_img, verbose=False)
            del dummy_img
            torch.cuda.empty_cache()
            print("âœ… GPUé¢„çƒ­å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ GPUåŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°CPU: {e}")
            device = 'cpu'
            model.to(device)
    else:
        device = 'cpu'
        print("ğŸ’» ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
    
    return model, device

def calculate_sharpness(image_region):
    """è®¡ç®—å›¾åƒåŒºåŸŸçš„æ¸…æ™°åº¦"""
    gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
    return cv2.Laplacian(gray, cv2.CV_64F).var()

def calculate_contrast(image_region):
    """è®¡ç®—å›¾åƒåŒºåŸŸçš„å¯¹æ¯”åº¦"""
    gray = cv2.cvtColor(image_region, cv2.COLOR_BGR2GRAY) if len(image_region.shape) == 3 else image_region
    return gray.std()

def evaluate_plate_quality(img, bbox, min_width=60, min_height=15, min_sharpness=50, min_contrast=15):
    """è¯„ä¼°è½¦ç‰Œè´¨é‡"""
    x1, y1, x2, y2 = bbox
    width = x2 - x1
    height = y2 - y1
    
    # åŸºæœ¬å°ºå¯¸æ£€æŸ¥
    if width < min_width or height < min_height:
        return False, f"å°ºå¯¸è¿‡å°: {width}x{height}"
    
    # é•¿å®½æ¯”æ£€æŸ¥ï¼ˆè½¦ç‰Œé€šå¸¸æ˜¯æ¨ªå‘çš„ï¼‰
    aspect_ratio = width / height
    if aspect_ratio < 1.5 or aspect_ratio > 8:
        return False, f"é•¿å®½æ¯”å¼‚å¸¸: {aspect_ratio:.2f}"
    
    # æå–è½¦ç‰ŒåŒºåŸŸ
    plate_region = img[y1:y2, x1:x2]
    if plate_region.size == 0:
        return False, "è½¦ç‰ŒåŒºåŸŸä¸ºç©º"
    
    # è®¡ç®—æ¸…æ™°åº¦å’Œå¯¹æ¯”åº¦
    sharpness = calculate_sharpness(plate_region)
    contrast = calculate_contrast(plate_region)
    
    # è´¨é‡æ£€æŸ¥
    if sharpness < min_sharpness:
        return False, f"æ¸…æ™°åº¦ä¸è¶³: {sharpness:.1f} < {min_sharpness}"
    
    if contrast < min_contrast:
        return False, f"å¯¹æ¯”åº¦ä¸è¶³: {contrast:.1f} < {min_contrast}"
    
    return True, {
        "width": width,
        "height": height,
        "aspect_ratio": aspect_ratio,
        "sharpness": sharpness,
        "contrast": contrast,
        "area": width * height
    }

def detect_license_plates(image_path, model, device, conf_threshold=0.3):
    """æ£€æµ‹å›¾ç‰‡ä¸­çš„è½¦ç‰Œ"""
    img = cv2.imread(str(image_path))
    if img is None:
        return False, [], None
    
    try:
        # ä½¿ç”¨ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        results = model(img, conf=conf_threshold, device=device, verbose=False)
        
        detected_plates = []
        
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œç½®ä¿¡åº¦
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    
                    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                    x1, y1, x2, y2 = max(0, int(x1)), max(0, int(y1)), min(img.shape[1], int(x2)), min(img.shape[0], int(y2))
                    
                    detected_plates.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(conf)
                    })
        
        return len(detected_plates) > 0, detected_plates, img
    
    except Exception as e:
        print(f"âŒ æ£€æµ‹å¤±è´¥ {image_path}: {e}")
        return False, [], None

def process_images(input_dir, output_dir, model, device, conf_threshold=0.3, 
                  min_sharpness=50, min_contrast=15, copy_mode=True, batch_size=32):
    """å¤„ç†å›¾ç‰‡ç›®å½•ï¼ŒæŒ‘é€‰æœ‰è½¦ç‰Œçš„å›¾ç‰‡"""
    
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºè¾“å‡ºå­ç›®å½•
    selected_dir = output_path / "selected_plates"
    annotated_dir = output_path / "annotated"
    rejected_dir = output_path / "rejected" if not copy_mode else None
    stats_dir = output_path / "stats"
    
    selected_dir.mkdir(exist_ok=True)
    annotated_dir.mkdir(exist_ok=True)
    stats_dir.mkdir(exist_ok=True)
    if rejected_dir:
        rejected_dir.mkdir(exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
    image_files = [f for f in input_path.iterdir() 
                  if f.is_file() and f.suffix.lower() in image_extensions]
    
    if not image_files:
        print("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"ğŸ“ å¤„ç† {len(image_files)} å¼ å›¾ç‰‡ï¼ˆæ‰¹å¤„ç†å¤§å°: {batch_size}ï¼‰...")
    print(f"ğŸ¯ è½¦ç‰Œæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    print(f"ğŸ“ æœ€å°æ¸…æ™°åº¦: {min_sharpness}")
    print(f"ğŸ” æœ€å°å¯¹æ¯”åº¦: {min_contrast}")
    
    selected_count = 0
    rejected_count = 0
    total_plates = 0
    processed_count = 0
    
    # ç”¨äºç»Ÿè®¡çš„æ•°æ®
    detection_stats = []
    
    # åˆ†æ‰¹å¤„ç†å›¾ç‰‡
    for i in range(0, len(image_files), batch_size):
        batch_files = image_files[i:i + batch_size]
        
        print(f"\nğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(image_files) + batch_size - 1)//batch_size}")
        
        for img_file in tqdm(batch_files, desc=f"æ‰¹æ¬¡ {i//batch_size + 1}"):
            processed_count += 1
            
            # å†…å­˜æ£€æŸ¥
            if processed_count % 20 == 0:
                memory_gb = psutil.virtual_memory().used / (1024**3)
                if memory_gb > 100:  # 100GBé˜ˆå€¼
                    print(f"âš ï¸ å†…å­˜ä½¿ç”¨é‡: {memory_gb:.1f}GBï¼Œæ‰§è¡Œåƒåœ¾å›æ”¶...")
                    gc.collect()
                    if device == 'cuda':
                        torch.cuda.empty_cache()
            
            # æ£€æµ‹è½¦ç‰Œ
            has_plates, plates_info, img = detect_license_plates(
                img_file, model, device, conf_threshold
            )
            
            if img is None:
                rejected_count += 1
                continue
            
            # è¯„ä¼°æ£€æµ‹åˆ°çš„è½¦ç‰Œè´¨é‡
            valid_plates = []
            if has_plates:
                for plate in plates_info:
                    bbox = plate['bbox']
                    confidence = plate['confidence']
                    
                    # è´¨é‡è¯„ä¼°
                    is_good, quality_result = evaluate_plate_quality(
                        img, bbox, min_sharpness=min_sharpness, min_contrast=min_contrast
                    )
                    
                    if is_good:
                        plate['quality'] = quality_result
                        valid_plates.append(plate)
                        total_plates += 1
            
            # è®°å½•æ£€æµ‹ç»Ÿè®¡
            detection_stats.append({
                'file': img_file.name,
                'detected_plates': len(plates_info) if has_plates else 0,
                'valid_plates': len(valid_plates),
                'selected': len(valid_plates) > 0
            })
            
            if valid_plates:
                selected_count += 1
                
                # å¤åˆ¶/ç§»åŠ¨åŸå›¾åˆ°é€‰ä¸­ç›®å½•
                if copy_mode:
                    shutil.copy2(img_file, selected_dir / img_file.name)
                else:
                    shutil.move(str(img_file), selected_dir / img_file.name)
                
                # åˆ›å»ºæ ‡æ³¨å›¾ç‰‡
                annotated_img = img.copy()
                for plate in valid_plates:
                    x1, y1, x2, y2 = plate['bbox']
                    conf = plate['confidence']
                    quality = plate['quality']
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                    # æ·»åŠ æ ‡ç­¾
                    label = f"Plate {conf:.2f} S:{quality['sharpness']:.0f} C:{quality['contrast']:.0f}"
                    cv2.putText(annotated_img, label, (x1, y1-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                
                # ä¿å­˜æ ‡æ³¨å›¾ç‰‡
                cv2.imwrite(str(annotated_dir / img_file.name), annotated_img)
                
                print(f"âœ… é€‰ä¸­: {img_file.name} - æ£€æµ‹åˆ°{len(valid_plates)}ä¸ªè½¦ç‰Œ")
                
            else:
                rejected_count += 1
                if rejected_dir:
                    if copy_mode:
                        # åœ¨copyæ¨¡å¼ä¸‹ï¼Œè¢«æ‹’ç»çš„å›¾ç‰‡ä¸ç§»åŠ¨ï¼Œåªè®°å½•
                        pass
                    else:
                        shutil.move(str(img_file), rejected_dir / img_file.name)
            
            # é‡Šæ”¾å›¾åƒå†…å­˜
            del img
            gc.collect()
        
        # æ‰¹æ¬¡å¤„ç†å®Œæˆåæ¸…ç†å†…å­˜
        gc.collect()
        if device == 'cuda':
            torch.cuda.empty_cache()
        
        # æ˜¾ç¤ºå½“å‰è¿›åº¦
        memory_usage = psutil.virtual_memory().used / (1024**3)
        gpu_info = ""
        if device == 'cuda':
            gpu_memory = torch.cuda.memory_allocated() / (1024**3)
            gpu_info = f", GPU: {gpu_memory:.1f}GB"
        
        print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_usage:.1f}GB{gpu_info}")
        print(f"ğŸ“Š å½“å‰è¿›åº¦: å·²å¤„ç† {processed_count}/{len(image_files)} å¼ ï¼Œé€‰ä¸­ {selected_count} å¼ ")
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_file = stats_dir / "detection_stats.txt"
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("è½¦ç‰Œæ£€æµ‹ç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n")
        f.write(f"å¤„ç†æ—¶é—´: {datetime.datetime.now()}\n")
        f.write(f"æ€»å›¾ç‰‡æ•°: {len(image_files)}\n")
        f.write(f"é€‰ä¸­å›¾ç‰‡: {selected_count}\n")
        f.write(f"æ‹’ç»å›¾ç‰‡: {rejected_count}\n")
        f.write(f"æ£€æµ‹åˆ°è½¦ç‰Œæ€»æ•°: {total_plates}\n")
        f.write(f"é€‰ä¸­ç‡: {selected_count/len(image_files)*100:.1f}%\n")
        f.write(f"æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}\n")
        f.write(f"æ¸…æ™°åº¦é˜ˆå€¼: {min_sharpness}\n")
        f.write(f"å¯¹æ¯”åº¦é˜ˆå€¼: {min_contrast}\n")
        f.write("\nè¯¦ç»†ç»“æœ:\n")
        for stat in detection_stats:
            status = "âœ…" if stat['selected'] else "âŒ"
            f.write(f"{status} {stat['file']}: æ£€æµ‹{stat['detected_plates']}ä¸ªï¼Œæœ‰æ•ˆ{stat['valid_plates']}ä¸ª\n")
    
    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(f"   - æ€»å›¾ç‰‡æ•°ï¼š{len(image_files)}")
    print(f"   - æœ‰è½¦ç‰Œå›¾ç‰‡ï¼š{selected_count}")
    print(f"   - æ— è½¦ç‰Œå›¾ç‰‡ï¼š{rejected_count}")
    print(f"   - æ£€æµ‹åˆ°è½¦ç‰Œæ€»æ•°ï¼š{total_plates}")
    print(f"   - é€‰ä¸­ç‡ï¼š{selected_count/len(image_files)*100:.1f}%")
    print(f"\nğŸ“ è¾“å‡ºç›®å½•ï¼š")
    print(f"   - é€‰ä¸­å›¾ç‰‡ï¼š{selected_dir}")
    print(f"   - æ ‡æ³¨å›¾ç‰‡ï¼š{annotated_dir}")
    print(f"   - ç»Ÿè®¡æ–‡ä»¶ï¼š{stats_file}")
    if rejected_dir:
        print(f"   - æ‹’ç»å›¾ç‰‡ï¼š{rejected_dir}")

def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹æŒ‘é€‰æœ‰è½¦ç‰Œçš„å›¾ç‰‡")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥å›¾ç‰‡ç›®å½•")
    parser.add_argument("--output", "-o", default="./license_plate_results", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--conf", type=float, default=0.3, help="è½¦ç‰Œæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ (0-1)")
    parser.add_argument("--sharpness", type=float, default=50, help="æœ€å°æ¸…æ™°åº¦é˜ˆå€¼")
    parser.add_argument("--contrast", type=float, default=15, help="æœ€å°å¯¹æ¯”åº¦é˜ˆå€¼")
    parser.add_argument("--copy", action="store_true", help="å¤åˆ¶æ¨¡å¼ï¼ˆé»˜è®¤ç§»åŠ¨æ¨¡å¼ï¼‰")
    parser.add_argument("--no_gpu", action="store_true", help="ç¦ç”¨GPUï¼Œå¼ºåˆ¶ä½¿ç”¨CPU")
    parser.add_argument("--gpu_id", type=int, default=None, help="æŒ‡å®šä½¿ç”¨çš„GPU ID (0, 1, 2...)")
    parser.add_argument("--batch_size", type=int, default=32, help="æ‰¹å¤„ç†å¤§å°")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    gpu_available = check_gpu_availability()
    use_gpu = gpu_available and not args.no_gpu
    
    # æ˜¾ç¤ºåˆå§‹å†…å­˜çŠ¶æ€
    initial_memory = psutil.virtual_memory().used / (1024**3)
    print(f"ğŸš€ å¼€å§‹å¤„ç†ï¼Œå½“å‰å†…å­˜ä½¿ç”¨: {initial_memory:.1f}GB")
    
    try:
        # åŠ è½½ä¸“ç”¨è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        model, device = load_license_plate_model(use_gpu, args.gpu_id)
        
        # å¤„ç†å›¾ç‰‡
        process_images(
            input_dir=args.input,
            output_dir=args.output,
            model=model,
            device=device,
            conf_threshold=args.conf,
            min_sharpness=args.sharpness,
            min_contrast=args.contrast,
            copy_mode=args.copy,
            batch_size=args.batch_size
        )
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
