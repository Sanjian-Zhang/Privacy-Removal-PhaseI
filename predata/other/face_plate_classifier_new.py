#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨
ä½¿ç”¨æ–°çš„è®¡åˆ†ç³»ç»Ÿï¼š
- ä¸€å¼ æ¸…æ™°æ­£è„¸è®°2åˆ†
- ä¸€å¼ æ¸…æ™°è½¦ç‰Œè®°1åˆ†
- èƒ½å¤ŸOCRè¯†åˆ«çš„æ–‡å­—è®°1åˆ†
- æ€»åˆ†>5åˆ†è®¤ä¸ºç¬¦åˆè¦æ±‚
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm
import logging
import gc
from collections import defaultdict

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åº“"""
    missing_deps = []
    
    try:
        from retinaface import RetinaFace
        print("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    try:
        from ultralytics import YOLO
        print("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    try:
        import easyocr
        print("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    if missing_deps:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        print("è¯·å®‰è£…ç¼ºå°‘çš„åº“:")
        for dep in missing_deps:
            print(f"  pip install {dep}")
        return False
    
    return True

# æ£€æŸ¥ä¾èµ–
if not check_dependencies():
    exit(1)

# æ­£å¼å¯¼å…¥
from retinaface import RetinaFace
from ultralytics import YOLO
import easyocr

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# === å‚æ•°é…ç½® ===
# ç›®å½•é…ç½®
INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames23/output_unique'
OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames23/output_unique/classified_frames23'
PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'

# æ–°è®¡åˆ†ç³»ç»Ÿé˜ˆå€¼
SCORE_THRESHOLD = 5                # æ€»åˆ†é˜ˆå€¼ï¼ˆ>5åˆ†ç¬¦åˆè¦æ±‚ï¼‰
CLEAR_FACE_SCORE = 2              # æ¸…æ™°æ­£è„¸å¾—åˆ†
CLEAR_PLATE_SCORE = 1             # æ¸…æ™°è½¦ç‰Œå¾—åˆ†
TEXT_RECOGNITION_SCORE = 1        # æ–‡å­—è¯†åˆ«å¾—åˆ†

# æ£€æµ‹é˜ˆå€¼
YAW_ANGLE_THRESHOLD = 35.0
MIN_FACE_CONFIDENCE = 0.8
MIN_PLATE_CONFIDENCE = 0.5
MIN_FACE_SIZE = 60
MIN_PLATE_SIZE = 50
MIN_FACE_CLARITY_SCORE = 30.0
MAX_FACE_DISTANCE_RATIO = 0.3
FACE_AREA_THRESHOLD = 3600
MIN_TEXT_CONFIDENCE = 0.5
MIN_TEXT_LENGTH = 3

# å›¾åƒå¤„ç†å‚æ•°
MAX_IMAGE_SIZE = (1280, 720)
SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

# æ€§èƒ½å‚æ•°
VERBOSE_LOGGING = True
GC_FREQUENCY = 100
PROGRESS_UPDATE_FREQUENCY = 50

# è¾“å‡ºç›®å½•
QUALIFIED_DIR = os.path.join(OUTPUT_BASE_DIR, "qualified")         # ç¬¦åˆæ¡ä»¶(æ€»åˆ†>5)
INSUFFICIENT_SCORE_DIR = os.path.join(OUTPUT_BASE_DIR, "insufficient_score")  # åˆ†æ•°ä¸å¤Ÿ
NO_CONTENT_DIR = os.path.join(OUTPUT_BASE_DIR, "no_content")       # æ— ä»»ä½•æœ‰æ•ˆå†…å®¹
ANALYSIS_DIR = os.path.join(OUTPUT_BASE_DIR, "analysis")           # åˆ†æç»“æœ

class FacePlateClassifier:
    """æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ï¼ˆæ–°è®¡åˆ†ç³»ç»Ÿï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        self.start_time = time.time()
        self.stats = {
            'qualified': 0,           # ç¬¦åˆæ¡ä»¶(æ€»åˆ†>5)
            'insufficient_score': 0,  # åˆ†æ•°ä¸å¤Ÿ
            'no_content': 0,          # æ— ä»»ä½•æœ‰æ•ˆå†…å®¹
            'failed': 0               # å¤„ç†å¤±è´¥
        }
        
        # è¯¦ç»†åˆ†æç»“æœ
        self.analysis_results = []
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_output_dirs()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        # åˆå§‹åŒ–OCR
        self._initialize_ocr()
        
        logger.info("ğŸš€ æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆï¼ˆæ–°è®¡åˆ†ç³»ç»Ÿï¼‰")
    
    def _create_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        dirs = [QUALIFIED_DIR, INSUFFICIENT_SCORE_DIR, NO_CONTENT_DIR, ANALYSIS_DIR]
        
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
            logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹"""
        try:
            # æµ‹è¯•RetinaFace
            logger.info("ğŸ” åˆå§‹åŒ–RetinaFaceæ¨¡å‹...")
            test_img = np.ones((100, 100, 3), dtype=np.uint8) * 128
            RetinaFace.detect_faces(test_img)
            logger.info("âœ… RetinaFaceæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹
            logger.info("ğŸš— åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
            if not os.path.exists(PLATE_MODEL_PATH):
                raise FileNotFoundError(f"è½¦ç‰Œæ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {PLATE_MODEL_PATH}")
            
            self.plate_model = YOLO(PLATE_MODEL_PATH)
            logger.info("âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _initialize_ocr(self):
        """åˆå§‹åŒ–OCRæ¨¡å‹"""
        try:
            logger.info("ğŸ“ åˆå§‹åŒ–EasyOCRæ¨¡å‹...")
            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'])  # æ”¯æŒä¸­æ–‡ç®€ä½“å’Œè‹±æ–‡
            logger.info("âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ OCRæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ocr_reader = None
    
    def calculate_face_clarity(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """è®¡ç®—äººè„¸åŒºåŸŸçš„æ¸…æ™°åº¦"""
        try:
            x1, y1, x2, y2 = bbox
            h, w = image.shape[:2]
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w, int(x2)), min(h, int(y2))
            
            if x2 <= x1 or y2 <= y1:
                return 0.0
            
            face_region = image[y1:y2, x1:x2]
            if face_region.size == 0:
                return 0.0
            
            if len(face_region.shape) == 3:
                gray_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_region
            
            # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è®¡ç®—æ¸…æ™°åº¦
            laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
            
            # é¢å¤–çš„æ¸…æ™°åº¦æŒ‡æ ‡ï¼šæ¢¯åº¦å¹…å€¼
            grad_x = cv2.Sobel(gray_face, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray_face, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            gradient_mean = np.mean(gradient_magnitude)
            
            # ç»¼åˆæ¸…æ™°åº¦åˆ†æ•°
            clarity_score = laplacian_var + gradient_mean * 0.1
            
            return float(clarity_score)
            
        except Exception as e:
            logger.debug(f"æ¸…æ™°åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0
            
            horizontal_offset = nose[0] - eye_center[0]
            normalized_offset = horizontal_offset / eye_width
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0
    
    def is_face_clear_and_close(self, image: np.ndarray, bbox: Tuple[int, int, int, int], img_size: Tuple[int, int]) -> Tuple[bool, Dict]:
        """åˆ¤æ–­äººè„¸æ˜¯å¦æ¸…æ™°ä¸”è·ç¦»åˆé€‚"""
        try:
            clarity_score = self.calculate_face_clarity(image, bbox)
            
            x1, y1, x2, y2 = bbox
            face_area = (x2 - x1) * (y2 - y1)
            img_width, img_height = img_size
            img_area = img_width * img_height
            distance_score = face_area / img_area
            
            is_clear = clarity_score >= MIN_FACE_CLARITY_SCORE
            is_close = distance_score >= MAX_FACE_DISTANCE_RATIO
            is_large_enough = face_area >= FACE_AREA_THRESHOLD
            
            is_good_quality = is_clear and (is_close or is_large_enough)
            
            quality_info = {
                'clarity_score': clarity_score,
                'distance_score': distance_score,
                'face_area': face_area,
                'is_clear': is_clear,
                'is_close': is_close,
                'is_large_enough': is_large_enough,
                'is_good_quality': is_good_quality
            }
            
            return is_good_quality, quality_info
            
        except Exception as e:
            logger.debug(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return False, {'error': str(e)}
    
    def detect_faces(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨RetinaFaceæ£€æµ‹æ¸…æ™°æ­£è„¸"""
        try:
            detections = RetinaFace.detect_faces(image_path)
            
            if not isinstance(detections, dict) or len(detections) == 0:
                return 0, []
            
            img = cv2.imread(image_path)
            if img is None:
                return 0, []
            
            img_height, img_width = img.shape[:2]
            img_size = (img_width, img_height)
            
            clear_frontal_faces = []
            
            for face_key, face_data in detections.items():
                try:
                    confidence = face_data.get('score', 0.0)
                    if confidence < MIN_FACE_CONFIDENCE:
                        continue
                    
                    facial_area = face_data['facial_area']
                    landmarks = face_data.get('landmarks', {})
                    
                    if not landmarks:
                        continue
                    
                    x1, y1, x2, y2 = facial_area
                    face_width = x2 - x1
                    face_height = y2 - y1
                    
                    if min(face_width, face_height) < MIN_FACE_SIZE:
                        continue
                    
                    # æ£€æŸ¥äººè„¸æ¸…æ™°åº¦å’Œè·ç¦»
                    is_good_quality, quality_info = self.is_face_clear_and_close(img, facial_area, img_size)
                    
                    if not is_good_quality:
                        continue
                    
                    # è®¡ç®—yawè§’åº¦
                    yaw_angle = self.calculate_yaw_angle(landmarks)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ­£è„¸
                    is_frontal = yaw_angle <= YAW_ANGLE_THRESHOLD
                    
                    if is_frontal:  # åªè®°å½•æ¸…æ™°çš„æ­£è„¸
                        face_info = {
                            'confidence': confidence,
                            'yaw_angle': yaw_angle,
                            'is_frontal': is_frontal,
                            'facial_area': facial_area,
                            'face_size': (face_width, face_height),
                            'quality_info': quality_info
                        }
                        
                        clear_frontal_faces.append(face_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æäººè„¸å¤±è´¥: {e}")
                    continue
            
            return len(clear_frontal_faces), clear_frontal_faces
            
        except Exception as e:
            logger.debug(f"äººè„¸æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_license_plates(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨YOLOæ£€æµ‹æ¸…æ™°è½¦ç‰Œ"""
        try:
            results = self.plate_model(image_path, verbose=False)
            
            if not results or len(results) == 0:
                return 0, []
            
            result = results[0]
            
            if result.boxes is None or len(result.boxes) == 0:
                return 0, []
            
            clear_plates = []
            
            for box in result.boxes:
                try:
                    confidence = float(box.conf[0])
                    if confidence < MIN_PLATE_CONFIDENCE:
                        continue
                    
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    plate_width = x2 - x1
                    plate_height = y2 - y1
                    
                    if min(plate_width, plate_height) < MIN_PLATE_SIZE:
                        continue
                    
                    plate_info = {
                        'confidence': confidence,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'plate_size': (float(plate_width), float(plate_height))
                    }
                    
                    clear_plates.append(plate_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æè½¦ç‰Œå¤±è´¥: {e}")
                    continue
            
            return len(clear_plates), clear_plates
            
        except Exception as e:
            logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_text(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨OCRæ£€æµ‹å¯è¯†åˆ«çš„æ–‡å­—"""
        try:
            if self.ocr_reader is None:
                return 0, []
            
            img = cv2.imread(image_path)
            if img is None:
                return 0, []
            
            results = self.ocr_reader.readtext(img)
            
            if not results:
                return 0, []
            
            valid_texts = []
            
            for bbox, text, confidence in results:
                try:
                    # ç¡®ä¿confidenceæ˜¯floatç±»å‹
                    confidence = float(confidence) if confidence is not None else 0.0
                    
                    if confidence < MIN_TEXT_CONFIDENCE:
                        continue
                    
                    cleaned_text = text.strip()
                    if len(cleaned_text) < MIN_TEXT_LENGTH:
                        continue
                    
                    # è¿‡æ»¤æ‰åªåŒ…å«ç¬¦å·çš„æ–‡å­—
                    if cleaned_text.replace(' ', '').replace('.', '').replace('-', '').replace('_', ''):
                        text_info = {
                            'text': cleaned_text,
                            'confidence': confidence,
                            'bbox': bbox
                        }
                        valid_texts.append(text_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†ææ–‡å­—å¤±è´¥: {e}")
                    continue
            
            return len(valid_texts), valid_texts
            
        except Exception as e:
            logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def classify_image(self, image_path: str) -> Tuple[str, Dict]:
        """ä½¿ç”¨æ–°è®¡åˆ†ç³»ç»Ÿåˆ†ç±»å›¾åƒ"""
        try:
            filename = os.path.basename(image_path)
            
            # æ£€æµ‹æ¸…æ™°æ­£è„¸
            frontal_count, face_details = self.detect_faces(image_path)
            
            # æ£€æµ‹æ¸…æ™°è½¦ç‰Œ
            plate_count, plate_details = self.detect_license_plates(image_path)
            
            # æ£€æµ‹å¯è¯†åˆ«æ–‡å­—
            text_count, text_details = self.detect_text(image_path)
            
            # æ–°è®¡åˆ†ç³»ç»Ÿ
            score = 0
            score_details = []
            
            # æ¸…æ™°æ­£è„¸ï¼šæ¯å¼ 2åˆ†
            if frontal_count > 0:
                face_score = frontal_count * CLEAR_FACE_SCORE
                score += face_score
                score_details.append(f"æ¸…æ™°æ­£è„¸ {frontal_count} å¼  Ã— {CLEAR_FACE_SCORE} = {face_score} åˆ†")
            
            # æ¸…æ™°è½¦ç‰Œï¼šæ¯å¼ 1åˆ†
            if plate_count > 0:
                plate_score = plate_count * CLEAR_PLATE_SCORE
                score += plate_score
                score_details.append(f"æ¸…æ™°è½¦ç‰Œ {plate_count} å¼  Ã— {CLEAR_PLATE_SCORE} = {plate_score} åˆ†")
            
            # å¯è¯†åˆ«æ–‡å­—ï¼š1åˆ†ï¼ˆæ— è®ºå¤šå°‘æ®µï¼‰
            if text_count > 0:
                text_score = TEXT_RECOGNITION_SCORE
                score += text_score
                score_details.append(f"å¯è¯†åˆ«æ–‡å­— = {text_score} åˆ†")
            
            # åˆ¤æ–­æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼ˆæ€»åˆ†>5ï¼‰
            meets_requirements = score > SCORE_THRESHOLD
            
            # åˆ›å»ºåˆ†æç»“æœ
            analysis = {
                'filename': filename,
                'frontal_faces': frontal_count,
                'license_plates': plate_count,
                'text_count': text_count,
                'total_score': score,
                'score_details': score_details,
                'meets_requirements': meets_requirements,
                'score_threshold': SCORE_THRESHOLD,
                'face_details': face_details,
                'plate_details': plate_details,
                'text_details': text_details,
                'timestamp': time.time()
            }
            
            # åˆ†ç±»é€»è¾‘
            if meets_requirements:
                category = 'qualified'
                analysis['qualification_reason'] = f'æ€»åˆ† {score} åˆ† > {SCORE_THRESHOLD} åˆ†ï¼Œç¬¦åˆè¦æ±‚'
            else:
                if score == 0:
                    category = 'no_content'
                    analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ†ï¼Œæ— ä»»ä½•æœ‰æ•ˆå†…å®¹'
                else:
                    category = 'insufficient_score'
                    analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ† â‰¤ {SCORE_THRESHOLD} åˆ†ï¼Œä¸ç¬¦åˆè¦æ±‚'
            
            analysis['category'] = category
            
            return category, analysis
            
        except Exception as e:
            logger.error(f"âŒ å›¾åƒåˆ†ç±»å¤±è´¥ {image_path}: {e}")
            return 'failed', {'filename': os.path.basename(image_path), 'error': str(e)}
    
    def copy_image_to_category(self, image_path: str, category: str) -> bool:
        """å¤åˆ¶å›¾åƒåˆ°å¯¹åº”åˆ†ç±»ç›®å½•"""
        try:
            filename = os.path.basename(image_path)
            
            category_dirs = {
                'qualified': QUALIFIED_DIR,
                'insufficient_score': INSUFFICIENT_SCORE_DIR,
                'no_content': NO_CONTENT_DIR
            }
            
            if category not in category_dirs:
                return False
            
            output_dir = category_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            shutil.move(image_path, output_path)
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def get_image_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        files = []
        input_path = Path(INPUT_DIR)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
            return []
        
        logger.info(f"ğŸ” æ‰«æç›®å½•: {INPUT_DIR}")
        
        for ext in SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            files.extend(input_path.glob(pattern))
        
        image_files = sorted([str(f) for f in files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
            analysis_file = os.path.join(ANALYSIS_DIR, "classification_analysis.json")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
            summary = {
                'total_processed': len(self.analysis_results),
                'statistics': self.stats.copy(),
                'processing_time': time.time() - self.start_time,
                'scoring_system': {
                    'clear_face_score': CLEAR_FACE_SCORE,
                    'clear_plate_score': CLEAR_PLATE_SCORE,
                    'text_recognition_score': TEXT_RECOGNITION_SCORE,
                    'score_threshold': SCORE_THRESHOLD
                },
                'configuration': {
                    'yaw_angle_threshold': YAW_ANGLE_THRESHOLD,
                    'min_face_confidence': MIN_FACE_CONFIDENCE,
                    'min_plate_confidence': MIN_PLATE_CONFIDENCE,
                    'min_text_confidence': MIN_TEXT_CONFIDENCE
                },
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(ANALYSIS_DIR, "classification_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        total_processed = sum(self.stats.values())
        
        logger.info("="*80)
        logger.info("ğŸ‰ æ­£è„¸å’Œè½¦ç‰Œåˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        logger.info("æ–°çš„è®¡åˆ†ç³»ç»Ÿ:")
        logger.info(f"  - ä¸€å¼ æ¸…æ™°æ­£è„¸ = {CLEAR_FACE_SCORE} åˆ†")
        logger.info(f"  - ä¸€å¼ æ¸…æ™°è½¦ç‰Œ = {CLEAR_PLATE_SCORE} åˆ†")  
        logger.info(f"  - èƒ½è¯†åˆ«çš„æ–‡å­— = {TEXT_RECOGNITION_SCORE} åˆ†")
        logger.info(f"  - æ€»åˆ† > {SCORE_THRESHOLD} åˆ† = ç¬¦åˆè¦æ±‚")
        logger.info(f"âœ… ç¬¦åˆæ¡ä»¶(>{SCORE_THRESHOLD}åˆ†): {self.stats['qualified']:,}")
        logger.info(f"âŒ åˆ†æ•°ä¸å¤Ÿ(â‰¤{SCORE_THRESHOLD}åˆ†): {self.stats['insufficient_score']:,}")
        logger.info(f"âŒ æ— ä»»ä½•å†…å®¹: {self.stats['no_content']:,}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,}")
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,}")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            avg_speed = total_processed / processing_time
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            success_rate = (self.stats['qualified'] / total_processed) * 100
            logger.info(f"ğŸ“ˆ ç¬¦åˆæ¡ä»¶æ¯”ä¾‹: {success_rate:.1f}%")
        
        # æ˜¾ç¤ºå„ç›®å½•æ–‡ä»¶æ•°é‡
        logger.info("\nğŸ“‚ å„åˆ†ç±»ç›®å½•ç»Ÿè®¡:")
        categories = [
            ("ç¬¦åˆæ¡ä»¶", QUALIFIED_DIR),
            ("åˆ†æ•°ä¸å¤Ÿ", INSUFFICIENT_SCORE_DIR),
            ("æ— ä»»ä½•å†…å®¹", NO_CONTENT_DIR)
        ]
        
        for name, dir_path in categories:
            if os.path.exists(dir_path):
                count = len([f for f in os.listdir(dir_path) 
                           if f.lower().endswith(tuple(SUPPORTED_FORMATS))])
                logger.info(f"  ğŸ“ {name}: {count} å¼ å›¾ç‰‡")
        
        logger.info("="*80)
    
    def run(self):
        """è¿è¡Œåˆ†ç±»å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ï¼ˆæ–°è®¡åˆ†ç³»ç»Ÿï¼‰...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_BASE_DIR}")
        logger.info(f"ğŸ“Š è®¡åˆ†è§„åˆ™:")
        logger.info(f"  - æ¸…æ™°æ­£è„¸: {CLEAR_FACE_SCORE} åˆ†/å¼ ")
        logger.info(f"  - æ¸…æ™°è½¦ç‰Œ: {CLEAR_PLATE_SCORE} åˆ†/å¼ ")
        logger.info(f"  - å¯è¯†åˆ«æ–‡å­—: {TEXT_RECOGNITION_SCORE} åˆ†")
        logger.info(f"  - é€šè¿‡é˜ˆå€¼: > {SCORE_THRESHOLD} åˆ†")
        logger.info(f"ğŸ“ yawè§’åº¦é˜ˆå€¼: {YAW_ANGLE_THRESHOLD}Â°")
        logger.info(f"ğŸ¯ äººè„¸ç½®ä¿¡åº¦é˜ˆå€¼: {MIN_FACE_CONFIDENCE}")
        logger.info(f"ğŸ¯ è½¦ç‰Œç½®ä¿¡åº¦é˜ˆå€¼: {MIN_PLATE_CONFIDENCE}")
        logger.info(f"ğŸ¯ æ–‡å­—è¯†åˆ«ç½®ä¿¡åº¦é˜ˆå€¼: {MIN_TEXT_CONFIDENCE}")
        logger.info(f"ğŸ” æœ€å°æ¸…æ™°åº¦åˆ†æ•°: {MIN_FACE_CLARITY_SCORE}")
        logger.info(f"ğŸ“ æœ€å°äººè„¸é¢ç§¯: {FACE_AREA_THRESHOLD}pxÂ²")
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files()
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return
        
        # å¼€å§‹å¤„ç†
        try:
            with tqdm(
                total=len(image_files),
                desc="åˆ†ç±»è¿›åº¦",
                ncols=120,
                bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
            ) as pbar:
                
                for i, image_path in enumerate(image_files):
                    try:
                        # åˆ†ç±»å›¾åƒ
                        category, analysis = self.classify_image(image_path)
                        
                        if category != 'failed':
                            # å¤åˆ¶åˆ°å¯¹åº”ç›®å½•
                            if self.copy_image_to_category(image_path, category):
                                self.stats[category] += 1
                            else:
                                self.stats['failed'] += 1
                                analysis['copy_failed'] = True
                        else:
                            self.stats['failed'] += 1
                        
                        # ä¿å­˜åˆ†æç»“æœ
                        self.analysis_results.append(analysis)
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        pbar.update(1)
                        
                        # æ›´æ–°æè¿°
                        if i % PROGRESS_UPDATE_FREQUENCY == 0 and i > 0:
                            stats_str = f"âœ…{self.stats['qualified']} âŒ{self.stats['insufficient_score']} â­•{self.stats['no_content']}"
                            pbar.set_description(f"åˆ†ç±»è¿›åº¦ ({stats_str})")
                        
                        # å®šæœŸå†…å­˜æ¸…ç†
                        if i % GC_FREQUENCY == 0 and i > 0:
                            gc.collect()
                    
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
                        self.stats['failed'] += 1
                        pbar.update(1)
        
        finally:
            # ä¿å­˜ç»“æœå’Œç»Ÿè®¡
            self.save_analysis_results()
            self.print_final_statistics()

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(INPUT_DIR):
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
            return
        
        # æ£€æŸ¥è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        if not os.path.exists(PLATE_MODEL_PATH):
            logger.error(f"âŒ è½¦ç‰Œæ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {PLATE_MODEL_PATH}")
            return
        
        # åˆ›å»ºåˆ†ç±»å™¨å¹¶è¿è¡Œ
        classifier = FacePlateClassifier()
        classifier.run()
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
