#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ YOLOv8s æ¨¡å‹è¿›è¡Œäººè„¸æ£€æµ‹å’Œæ•°é‡åˆ†ç±»
ä¸“é—¨é’ˆå¯¹ /home/zhiqics/sanjian/predata/models/yolov8s.pt æ¨¡å‹ä¼˜åŒ–
"""

import os
import cv2
import shutil
import torch
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict
import logging
from datetime import datetime
import math

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ£€æŸ¥ä¾èµ–åº“
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    logger.info("âœ… ultralytics åº“å¯ç”¨")
except ImportError:
    YOLO_AVAILABLE = False
    logger.error("âŒ ultralytics åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install ultralytics")
    exit(1)


class YOLOv8sFaceClassifier:
    """ä½¿ç”¨ YOLOv8s æ¨¡å‹è¿›è¡Œäººè„¸æ£€æµ‹å’Œåˆ†ç±»ï¼ŒåŒ…å«äººè„¸è´¨é‡è¯„ä¼°"""
    
    def __init__(self, 
                 model_path: str = "/home/zhiqics/sanjian/predata/models/yolov8s.pt",
                 min_face_size: int = 30,
                 confidence_threshold: float = 0.25,
                 iou_threshold: float = 0.45,
                 use_gpu: bool = True,
                 face_quality_threshold: float = 0.6,  # äººè„¸è´¨é‡é˜ˆå€¼
                 filter_side_faces: bool = True,       # æ˜¯å¦è¿‡æ»¤ä¾§è„¸
                 filter_blurry_faces: bool = True):    # æ˜¯å¦è¿‡æ»¤æ¨¡ç³Šäººè„¸
        """
        åˆå§‹åŒ– YOLOv8s äººè„¸åˆ†ç±»å™¨
        
        Args:
            model_path: YOLOv8s æ¨¡å‹è·¯å¾„
            min_face_size: æœ€å°äººè„¸å°ºå¯¸ (åƒç´ )
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IoU é˜ˆå€¼ï¼Œç”¨äºéæå¤§å€¼æŠ‘åˆ¶
            use_gpu: æ˜¯å¦ä½¿ç”¨ GPU
            face_quality_threshold: äººè„¸è´¨é‡é˜ˆå€¼ (0-1)
            filter_side_faces: æ˜¯å¦è¿‡æ»¤ä¾§è„¸å’Œåè„‘å‹º
            filter_blurry_faces: æ˜¯å¦è¿‡æ»¤æ¨¡ç³Šäººè„¸
        """
        self.model_path = model_path
        self.min_face_size = min_face_size
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.use_gpu = use_gpu
        self.face_quality_threshold = face_quality_threshold
        self.filter_side_faces = filter_side_faces
        self.filter_blurry_faces = filter_blurry_faces
        
        # è®¾å¤‡æ£€æŸ¥å’Œé…ç½®
        self.device = self._setup_device()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._load_model()
        
        # åˆå§‹åŒ–äººè„¸è´¨é‡è¯„ä¼°å™¨
        self._init_face_quality_detectors()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'no_faces': 0,
            'single_face': 0,
            'few_faces': 0,  # 2-3 å¼ äººè„¸
            'many_faces': 0,  # 4+ å¼ äººè„¸
            'errors': 0,
            'filtered_low_quality': 0,  # è¢«è´¨é‡è¿‡æ»¤å™¨è¿‡æ»¤çš„äººè„¸æ•°é‡
            'filtered_side_faces': 0,   # è¢«ä¾§è„¸è¿‡æ»¤å™¨è¿‡æ»¤çš„æ•°é‡
            'filtered_blurry': 0        # è¢«æ¨¡ç³Šè¿‡æ»¤å™¨è¿‡æ»¤çš„æ•°é‡
        }
    
    def _setup_device(self) -> str:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if self.use_gpu and torch.cuda.is_available():
            try:
                # æµ‹è¯• CUDA
                test_tensor = torch.tensor([1.0]).cuda()
                device = 'cuda'
                logger.info(f"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name(0)}")
                del test_tensor
            except Exception as e:
                logger.warning(f"âš ï¸  GPU ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ° CPU: {e}")
                device = 'cpu'
        else:
            device = 'cpu'
            logger.info("ğŸ“± ä½¿ç”¨ CPU è¿›è¡Œæ¨ç†")
        
        return device
    
    def _init_face_quality_detectors(self):
        """åˆå§‹åŒ–äººè„¸è´¨é‡è¯„ä¼°å™¨"""
        try:
            # åˆå§‹åŒ– OpenCV çš„äººè„¸æ£€æµ‹å™¨ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰
            self.face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'  # type: ignore
            )
            self.profile_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_profileface.xml'  # type: ignore
            )
            
            logger.info("âœ… äººè„¸è´¨é‡è¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  äººè„¸è´¨é‡è¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.filter_side_faces = False
    
    def _calculate_face_quality(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Dict[str, float]:
        """
        è®¡ç®—äººè„¸è´¨é‡åˆ†æ•°
        
        Args:
            image: åŸå§‹å›¾åƒ
            bbox: äººè„¸è¾¹ç•Œæ¡† (x1, y1, x2, y2)
            
        Returns:
            dict: åŒ…å«å„ç§è´¨é‡æŒ‡æ ‡çš„å­—å…¸
        """
        x1, y1, x2, y2 = bbox
        face_img = image[y1:y2, x1:x2]
        
        if face_img.size == 0:
            return {'overall_quality': 0.0, 'sharpness': 0.0, 'brightness': 0.0, 'contrast': 0.0}
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(face_img.shape) == 3:
            face_gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        else:
            face_gray = face_img
        
        # 1. æ¸…æ™°åº¦è¯„ä¼°ï¼ˆæ‹‰æ™®æ‹‰æ–¯ç®—å­ï¼‰
        laplacian_var = cv2.Laplacian(face_gray, cv2.CV_64F).var()
        sharpness_score = min(laplacian_var / 500.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
        
        # 2. äº®åº¦è¯„ä¼°
        mean_brightness = np.mean(face_gray)
        # ç†æƒ³äº®åº¦èŒƒå›´ 80-180
        if 80 <= mean_brightness <= 180:
            brightness_score = 1.0
        else:
            brightness_score = max(0.0, 1.0 - abs(mean_brightness - 130) / 130.0)
        
        # 3. å¯¹æ¯”åº¦è¯„ä¼°
        contrast = np.std(face_gray)
        contrast_score = min(contrast / 60.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
        
        # 4. ç»¼åˆè´¨é‡åˆ†æ•°
        overall_quality = (sharpness_score * 0.5 + brightness_score * 0.2 + contrast_score * 0.3)
        
        return {
            'overall_quality': float(overall_quality),
            'sharpness': float(sharpness_score),
            'brightness': float(brightness_score),
            'contrast': float(contrast_score)
        }
    
    def _is_frontal_face(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[bool, float]:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºæ­£é¢äººè„¸ï¼Œè¿‡æ»¤ä¾§è„¸å’Œåè„‘å‹º
        
        Args:
            image: åŸå§‹å›¾åƒ
            bbox: äººè„¸è¾¹ç•Œæ¡† (x1, y1, x2, y2)
            
        Returns:
            tuple: (æ˜¯å¦ä¸ºæ­£é¢äººè„¸, æ­£é¢ç¨‹åº¦åˆ†æ•°)
        """
        if not self.filter_side_faces:
            return True, 1.0
        
        x1, y1, x2, y2 = bbox
        face_img = image[y1:y2, x1:x2]
        
        if face_img.size == 0:
            return False, 0.0
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(face_img.shape) == 3:
            face_gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        else:
            face_gray = face_img
        
        try:
            # ä½¿ç”¨æ­£é¢äººè„¸æ£€æµ‹å™¨
            frontal_faces = self.face_cascade.detectMultiScale(
                face_gray,
                scaleFactor=1.1,
                minNeighbors=3,
                minSize=(20, 20),
                flags=cv2.CASCADE_SCALE_IMAGE
            )
            
            # ä½¿ç”¨ä¾§é¢äººè„¸æ£€æµ‹å™¨
            profile_faces = self.profile_cascade.detectMultiScale(
                face_gray,
                scaleFactor=1.1,
                minNeighbors=3,
                minSize=(20, 20),
                flags=cv2.CASCADE_SCALE_IMAGE
            )
            
            frontal_count = len(frontal_faces)
            profile_count = len(profile_faces)
            
            # å¦‚æœæ£€æµ‹åˆ°æ­£é¢äººè„¸ï¼Œè®¡ç®—æ­£é¢ç¨‹åº¦
            if frontal_count > 0:
                # æ­£é¢äººè„¸æ•°é‡è¶Šå¤šï¼Œæ­£é¢ç¨‹åº¦è¶Šé«˜
                frontal_score = min(1.0, frontal_count / (frontal_count + profile_count + 1))
                
                # å¦‚æœæœ‰ä¾§è„¸æ£€æµ‹ï¼Œé™ä½æ­£é¢ç¨‹åº¦
                if profile_count > 0:
                    frontal_score *= 0.7
                
                # æ­£é¢ç¨‹åº¦å¤§äº0.3æ‰è®¤ä¸ºæ˜¯æ­£é¢
                is_frontal = frontal_score > 0.3
                return is_frontal, frontal_score
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•äººè„¸ç‰¹å¾ï¼Œå¯èƒ½æ˜¯åè„‘å‹ºæˆ–å…¶ä»–
            return False, 0.0
            
        except Exception:
            # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä¿å®ˆåœ°è®¤ä¸ºæ˜¯æ­£é¢
            return True, 0.5
    
    def _assess_face_pose(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Dict[str, float]:
        """
        è¯„ä¼°äººè„¸å§¿æ€ï¼Œæ£€æµ‹æ˜¯å¦ä¸ºåè„‘å‹ºæˆ–æåº¦ä¾§é¢
        
        Args:
            image: åŸå§‹å›¾åƒ
            bbox: äººè„¸è¾¹ç•Œæ¡† (x1, y1, x2, y2)
            
        Returns:
            dict: åŒ…å«å§¿æ€è¯„ä¼°ç»“æœçš„å­—å…¸
        """
        x1, y1, x2, y2 = bbox
        face_img = image[y1:y2, x1:x2]
        
        if face_img.size == 0:
            return {'pose_quality': 0.0, 'is_back_head': True}
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(face_img.shape) == 3:
            face_gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        else:
            face_gray = face_img
        
        # ç®€å•çš„åè„‘å‹ºæ£€æµ‹ï¼šåŸºäºçº¹ç†å’Œè¾¹ç¼˜ç‰¹å¾
        # 1. è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(face_gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # 2. çº¹ç†åˆ†æï¼ˆæ ‡å‡†å·®ï¼‰
        texture_std = np.std(face_gray)
        
        # 3. å¯¹ç§°æ€§æ£€æŸ¥
        h, w = face_gray.shape
        left_half = face_gray[:, :w//2]
        right_half = cv2.flip(face_gray[:, w//2:], 1)
        
        # è°ƒæ•´å°ºå¯¸ä»¥åŒ¹é…
        min_width = min(left_half.shape[1], right_half.shape[1])
        left_half = left_half[:, :min_width]
        right_half = right_half[:, :min_width]
        
        # è®¡ç®—å¯¹ç§°æ€§
        if left_half.shape == right_half.shape:
            symmetry_score = 1.0 - np.mean(np.abs(left_half.astype(float) - right_half.astype(float))) / 255.0
        else:
            symmetry_score = 0.5
        
        # ç»¼åˆåˆ¤æ–­
        # æ­£å¸¸äººè„¸ï¼šè¾¹ç¼˜å¯†åº¦é€‚ä¸­ï¼Œçº¹ç†ä¸°å¯Œï¼Œæœ‰ä¸€å®šå¯¹ç§°æ€§
        # åè„‘å‹ºï¼šè¾¹ç¼˜å¯†åº¦ä½ï¼Œçº¹ç†å•ä¸€ï¼Œå¯¹ç§°æ€§å·®
        
        pose_score = (edge_density * 2 + texture_std / 100.0 + symmetry_score) / 3.0
        pose_score = min(1.0, pose_score)
        
        # é˜ˆå€¼åˆ¤æ–­æ˜¯å¦ä¸ºåè„‘å‹º
        is_back_head = pose_score < 0.3
        
        return {
            'pose_quality': float(pose_score),
            'is_back_head': bool(is_back_head),
            'edge_density': float(edge_density),
            'texture_std': float(texture_std),
            'symmetry_score': float(symmetry_score)
        }
    
    def _load_model(self) -> YOLO:
        """åŠ è½½ YOLOv8s æ¨¡å‹"""
        try:
            if not os.path.exists(self.model_path):
                logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            
            # åŠ è½½æ¨¡å‹
            model = YOLO(self.model_path)
            
            # è®¾ç½®è®¾å¤‡
            model.to(self.device)
            
            logger.info(f"âœ… YOLOv8s æ¨¡å‹åŠ è½½æˆåŠŸ")
            logger.info(f"   ğŸ“ æ¨¡å‹è·¯å¾„: {self.model_path}")
            logger.info(f"   ğŸ–¥ï¸  è¿è¡Œè®¾å¤‡: {self.device}")
            logger.info(f"   ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}")
            logger.info(f"   ğŸ“ æœ€å°äººè„¸å°ºå¯¸: {self.min_face_size}px")
            
            return model
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e
    
    def detect_faces(self, image_path: str) -> Tuple[int, List[Dict]]:
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„äººè„¸ï¼ŒåŒ…å«è´¨é‡è¯„ä¼°å’Œè¿‡æ»¤
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            tuple: (é«˜è´¨é‡äººè„¸æ•°é‡, æ£€æµ‹ç»“æœåˆ—è¡¨)
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                logger.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return 0, []
            
            # è¯»å–å›¾ç‰‡è·å–å°ºå¯¸ä¿¡æ¯
            img = cv2.imread(image_path)
            if img is None:
                logger.error(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
                return 0, []
            
            height, width = img.shape[:2]
            
            # ä½¿ç”¨ YOLOv8s è¿›è¡Œæ¨ç†
            results = self.model(
                image_path,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                device=self.device,
                verbose=False  # å‡å°‘è¾“å‡ºä¿¡æ¯
            )
            
            if not results:
                return 0, []
            
            all_detections = []
            
            # å¤„ç†æ£€æµ‹ç»“æœ
            for result in results:
                if result.boxes is not None and len(result.boxes) > 0:
                    for box in result.boxes:
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = box.conf[0].cpu().numpy()
                        
                        # è®¡ç®—äººè„¸å°ºå¯¸
                        face_width = x2 - x1
                        face_height = y2 - y1
                        
                        # åŸºæœ¬è¿‡æ»¤ï¼šå°ºå¯¸å’Œè¾¹ç¼˜æ£€æŸ¥
                        if (face_width >= self.min_face_size and 
                            face_height >= self.min_face_size and
                            x1 > width * 0.01 and y1 > height * 0.01 and  # ä¸åœ¨å›¾ç‰‡è¾¹ç¼˜
                            x2 < width * 0.99 and y2 < height * 0.99):
                            
                            bbox = (int(x1), int(y1), int(x2), int(y2))
                            
                            # è®¡ç®—äººè„¸è´¨é‡
                            quality_metrics = self._calculate_face_quality(img, bbox)
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸ºæ­£é¢äººè„¸
                            is_frontal, frontal_score = self._is_frontal_face(img, bbox)
                            
                            # è¯„ä¼°äººè„¸å§¿æ€
                            pose_metrics = self._assess_face_pose(img, bbox)
                            
                            # ç»¼åˆè´¨é‡è¯„åˆ†
                            overall_score = (
                                quality_metrics['overall_quality'] * 0.4 +
                                frontal_score * 0.3 +
                                pose_metrics['pose_quality'] * 0.3
                            )
                            
                            detection_info = {
                                'bbox': bbox,
                                'confidence': float(confidence),
                                'width': int(face_width),
                                'height': int(face_height),
                                'area': int(face_width * face_height),
                                'overall_score': overall_score,
                                'quality_metrics': quality_metrics,
                                'frontal_score': frontal_score,
                                'is_frontal': is_frontal,
                                'pose_metrics': pose_metrics,
                                'is_high_quality': False  # å°†åœ¨åé¢è®¾ç½®
                            }
                            
                            all_detections.append(detection_info)
            
            # æŒ‰ç»¼åˆè´¨é‡åˆ†æ•°æ’åº
            all_detections.sort(key=lambda x: x['overall_score'], reverse=True)
            
            # åº”ç”¨è´¨é‡è¿‡æ»¤
            high_quality_faces = []
            filtered_stats = {'low_quality': 0, 'side_faces': 0, 'blurry': 0, 'back_head': 0}
            
            for detection in all_detections:
                should_keep = True
                filter_reasons = []
                
                # 1. ç»¼åˆè´¨é‡æ£€æŸ¥
                if detection['overall_score'] < self.face_quality_threshold:
                    should_keep = False
                    filter_reasons.append('low_overall_quality')
                    filtered_stats['low_quality'] += 1
                
                # 2. ä¾§è„¸è¿‡æ»¤
                if self.filter_side_faces and not detection['is_frontal']:
                    should_keep = False
                    filter_reasons.append('side_face')
                    filtered_stats['side_faces'] += 1
                
                # 3. åè„‘å‹ºè¿‡æ»¤
                if detection['pose_metrics']['is_back_head']:
                    should_keep = False
                    filter_reasons.append('back_head')
                    filtered_stats['back_head'] += 1
                
                # 4. æ¨¡ç³Šåº¦è¿‡æ»¤
                if (self.filter_blurry_faces and 
                    detection['quality_metrics']['sharpness'] < 0.3):
                    should_keep = False
                    filter_reasons.append('blurry')
                    filtered_stats['blurry'] += 1
                
                if should_keep:
                    detection['is_high_quality'] = True
                    high_quality_faces.append(detection)
                else:
                    detection['filter_reasons'] = filter_reasons
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['filtered_low_quality'] += filtered_stats['low_quality']
            self.stats['filtered_side_faces'] += filtered_stats['side_faces']
            self.stats['filtered_blurry'] += filtered_stats['blurry']
            
            logger.debug(f"æ£€æµ‹åˆ° {len(all_detections)} å¼ äººè„¸ï¼Œè¿‡æ»¤åä¿ç•™ {len(high_quality_faces)} å¼ é«˜è´¨é‡äººè„¸")
            
            return len(high_quality_faces), high_quality_faces
            
        except Exception as e:
            logger.error(f"æ£€æµ‹å‡ºé”™ {os.path.basename(image_path)}: {str(e)}")
            return 0, []
    
    def classify_by_face_count(self, face_count: int) -> str:
        """
        æ ¹æ®äººè„¸æ•°é‡è¿›è¡Œåˆ†ç±»
        
        Args:
            face_count: æ£€æµ‹åˆ°çš„äººè„¸æ•°é‡
            
        Returns:
            str: åˆ†ç±»ç±»åˆ«
        """
        if face_count == 0:
            return "no_faces"
        elif face_count == 1:
            return "single_face"
        elif face_count <= 3:
            return "few_faces"  # 2-3 å¼ äººè„¸
        else:
            return "many_faces"  # 4+ å¼ äººè„¸
    
    def test_single_image(self, image_path: str) -> None:
        """æµ‹è¯•å•å¼ å›¾ç‰‡çš„æ£€æµ‹æ•ˆæœï¼Œæ˜¾ç¤ºè¯¦ç»†çš„è´¨é‡è¯„ä¼°ä¿¡æ¯"""
        logger.info(f"ğŸ§ª æµ‹è¯•å›¾ç‰‡: {os.path.basename(image_path)}")
        
        if not os.path.exists(image_path):
            logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return
        
        # æ£€æµ‹äººè„¸
        face_count, detections = self.detect_faces(image_path)
        category = self.classify_by_face_count(face_count)
        
        logger.info(f"ğŸ“Š æ£€æµ‹ç»“æœ:")
        logger.info(f"   ğŸ‘¥ é«˜è´¨é‡äººè„¸æ•°é‡: {face_count}")
        logger.info(f"   ğŸ·ï¸  åˆ†ç±»ç±»åˆ«: {category}")
        
        if face_count > 0:
            logger.info(f"   ğŸ“ è¯¦ç»†ä¿¡æ¯:")
            for i, face in enumerate(detections, 1):
                bbox = face['bbox']
                conf = face['confidence']
                size = f"{face['width']}Ã—{face['height']}"
                area = face['area']
                overall_score = face.get('overall_score', 0)
                
                logger.info(f"      äººè„¸ {i}:")
                logger.info(f"         ä½ç½®: {bbox}")
                logger.info(f"         YOLOç½®ä¿¡åº¦: {conf:.3f}")
                logger.info(f"         ç»¼åˆè´¨é‡åˆ†æ•°: {overall_score:.3f}")
                logger.info(f"         å°ºå¯¸: {size} (é¢ç§¯: {area})")
                
                if 'is_frontal' in face:
                    logger.info(f"         æ˜¯å¦æ­£é¢: {'æ˜¯' if face['is_frontal'] else 'å¦'} (åˆ†æ•°: {face.get('frontal_score', 0):.3f})")
                
                # è´¨é‡æŒ‡æ ‡
                if 'quality_metrics' in face:
                    quality = face['quality_metrics']
                    logger.info(f"         æ¸…æ™°åº¦: {quality['sharpness']:.3f}")
                    logger.info(f"         äº®åº¦: {quality['brightness']:.3f}")
                    logger.info(f"         å¯¹æ¯”åº¦: {quality['contrast']:.3f}")
                
                # å§¿æ€æŒ‡æ ‡
                if 'pose_metrics' in face:
                    pose = face['pose_metrics']
                    logger.info(f"         å§¿æ€è´¨é‡: {pose['pose_quality']:.3f}")
                    logger.info(f"         æ˜¯å¦åè„‘å‹º: {'æ˜¯' if pose['is_back_head'] else 'å¦'}")
                
                if not face.get('is_high_quality', True) and 'filter_reasons' in face:
                    reasons = ', '.join(face['filter_reasons'])
                    logger.info(f"         âš ï¸  è¿‡æ»¤åŸå› : {reasons}")
                
                logger.info("")
        else:
            logger.info("   âŒ æœªæ£€æµ‹åˆ°é«˜è´¨é‡äººè„¸")
        
        # æ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡
        logger.info(f"   ğŸ“ˆ æœ¬æ¬¡è¿‡æ»¤ç»Ÿè®¡:")
        logger.info(f"      è´¨é‡è¿‡æ»¤è®¾ç½®: é˜ˆå€¼={self.face_quality_threshold}, è¿‡æ»¤ä¾§è„¸={self.filter_side_faces}, è¿‡æ»¤æ¨¡ç³Š={self.filter_blurry_faces}")
    
    def process_directory(self, 
                         input_dir: str, 
                         output_dir: str,
                         copy_files: bool = True,
                         create_report: bool = True) -> Dict:
        """
        å¤„ç†æ•´ä¸ªç›®å½•çš„å›¾ç‰‡
        
        Args:
            input_dir: è¾“å…¥ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            copy_files: æ˜¯å¦å¤åˆ¶æ–‡ä»¶åˆ°åˆ†ç±»ç›®å½•
            create_report: æ˜¯å¦åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
            
        Returns:
            dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        categories = {
            "no_faces": output_path / "0_faces" / "no_faces",
            "single_face": output_path / "1_face" / "single_face", 
            "few_faces": output_path / "2-3_faces" / "few_faces",
            "many_faces": output_path / "4+_faces" / "many_faces"
        }
        
        if copy_files:
            for category_path in categories.values():
                category_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {category_path}")
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.JPG', '.JPEG', '.PNG'}
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in image_extensions:
            image_files.extend(input_path.rglob(f'*{ext}'))
        
        if not image_files:
            logger.error(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return {}
        
        logger.info(f"ğŸ“· æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†...")
        
        # è¯¦ç»†å¤„ç†è®°å½•
        processing_log = []
        
        # å¤„ç†æ¯å¼ å›¾ç‰‡
        for i, image_file in enumerate(image_files, 1):
            try:
                logger.info(f"[{i:4d}/{len(image_files)}] å¤„ç†: {image_file.name}")
                
                # æ£€æµ‹äººè„¸
                face_count, detections = self.detect_faces(str(image_file))
                category = self.classify_by_face_count(face_count)
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats['total_processed'] += 1
                if category == "no_faces":
                    self.stats['no_faces'] += 1
                    logger.info(f"   âŒ æ— äººè„¸")
                elif category == "single_face":
                    self.stats['single_face'] += 1
                    logger.info(f"   ğŸ‘¤ å•äººè„¸")
                elif category == "few_faces":
                    self.stats['few_faces'] += 1
                    logger.info(f"   ğŸ‘¥ å°‘é‡äººè„¸ ({face_count} å¼ )")
                else:  # many_faces
                    self.stats['many_faces'] += 1
                    logger.info(f"   ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ å¤šäººè„¸ ({face_count} å¼ )")
                
                # è®°å½•å¤„ç†ç»“æœ
                processing_log.append({
                    'filename': image_file.name,
                    'face_count': face_count,
                    'category': category,
                    'detections': detections
                })
                
                # å¤åˆ¶æ–‡ä»¶åˆ°ç›¸åº”ç›®å½•
                if copy_files and category in categories:
                    dest_dir = categories[category]
                    dest_file = dest_dir / image_file.name
                    
                    # å¤„ç†æ–‡ä»¶åå†²çª
                    counter = 1
                    original_dest = dest_file
                    while dest_file.exists():
                        name_stem = original_dest.stem
                        suffix = original_dest.suffix
                        dest_file = dest_dir / f"{name_stem}_{counter}{suffix}"
                        counter += 1
                    
                    # å¤åˆ¶æ–‡ä»¶ï¼ˆä¿æŒåŸå§‹è´¨é‡ï¼‰
                    shutil.copy2(str(image_file), str(dest_file))
                
            except Exception as e:
                logger.error(f"   âŒ å¤„ç†å‡ºé”™: {str(e)}")
                self.stats['errors'] += 1
                processing_log.append({
                    'filename': image_file.name,
                    'face_count': 0,
                    'category': 'error',
                    'error': str(e)
                })
        
        # åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
        if create_report:
            self._create_report(output_path, processing_log)
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        self._print_final_stats()
        
        return self.stats.copy()
    
    def _create_report(self, output_path: Path, processing_log: List[Dict]) -> None:
        """åˆ›å»ºå¤„ç†æŠ¥å‘Š"""
        report_path = output_path / f"face_classification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("YOLOv8s äººè„¸æ£€æµ‹åˆ†ç±»æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ¨¡å‹è·¯å¾„: {self.model_path}\n")
                f.write(f"ä½¿ç”¨è®¾å¤‡: {self.device}\n")
                f.write(f"ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}\n")
                f.write(f"æœ€å°äººè„¸å°ºå¯¸: {self.min_face_size}px\n")
                f.write("\nç»Ÿè®¡ç»“æœ:\n")
                f.write(f"æ€»å›¾ç‰‡æ•°: {self.stats['total_processed']}\n")
                f.write(f"æ— äººè„¸: {self.stats['no_faces']}\n")
                f.write(f"å•äººè„¸: {self.stats['single_face']}\n")
                f.write(f"å°‘é‡äººè„¸(2-3å¼ ): {self.stats['few_faces']}\n")
                f.write(f"å¤šäººè„¸(4+å¼ ): {self.stats['many_faces']}\n")
                f.write(f"å¤„ç†é”™è¯¯: {self.stats['errors']}\n")
                f.write("\nè¯¦ç»†å¤„ç†è®°å½•:\n")
                f.write("-" * 50 + "\n")
                
                for record in processing_log:
                    f.write(f"æ–‡ä»¶å: {record['filename']}\n")
                    f.write(f"äººè„¸æ•°é‡: {record['face_count']}\n")
                    f.write(f"åˆ†ç±»: {record['category']}\n")
                    
                    if 'error' in record:
                        f.write(f"é”™è¯¯: {record['error']}\n")
                    elif record['detections']:
                        f.write("æ£€æµ‹è¯¦æƒ…:\n")
                        for i, det in enumerate(record['detections'], 1):
                            f.write(f"  äººè„¸{i}: ä½ç½®{det['bbox']}, ç½®ä¿¡åº¦{det['confidence']:.3f}, å°ºå¯¸{det['width']}Ã—{det['height']}\n")
                    
                    f.write("-" * 30 + "\n")
            
            logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _print_final_stats(self) -> None:
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ å¤„ç†å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š æ€»å›¾ç‰‡æ•°: {self.stats['total_processed']}")
        logger.info(f"âŒ æ— äººè„¸å›¾ç‰‡: {self.stats['no_faces']} ({self.stats['no_faces']/max(self.stats['total_processed'],1)*100:.1f}%)")
        logger.info(f"ğŸ‘¤ å•äººè„¸å›¾ç‰‡: {self.stats['single_face']} ({self.stats['single_face']/max(self.stats['total_processed'],1)*100:.1f}%)")
        logger.info(f"ğŸ‘¥ å°‘é‡äººè„¸å›¾ç‰‡(2-3å¼ ): {self.stats['few_faces']} ({self.stats['few_faces']/max(self.stats['total_processed'],1)*100:.1f}%)")
        logger.info(f"ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ å¤šäººè„¸å›¾ç‰‡(4+å¼ ): {self.stats['many_faces']} ({self.stats['many_faces']/max(self.stats['total_processed'],1)*100:.1f}%)")
        logger.info(f"âš ï¸  å¤„ç†é”™è¯¯: {self.stats['errors']}")
        logger.info("=" * 40)
        logger.info("ğŸ” è´¨é‡è¿‡æ»¤ç»Ÿè®¡:")
        logger.info(f"   ğŸš« ä½è´¨é‡è¿‡æ»¤: {self.stats['filtered_low_quality']}")
        logger.info(f"   ğŸš« ä¾§è„¸è¿‡æ»¤: {self.stats['filtered_side_faces']}")
        logger.info(f"   ğŸš« æ¨¡ç³Šè¿‡æ»¤: {self.stats['filtered_blurry']}")
        total_filtered = (self.stats['filtered_low_quality'] + 
                         self.stats['filtered_side_faces'] + 
                         self.stats['filtered_blurry'])
        logger.info(f"   ğŸš« æ€»è¿‡æ»¤æ•°: {total_filtered}")
        logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ YOLOv8s äººè„¸æ£€æµ‹åˆ†ç±»å™¨ (æ”¯æŒè´¨é‡è¿‡æ»¤)")
    logger.info("=" * 50)
    
    # é…ç½®å‚æ•°
    MODEL_PATH = "/home/zhiqics/sanjian/predata/models/yolov8s.pt"
    INPUT_DIR = "/home/zhiqics/sanjian/predata/output_frames22"  # ä¿®æ”¹ä¸ºæ‚¨çš„è¾“å…¥ç›®å½•
    OUTPUT_DIR = "/home/zhiqics/sanjian/predata/face_classification_results"
    
    # æ£€æµ‹å‚æ•°
    MIN_FACE_SIZE = 40              # æœ€å°äººè„¸å°ºå¯¸ (å¢åŠ ä»¥è¿‡æ»¤å°è„¸)
    CONFIDENCE_THRESHOLD = 0.3      # YOLOç½®ä¿¡åº¦é˜ˆå€¼
    IOU_THRESHOLD = 0.45           # IoU é˜ˆå€¼
    USE_GPU = True                 # æ˜¯å¦ä½¿ç”¨ GPU
    
    # è´¨é‡è¿‡æ»¤å‚æ•°
    FACE_QUALITY_THRESHOLD = 0.5   # äººè„¸ç»¼åˆè´¨é‡é˜ˆå€¼ (0-1)
    FILTER_SIDE_FACES = True       # è¿‡æ»¤ä¾§è„¸å’Œåè„‘å‹º
    FILTER_BLURRY_FACES = True     # è¿‡æ»¤æ¨¡ç³Šäººè„¸
    
    logger.info("ğŸ”§ é…ç½®å‚æ•°:")
    logger.info(f"   ğŸ“ æ¨¡å‹è·¯å¾„: {MODEL_PATH}")
    logger.info(f"   ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
    logger.info(f"   ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    logger.info(f"   ğŸ“ æœ€å°äººè„¸å°ºå¯¸: {MIN_FACE_SIZE}px")
    logger.info(f"   ğŸ¯ YOLOç½®ä¿¡åº¦é˜ˆå€¼: {CONFIDENCE_THRESHOLD}")
    logger.info(f"   ğŸ¯ è´¨é‡è¿‡æ»¤é˜ˆå€¼: {FACE_QUALITY_THRESHOLD}")
    logger.info(f"   ğŸš« è¿‡æ»¤ä¾§è„¸: {'æ˜¯' if FILTER_SIDE_FACES else 'å¦'}")
    logger.info(f"   ğŸš« è¿‡æ»¤æ¨¡ç³Š: {'æ˜¯' if FILTER_BLURRY_FACES else 'å¦'}")
    
    # åˆ›å»ºåˆ†ç±»å™¨
    try:
        classifier = YOLOv8sFaceClassifier(
            model_path=MODEL_PATH,
            min_face_size=MIN_FACE_SIZE,
            confidence_threshold=CONFIDENCE_THRESHOLD,
            iou_threshold=IOU_THRESHOLD,
            use_gpu=USE_GPU,
            face_quality_threshold=FACE_QUALITY_THRESHOLD,
            filter_side_faces=FILTER_SIDE_FACES,
            filter_blurry_faces=FILTER_BLURRY_FACES
        )
    except Exception as e:
        logger.error(f"åˆ›å»ºåˆ†ç±»å™¨å¤±è´¥: {e}")
        return
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(INPUT_DIR):
        logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
        logger.info("è¯·ç¡®ä¿è¾“å…¥ç›®å½•å­˜åœ¨å¹¶åŒ…å«å›¾ç‰‡æ–‡ä»¶")
        return
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ–‡ä»¶
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.JPG', '.JPEG', '.PNG'}
    image_files = []
    for ext in image_extensions:
        image_files.extend(Path(INPUT_DIR).rglob(f'*{ext}'))
    
    if not image_files:
        logger.error(f"âŒ åœ¨ {INPUT_DIR} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    logger.info(f"ğŸ“· æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    # æµ‹è¯•ç¬¬ä¸€å¼ å›¾ç‰‡
    if image_files:
        logger.info("\n" + "=" * 40)
        logger.info("ğŸ§ª æµ‹è¯•ç¬¬ä¸€å¼ å›¾ç‰‡")
        logger.info("=" * 40)
        classifier.test_single_image(str(image_files[0]))
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        print("\n" + "=" * 40)
        response = input("â“ æ˜¯å¦ç»§ç»­å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼Ÿ(y/n): ").lower().strip()
        if response not in ['y', 'yes', 'æ˜¯', 'ç»§ç»­']:
            logger.info("ğŸ‘‹ å·²å–æ¶ˆå¤„ç†")
            return
    
    # å¼€å§‹æ‰¹é‡å¤„ç†
    logger.info(f"\nğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    results = classifier.process_directory(
        input_dir=INPUT_DIR,
        output_dir=OUTPUT_DIR,
        copy_files=True,      # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†ç±»ç›®å½•
        create_report=True    # åˆ›å»ºè¯¦ç»†æŠ¥å‘Š
    )
    
    logger.info(f"âœ… å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()
