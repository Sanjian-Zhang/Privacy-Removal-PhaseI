#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨
åŠŸèƒ½è¦æ±‚ï¼š
1. å…ˆç”¨ YOLOv8s è¯†åˆ«å›¾ç‰‡ä¸­äººè„¸æ•°é‡
2. å¦‚æœæ­£è„¸æ•°é‡ä¸æ»¡è¶³4å¼ è¦æ±‚ï¼Œç›´æ¥ç§»åŠ¨åˆ°ç›¸åº”æ–‡ä»¶å¤¹
3. ç”¨æ¡†çš„å¤§å°åˆ¤æ–­è„¸æ˜¯è¿‘æ™¯è¿˜æ˜¯è¿œæ™¯ï¼Œå¿½ç•¥è¿œæ™¯
4. ç”¨ RetinaFace æ£€æµ‹æ­£è„¸
5. åªè¦å›¾ç‰‡ä¸­æœ‰4å¼ è¿‘æ™¯æ­£è„¸ç›´æ¥æ»¡è¶³æ¡ä»¶
6. å¦‚æœå°‘äº4å¼ è¿‘æ™¯æ­£è„¸ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰æ¸…æ™°çš„è½¦ç‰Œå’Œæ–‡å­—
7. è€ƒè™‘GPU0å’Œ1éƒ½å¯ä»¥ä½¿ç”¨
8. å¤„ç†å›¾ç‰‡æ—¶ä¸å‹ç¼©å›¾ç‰‡
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import gc
from collections import defaultdict

# è®¾ç½®ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨å¯¼å…¥æ·±åº¦å­¦ä¹ åº“ä¹‹å‰
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # å¯ç”¨GPU 0å’Œ1
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'     # å‡å°‘TensorFlowæ—¥å¿—è¾“å‡º

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('advanced_face_plate_detector.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–åº“"""
    missing_deps = []
    imported_modules = {}
    
    # æ£€æŸ¥RetinaFace
    try:
        from retinaface import RetinaFace
        imported_modules['RetinaFace'] = RetinaFace
        logger.info("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    # æ£€æŸ¥YOLO
    try:
        from ultralytics import YOLO
        imported_modules['YOLO'] = YOLO
        logger.info("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    # æ£€æŸ¥EasyOCR
    try:
        import easyocr
        imported_modules['easyocr'] = easyocr
        logger.info("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    # æ£€æŸ¥torch
    try:
        import torch
        imported_modules['torch'] = torch
        logger.info("âœ… PyTorch åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ PyTorch åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("torch")
    
    if missing_deps:
        logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        logger.error("è¯·å®‰è£…ç¼ºå°‘çš„åº“:")
        for dep in missing_deps:
            logger.error(f"  pip install {dep}")
        return None
    
    return imported_modules

# æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–
modules = check_dependencies()
if modules is None:
    exit(1)

# ä»æ£€æŸ¥ç»“æœä¸­è·å–æ¨¡å—
RetinaFace = modules['RetinaFace']
YOLO = modules['YOLO']
easyocr = modules['easyocr']
torch = modules['torch']

class Config:
    """é…ç½®ç±»"""
    
    # ç›®å½•é…ç½®
    INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames87'  # è¾“å…¥ç›®å½•
    OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames87'  # è¾“å‡ºåŸºç¡€ç›®å½•
    
    # æ¨¡å‹è·¯å¾„
    YOLOV8S_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/yolov8s.pt'
    LICENSE_PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'
    
    # æ£€æµ‹é˜ˆå€¼
    REQUIRED_CLOSE_FRONTAL_FACES = 4      # éœ€è¦çš„è¿‘æ™¯æ­£è„¸æ•°é‡
    MIN_FACE_CONFIDENCE_YOLO = 0.5        # YOLOäººè„¸æœ€å°ç½®ä¿¡åº¦
    MIN_FACE_CONFIDENCE_RETINA = 0.8      # RetinaFaceæœ€å°ç½®ä¿¡åº¦
    MIN_PLATE_CONFIDENCE = 0.5            # è½¦ç‰Œæœ€å°ç½®ä¿¡åº¦
    MIN_TEXT_CONFIDENCE = 0.5             # æ–‡å­—æœ€å°ç½®ä¿¡åº¦
    YAW_ANGLE_THRESHOLD = 30.0            # yawè§’åº¦é˜ˆå€¼ï¼ˆæ­£è„¸ï¼‰
    
    # è¿‘æ™¯åˆ¤æ–­å‚æ•°
    MIN_FACE_SIZE = 80                    # æœ€å°äººè„¸å°ºå¯¸ï¼ˆåƒç´ ï¼‰
    CLOSE_UP_FACE_RATIO = 0.08           # è¿‘æ™¯äººè„¸æœ€å°é¢ç§¯æ¯”ä¾‹
    MIN_FACE_AREA = 6400                 # æœ€å°äººè„¸é¢ç§¯ï¼ˆ80x80ï¼‰
    
    # å›¾åƒè´¨é‡ä¿æŠ¤
    PRESERVE_IMAGE_QUALITY = True
    IMAGE_READ_FLAGS = cv2.IMREAD_COLOR
    JPEG_QUALITY = 100
    PNG_COMPRESSION = 0
    
    # GPUé…ç½®
    USE_GPU = True
    PREFERRED_GPU = 0                     # ä¼˜å…ˆä½¿ç”¨GPU 0
    FALLBACK_GPU = 1                      # å¤‡ç”¨GPU 1
    
    # æ–‡ä»¶æ ¼å¼
    SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
    
    # æ€§èƒ½å‚æ•°
    GC_FREQUENCY = 50
    PROGRESS_UPDATE_FREQUENCY = 25
    MAX_PROCESSING_TIME_PER_IMAGE = 60
    
    @classmethod
    def get_output_dirs(cls):
        """è·å–è¾“å‡ºç›®å½•é…ç½®"""
        return {
            'satisfied_4_faces': os.path.join(cls.OUTPUT_BASE_DIR, "satisfied_4_close_frontal_faces"),
            'satisfied_with_plate': os.path.join(cls.OUTPUT_BASE_DIR, "satisfied_with_plate_text"),
            'insufficient_faces': os.path.join(cls.OUTPUT_BASE_DIR, "insufficient_faces"),
            'no_faces': os.path.join(cls.OUTPUT_BASE_DIR, "no_faces"),
            'analysis': os.path.join(cls.OUTPUT_BASE_DIR, "analysis"),
        }

class AdvancedFacePlateDetector:
    """é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨"""
    
    def __init__(self, config: Optional[Config] = None):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        self.config = config or Config()
        self.start_time = time.time()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'satisfied_4_faces': 0,        # 4å¼ è¿‘æ™¯æ­£è„¸æ»¡è¶³æ¡ä»¶
            'satisfied_with_plate': 0,     # é€šè¿‡è½¦ç‰Œ/æ–‡å­—æ»¡è¶³æ¡ä»¶
            'insufficient_faces': 0,       # äººè„¸ä¸å¤Ÿ
            'no_faces': 0,                 # æ— äººè„¸
            'failed': 0,                   # å¤„ç†å¤±è´¥
        }
        
        # è¯¦ç»†åˆ†æç»“æœ
        self.analysis_results = []
        
        # è·å–è¾“å‡ºç›®å½•
        self.output_dirs = self.config.get_output_dirs()
        
        # è®¾å¤‡é…ç½®
        self.device = self._setup_device()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_output_dirs()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        logger.info("ğŸš€ é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“¸ å›¾åƒè´¨é‡ä¿æŠ¤: å·²å¯ç”¨ï¼Œç¡®ä¿å¤„ç†è¿‡ç¨‹ä¸­ä¸å‹ç¼©å›¾ç‰‡")
        logger.info(f"ğŸ¯ éœ€è¦è¿‘æ™¯æ­£è„¸æ•°é‡: {self.config.REQUIRED_CLOSE_FRONTAL_FACES}")
        logger.info(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def _setup_device(self) -> str:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        try:
            if self.config.USE_GPU and torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                logger.info(f"ğŸ” æ£€æµ‹åˆ° {device_count} ä¸ªGPUè®¾å¤‡")
                
                # å°è¯•ä¼˜å…ˆGPU
                if self.config.PREFERRED_GPU < device_count:
                    device = f'cuda:{self.config.PREFERRED_GPU}'
                    gpu_name = torch.cuda.get_device_name(self.config.PREFERRED_GPU)
                    gpu_memory = torch.cuda.get_device_properties(self.config.PREFERRED_GPU).total_memory / 1024**3
                    logger.info(f"ğŸš€ ä½¿ç”¨ä¼˜å…ˆGPU: {gpu_name} (è®¾å¤‡ {self.config.PREFERRED_GPU})")
                    logger.info(f"ğŸ”¥ GPUæ˜¾å­˜: {gpu_memory:.1f} GB")
                    
                    # æ¸…ç†GPUç¼“å­˜
                    torch.cuda.empty_cache()
                    return device
                
                # å°è¯•å¤‡ç”¨GPU
                elif self.config.FALLBACK_GPU < device_count:
                    device = f'cuda:{self.config.FALLBACK_GPU}'
                    gpu_name = torch.cuda.get_device_name(self.config.FALLBACK_GPU)
                    logger.info(f"ğŸš€ ä½¿ç”¨å¤‡ç”¨GPU: {gpu_name} (è®¾å¤‡ {self.config.FALLBACK_GPU})")
                    torch.cuda.empty_cache()
                    return device
                
                else:
                    logger.warning(f"âš ï¸  æŒ‡å®šçš„GPUè®¾å¤‡ä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                    return 'cpu'
            else:
                logger.info("ğŸ’» ä½¿ç”¨CPUæ¨¡å¼")
                return 'cpu'
                
        except Exception as e:
            logger.error(f"âŒ è®¾å¤‡è®¾ç½®å¤±è´¥: {e}")
            return 'cpu'
    
    def _create_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        for name, dir_path in self.output_dirs.items():
            try:
                os.makedirs(dir_path, exist_ok=True)
                logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
                raise
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
            if not os.path.exists(self.config.YOLOV8S_MODEL_PATH):
                raise FileNotFoundError(f"YOLOv8sæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.config.YOLOV8S_MODEL_PATH}")
            
            if not os.path.exists(self.config.LICENSE_PLATE_MODEL_PATH):
                raise FileNotFoundError(f"è½¦ç‰Œæ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.config.LICENSE_PLATE_MODEL_PATH}")
            
            # åˆå§‹åŒ–YOLOv8säººè„¸æ£€æµ‹æ¨¡å‹
            logger.info("ğŸ” åˆå§‹åŒ–YOLOv8säººè„¸æ£€æµ‹æ¨¡å‹...")
            self.face_model = YOLO(self.config.YOLOV8S_MODEL_PATH)
            logger.info("âœ… YOLOv8säººè„¸æ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹
            logger.info("ğŸš— åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
            self.plate_model = YOLO(self.config.LICENSE_PLATE_MODEL_PATH)
            logger.info("âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
            # æµ‹è¯•RetinaFace
            logger.info("ğŸ” æµ‹è¯•RetinaFaceæ¨¡å‹...")
            self._test_retinaface()
            
            # åˆå§‹åŒ–OCR
            logger.info("ğŸ“ åˆå§‹åŒ–EasyOCRæ¨¡å‹...")
            self._initialize_ocr()
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _test_retinaface(self):
        """æµ‹è¯•RetinaFaceæ¨¡å‹"""
        try:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_img = np.ones((100, 100, 3), dtype=np.uint8) * 128
            result = RetinaFace.detect_faces(test_img)
            logger.info("âœ… RetinaFaceæ¨¡å‹æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ RetinaFaceæµ‹è¯•å¤±è´¥: {e}")
            raise
    
    def _initialize_ocr(self):
        """åˆå§‹åŒ–OCRæ¨¡å‹"""
        try:
            gpu_enabled = 'cuda' in self.device
            self.ocr_reader = easyocr.Reader(
                ['ch_sim', 'en'],  # æ”¯æŒä¸­æ–‡ç®€ä½“å’Œè‹±æ–‡
                gpu=gpu_enabled
            )
            logger.info(f"âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ ({'GPU' if gpu_enabled else 'CPU'}æ¨¡å¼)")
        except Exception as e:
            logger.error(f"âŒ OCRæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ocr_reader = None
    
    def detect_faces_yolo(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨YOLOv8sæ£€æµ‹äººè„¸"""
        try:
            results = self.face_model(image_path, verbose=False, device=self.device)
            
            if not results or len(results) == 0:
                return 0, []
            
            result = results[0]
            if result.boxes is None or len(result.boxes) == 0:
                return 0, []
            
            # è¯»å–å›¾åƒè·å–å°ºå¯¸ä¿¡æ¯
            img = cv2.imread(image_path, self.config.IMAGE_READ_FLAGS)
            if img is None:
                return 0, []
            
            img_height, img_width = img.shape[:2]
            img_area = img_width * img_height
            
            face_detections = []
            close_up_faces = 0
            
            for box in result.boxes:
                try:
                    confidence = float(box.conf[0])
                    if confidence < self.config.MIN_FACE_CONFIDENCE_YOLO:
                        continue
                    
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    face_width = x2 - x1
                    face_height = y2 - y1
                    face_area = face_width * face_height
                    
                    # æ£€æŸ¥æœ€å°å°ºå¯¸
                    if min(face_width, face_height) < self.config.MIN_FACE_SIZE:
                        continue
                    
                    if face_area < self.config.MIN_FACE_AREA:
                        continue
                    
                    # è®¡ç®—é¢ç§¯æ¯”ä¾‹åˆ¤æ–­æ˜¯å¦ä¸ºè¿‘æ™¯
                    area_ratio = face_area / img_area
                    is_close_up = area_ratio >= self.config.CLOSE_UP_FACE_RATIO
                    
                    face_info = {
                        'confidence': confidence,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'face_size': (float(face_width), float(face_height)),
                        'face_area': float(face_area),
                        'area_ratio': float(area_ratio),
                        'is_close_up': is_close_up
                    }
                    
                    face_detections.append(face_info)
                    
                    if is_close_up:
                        close_up_faces += 1
                
                except Exception as e:
                    logger.debug(f"åˆ†æYOLOæ£€æµ‹æ¡†å¤±è´¥: {e}")
                    continue
            
            return close_up_faces, face_detections
            
        except Exception as e:
            logger.debug(f"YOLOäººè„¸æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0
            
            horizontal_offset = nose[0] - eye_center[0]
            normalized_offset = horizontal_offset / eye_width
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0
    
    def detect_frontal_faces_retina(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨RetinaFaceæ£€æµ‹æ­£è„¸"""
        try:
            # ç›´æ¥ä¼ é€’å›¾ç‰‡è·¯å¾„ç»™RetinaFace
            detections = RetinaFace.detect_faces(image_path)
            
            if not isinstance(detections, dict) or len(detections) == 0:
                return 0, []
            
            # è¯»å–å›¾åƒä¿¡æ¯
            img = cv2.imread(image_path, self.config.IMAGE_READ_FLAGS)
            if img is None:
                return 0, []
            
            img_height, img_width = img.shape[:2]
            img_area = img_width * img_height
            
            frontal_faces = []
            close_frontal_count = 0
            
            for face_key, face_data in detections.items():
                try:
                    confidence = face_data.get('score', 0.0)
                    if confidence < self.config.MIN_FACE_CONFIDENCE_RETINA:
                        continue
                    
                    facial_area = face_data['facial_area']
                    landmarks = face_data.get('landmarks', {})
                    
                    if not landmarks:
                        continue
                    
                    x1, y1, x2, y2 = facial_area
                    face_width = x2 - x1
                    face_height = y2 - y1
                    face_area = face_width * face_height
                    
                    # æ£€æŸ¥æœ€å°å°ºå¯¸
                    if min(face_width, face_height) < self.config.MIN_FACE_SIZE:
                        continue
                    
                    if face_area < self.config.MIN_FACE_AREA:
                        continue
                    
                    # è®¡ç®—yawè§’åº¦
                    yaw_angle = self.calculate_yaw_angle(landmarks)
                    is_frontal = yaw_angle <= self.config.YAW_ANGLE_THRESHOLD
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºè¿‘æ™¯
                    area_ratio = face_area / img_area
                    is_close_up = area_ratio >= self.config.CLOSE_UP_FACE_RATIO
                    
                    face_info = {
                        'confidence': confidence,
                        'yaw_angle': yaw_angle,
                        'is_frontal': is_frontal,
                        'facial_area': facial_area,
                        'face_size': (face_width, face_height),
                        'face_area': face_area,
                        'area_ratio': area_ratio,
                        'is_close_up': is_close_up,
                        'is_close_frontal': is_frontal and is_close_up
                    }
                    
                    frontal_faces.append(face_info)
                    
                    if is_frontal and is_close_up:
                        close_frontal_count += 1
                
                except Exception as e:
                    logger.debug(f"åˆ†æRetinaFaceæ£€æµ‹ç»“æœå¤±è´¥: {e}")
                    continue
            
            return close_frontal_count, frontal_faces
            
        except Exception as e:
            logger.debug(f"RetinaFaceæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_license_plates(self, image_path: str) -> Tuple[int, List[Dict]]:
        """æ£€æµ‹è½¦ç‰Œ"""
        try:
            results = self.plate_model(image_path, verbose=False, device=self.device)
            
            if not results or len(results) == 0:
                return 0, []
            
            result = results[0]
            if result.boxes is None or len(result.boxes) == 0:
                return 0, []
            
            clear_plates = []
            
            for box in result.boxes:
                try:
                    confidence = float(box.conf[0])
                    if confidence < self.config.MIN_PLATE_CONFIDENCE:
                        continue
                    
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    plate_width = x2 - x1
                    plate_height = y2 - y1
                    
                    plate_info = {
                        'confidence': confidence,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'plate_size': (float(plate_width), float(plate_height))
                    }
                    
                    clear_plates.append(plate_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æè½¦ç‰Œå¤±è´¥: {e}")
                    continue
            
            return len(clear_plates), clear_plates
            
        except Exception as e:
            logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_text(self, image_path: str) -> Tuple[int, List[Dict]]:
        """æ£€æµ‹æ–‡å­—"""
        try:
            if self.ocr_reader is None:
                return 0, []
            
            img = cv2.imread(image_path, self.config.IMAGE_READ_FLAGS)
            if img is None:
                return 0, []
            
            results = self.ocr_reader.readtext(img)
            
            if not results:
                return 0, []
            
            valid_texts = []
            
            for bbox, text, confidence in results:
                try:
                    confidence = float(confidence) if confidence is not None else 0.0
                    
                    if confidence < self.config.MIN_TEXT_CONFIDENCE:
                        continue
                    
                    cleaned_text = text.strip()
                    if len(cleaned_text) < 2:
                        continue
                    
                    text_info = {
                        'text': cleaned_text,
                        'confidence': confidence,
                        'bbox': bbox
                    }
                    valid_texts.append(text_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†ææ–‡å­—å¤±è´¥: {e}")
                    continue
            
            return len(valid_texts), valid_texts
            
        except Exception as e:
            logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def classify_image(self, image_path: str) -> Tuple[str, Dict]:
        """åˆ†ç±»å›¾åƒ"""
        start_time = time.time()
        
        try:
            filename = os.path.basename(image_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å’Œæœ‰æ•ˆ
            if not os.path.exists(image_path):
                return 'failed', {'filename': filename, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}
            
            file_size = os.path.getsize(image_path)
            if file_size == 0:
                return 'failed', {'filename': filename, 'error': 'æ–‡ä»¶ä¸ºç©º'}
            
            # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨YOLOv8sæ£€æµ‹äººè„¸
            yolo_close_faces, yolo_face_details = self.detect_faces_yolo(image_path)
            
            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨RetinaFaceæ£€æµ‹æ­£è„¸
            retina_close_frontal, retina_face_details = self.detect_frontal_faces_retina(image_path)
            
            # åˆ¤æ–­æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¿‘æ™¯æ­£è„¸
            has_enough_faces = retina_close_frontal >= self.config.REQUIRED_CLOSE_FRONTAL_FACES
            
            plate_count = 0
            text_count = 0
            plate_details = []
            text_details = []
            
            if not has_enough_faces:
                # å¦‚æœè¿‘æ™¯æ­£è„¸ä¸å¤Ÿï¼Œæ£€æµ‹è½¦ç‰Œå’Œæ–‡å­—
                plate_count, plate_details = self.detect_license_plates(image_path)
                text_count, text_details = self.detect_text(image_path)
            
            processing_time = time.time() - start_time
            
            # åˆ›å»ºåˆ†æç»“æœ
            analysis = {
                'filename': filename,
                'yolo_close_faces': yolo_close_faces,
                'retina_close_frontal_faces': retina_close_frontal,
                'license_plates': plate_count,
                'text_count': text_count,
                'yolo_face_details': yolo_face_details,
                'retina_face_details': retina_face_details,
                'plate_details': plate_details,
                'text_details': text_details,
                'processing_time': processing_time,
                'file_size': file_size,
                'timestamp': time.time()
            }
            
            # å†³å®šåˆ†ç±»
            if has_enough_faces:
                category = 'satisfied_4_faces'
                analysis['result'] = f'æ»¡è¶³æ¡ä»¶ï¼šæœ‰{retina_close_frontal}å¼ è¿‘æ™¯æ­£è„¸(>={self.config.REQUIRED_CLOSE_FRONTAL_FACES})'
            elif retina_close_frontal > 0 and (plate_count > 0 or text_count > 0):
                category = 'satisfied_with_plate'
                analysis['result'] = f'æ»¡è¶³æ¡ä»¶ï¼šæœ‰{retina_close_frontal}å¼ è¿‘æ™¯æ­£è„¸ + {plate_count}ä¸ªè½¦ç‰Œ + {text_count}ä¸ªæ–‡å­—'
            elif yolo_close_faces > 0 or retina_close_frontal > 0:
                category = 'insufficient_faces'
                analysis['result'] = f'äººè„¸ä¸è¶³ï¼šYOLOæ£€æµ‹{yolo_close_faces}å¼ è¿‘æ™¯äººè„¸ï¼ŒRetinaFaceæ£€æµ‹{retina_close_frontal}å¼ è¿‘æ™¯æ­£è„¸'
            else:
                category = 'no_faces'
                analysis['result'] = 'æ— äººè„¸æ£€æµ‹åˆ°'
            
            analysis['category'] = category
            
            return category, analysis
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ å›¾åƒåˆ†ç±»å¤±è´¥ {image_path}: {e}")
            return 'failed', {
                'filename': os.path.basename(image_path), 
                'error': str(e),
                'processing_time': processing_time
            }
    
    def move_image_to_category(self, image_path: str, category: str) -> bool:
        """ç§»åŠ¨å›¾åƒåˆ°å¯¹åº”åˆ†ç±»ç›®å½•ï¼Œç¡®ä¿ä¸å‹ç¼©å›¾ç‰‡"""
        try:
            filename = os.path.basename(image_path)
            
            if category not in self.output_dirs:
                logger.error(f"âŒ æœªçŸ¥åˆ†ç±»: {category}")
                return False
            
            output_dir = self.output_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            # ä½¿ç”¨shutil.copy2ä¿æŒåŸå§‹æ–‡ä»¶è´¨é‡å’Œå…ƒæ•°æ®
            shutil.copy2(image_path, output_path)
            
            # éªŒè¯å¤åˆ¶æ˜¯å¦æˆåŠŸ
            if not os.path.exists(output_path):
                logger.error(f"âŒ æ–‡ä»¶å¤åˆ¶å¤±è´¥: {output_path}")
                return False
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            original_size = os.path.getsize(image_path)
            copied_size = os.path.getsize(output_path)
            if original_size != copied_size:
                logger.warning(f"âš ï¸  æ–‡ä»¶å¤§å°ä¸åŒ¹é…: åŸå§‹={original_size}, å¤åˆ¶={copied_size}")
            
            # åˆ é™¤åŸæ–‡ä»¶
            os.remove(image_path)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def get_image_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        files = []
        input_path = Path(self.config.INPUT_DIR)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.config.INPUT_DIR}")
            return []
        
        logger.info(f"ğŸ” æ‰«æç›®å½•: {self.config.INPUT_DIR}")
        
        for ext in self.config.SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            files.extend(input_path.glob(pattern))
        
        image_files = sorted([str(f) for f in files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            analysis_dir = self.output_dirs['analysis']
            
            # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
            analysis_file = os.path.join(analysis_dir, "advanced_classification_analysis.json")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
            summary = {
                'total_processed': len(self.analysis_results),
                'statistics': self.stats.copy(),
                'processing_time': time.time() - self.start_time,
                'configuration': {
                    'required_close_frontal_faces': self.config.REQUIRED_CLOSE_FRONTAL_FACES,
                    'yaw_angle_threshold': self.config.YAW_ANGLE_THRESHOLD,
                    'close_up_face_ratio': self.config.CLOSE_UP_FACE_RATIO,
                    'min_face_area': self.config.MIN_FACE_AREA,
                },
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(analysis_dir, "advanced_classification_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        total_processed = sum(self.stats.values())
        
        logger.info("="*80)
        logger.info("ğŸ‰ é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹åˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        logger.info(f"âœ… 4å¼ è¿‘æ™¯æ­£è„¸æ»¡è¶³æ¡ä»¶: {self.stats['satisfied_4_faces']:,}")
        logger.info(f"âœ… è½¦ç‰Œ/æ–‡å­—æ»¡è¶³æ¡ä»¶: {self.stats['satisfied_with_plate']:,}")
        logger.info(f"âŒ äººè„¸æ•°é‡ä¸è¶³: {self.stats['insufficient_faces']:,}")
        logger.info(f"âŒ æ— äººè„¸: {self.stats['no_faces']:,}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,}")
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,}")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            avg_speed = total_processed / processing_time
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            success_rate = ((self.stats['satisfied_4_faces'] + self.stats['satisfied_with_plate']) / total_processed) * 100
            logger.info(f"ğŸ“ˆ æ»¡è¶³æ¡ä»¶æ¯”ä¾‹: {success_rate:.1f}%")
        
        # æ˜¾ç¤ºå„ç›®å½•æ–‡ä»¶æ•°é‡
        logger.info("\nğŸ“‚ å„åˆ†ç±»ç›®å½•ç»Ÿè®¡:")
        categories = [
            ("4å¼ è¿‘æ™¯æ­£è„¸æ»¡è¶³", self.output_dirs['satisfied_4_faces']),
            ("è½¦ç‰Œæ–‡å­—æ»¡è¶³", self.output_dirs['satisfied_with_plate']),
            ("äººè„¸æ•°é‡ä¸è¶³", self.output_dirs['insufficient_faces']),
            ("æ— äººè„¸", self.output_dirs['no_faces'])
        ]
        
        for name, dir_path in categories:
            if os.path.exists(dir_path):
                count = len([f for f in os.listdir(dir_path) 
                           if f.lower().endswith(tuple(self.config.SUPPORTED_FORMATS))])
                logger.info(f"  ğŸ“ {name}: {count} å¼ å›¾ç‰‡")
        
        logger.info("="*80)
    
    def run(self):
        """è¿è¡Œæ£€æµ‹å™¨"""
        logger.info("ğŸš€ å¯åŠ¨é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {self.config.INPUT_DIR}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.config.OUTPUT_BASE_DIR}")
        logger.info(f"ğŸ’» è®¡ç®—è®¾å¤‡: {self.device}")
        logger.info(f"ğŸ¯ éœ€è¦è¿‘æ™¯æ­£è„¸æ•°é‡: {self.config.REQUIRED_CLOSE_FRONTAL_FACES}")
        logger.info(f"ğŸ“ yawè§’åº¦é˜ˆå€¼: {self.config.YAW_ANGLE_THRESHOLD}Â°")
        logger.info(f"ğŸ“ è¿‘æ™¯é¢ç§¯æ¯”ä¾‹é˜ˆå€¼: {self.config.CLOSE_UP_FACE_RATIO}")
        logger.info(f"ğŸ” YOLOäººè„¸ç½®ä¿¡åº¦é˜ˆå€¼: {self.config.MIN_FACE_CONFIDENCE_YOLO}")
        logger.info(f"ğŸ” RetinaFaceç½®ä¿¡åº¦é˜ˆå€¼: {self.config.MIN_FACE_CONFIDENCE_RETINA}")
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files()
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return
        
        total_files = len(image_files)
        logger.info(f"ğŸ“Š æ‰¾åˆ° {total_files} å¼ å›¾ç‰‡å¾…å¤„ç†")
        
        # å¼€å§‹å¤„ç†
        try:
            start_time = time.time()
            failed_files = []
            
            for i, image_path in enumerate(image_files):
                try:
                    # åˆ†ç±»å›¾åƒ
                    category, analysis = self.classify_image(image_path)
                    
                    if category != 'failed':
                        # ç§»åŠ¨åˆ°å¯¹åº”ç›®å½•
                        if self.move_image_to_category(image_path, category):
                            self.stats[category] += 1
                        else:
                            self.stats['failed'] += 1
                            analysis['move_failed'] = True
                            failed_files.append(image_path)
                    else:
                        self.stats['failed'] += 1
                        failed_files.append(image_path)
                    
                    # ä¿å­˜åˆ†æç»“æœ
                    self.analysis_results.append(analysis)
                    
                    # è¿›åº¦æ˜¾ç¤º
                    if (i + 1) % self.config.PROGRESS_UPDATE_FREQUENCY == 0 or i == total_files - 1:
                        progress = (i + 1) / total_files * 100
                        elapsed = time.time() - start_time
                        
                        if i > 0:
                            avg_time = elapsed / (i + 1)
                            remaining_files = total_files - (i + 1)
                            eta = remaining_files * avg_time
                            
                            eta_str = f"{eta/60:.1f}åˆ†é’Ÿ" if eta > 60 else f"{eta:.0f}ç§’"
                            
                            print(f"\rğŸ“Š è¿›åº¦: {i+1}/{total_files} ({progress:.1f}%) "
                                  f"| å·²ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ "
                                  f"| é¢„è®¡å‰©ä½™: {eta_str} "
                                  f"| é€Ÿåº¦: {(i+1)/elapsed:.1f}å¼ /ç§’", end='', flush=True)
                        else:
                            print(f"\rğŸ“Š è¿›åº¦: {i+1}/{total_files} ({progress:.1f}%)", end='', flush=True)
                    
                    # å®šæœŸå†…å­˜æ¸…ç†
                    if (i + 1) % self.config.GC_FREQUENCY == 0:
                        gc.collect()
                        if 'cuda' in self.device:
                            torch.cuda.empty_cache()
                
                except KeyboardInterrupt:
                    logger.info("\nâš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
                    break
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
                    self.stats['failed'] += 1
                    failed_files.append(image_path)
            
            # å®Œæˆåæ¢è¡Œ
            print()
            
            # æ˜¾ç¤ºå¤±è´¥æ–‡ä»¶
            if failed_files:
                logger.warning(f"âš ï¸  å¤±è´¥æ–‡ä»¶æ•°: {len(failed_files)}")
                if len(failed_files) <= 10:
                    for failed_file in failed_files:
                        logger.warning(f"  - {os.path.basename(failed_file)}")
                else:
                    logger.warning(f"  æ˜¾ç¤ºå‰10ä¸ª: {[os.path.basename(f) for f in failed_files[:10]]}")
        
        finally:
            # ä¿å­˜ç»“æœå’Œç»Ÿè®¡
            self.save_analysis_results()
            self.print_final_statistics()

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºé…ç½®
        config = Config()
        
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(config.INPUT_DIR):
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {config.INPUT_DIR}")
            return
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(config.YOLOV8S_MODEL_PATH):
            logger.error(f"âŒ YOLOv8sæ¨¡å‹ä¸å­˜åœ¨: {config.YOLOV8S_MODEL_PATH}")
            return
        
        if not os.path.exists(config.LICENSE_PLATE_MODEL_PATH):
            logger.error(f"âŒ è½¦ç‰Œæ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {config.LICENSE_PLATE_MODEL_PATH}")
            return
        
        # åˆ›å»ºæ£€æµ‹å™¨å¹¶è¿è¡Œ
        detector = AdvancedFacePlateDetector(config)
        detector.run()
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
