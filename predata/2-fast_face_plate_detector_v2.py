#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿäººè„¸è½¦ç‰Œæ£€æµ‹å™¨ - é«˜åº¦ä¼˜åŒ–ç‰ˆæœ¬
ä¸“æ³¨äºé€Ÿåº¦å’Œç¨³å®šæ€§ï¼Œç§»é™¤å¤æ‚çš„é¢„è¿‡æ»¤é€»è¾‘
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import gc
import multiprocessing as mp
import math
import re
import threading
import psutil
from datetime import datetime
from collections import defaultdict
from contextlib import contextmanager

# GPUåŠ é€Ÿç›¸å…³å¯¼å…¥
try:
    import cupy as cp
    CUPY_AVAILABLE = True
    print("âœ… CuPyå¯ç”¨ï¼Œå°†ä½¿ç”¨GPUåŠ é€Ÿ")
except ImportError:
    CUPY_AVAILABLE = False
    print("âš ï¸ CuPyä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUå¤„ç†")

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ä¿®å¤CUDAå¤šè¿›ç¨‹é—®é¢˜
if __name__ == "__main__":
    mp.set_start_method('spawn', force=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('fast_face_plate_detector_v2.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–åº“"""
    missing_deps = []
    imported_modules = {}
    
    try:
        from retinaface import RetinaFace
        imported_modules['RetinaFace'] = RetinaFace
        logger.info("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    try:
        from ultralytics import YOLO
        imported_modules['YOLO'] = YOLO
        logger.info("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    try:
        import easyocr
        imported_modules['easyocr'] = easyocr
        logger.info("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    try:
        import torch
        imported_modules['torch'] = torch
        logger.info("âœ… PyTorch åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ PyTorch åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("torch")
    
    if missing_deps:
        logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        return None
    
    return imported_modules

# æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–
modules = check_dependencies()
if modules is None:
    exit(1)

RetinaFace = modules['RetinaFace']
YOLO = modules['YOLO']
easyocr = modules['easyocr']
torch = modules['torch']

class GPUMemoryManager:
    """GPUå†…å­˜ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, max_gpu_memory_mb=3072, max_cpu_memory_mb=1536, warning_threshold=0.7):
        """
        åˆå§‹åŒ–GPUå†…å­˜ç®¡ç†å™¨
        
        Args:
            max_gpu_memory_mb (int): æœ€å¤§GPUå†…å­˜ä½¿ç”¨é‡(MB) - é™ä½é»˜è®¤å€¼
            max_cpu_memory_mb (int): æœ€å¤§CPUå†…å­˜ä½¿ç”¨é‡(MB) - é™ä½é»˜è®¤å€¼
            warning_threshold (float): å†…å­˜è­¦å‘Šé˜ˆå€¼(0-1) - é™ä½é˜ˆå€¼
        """
        self.max_gpu_memory_bytes = max_gpu_memory_mb * 1024 * 1024
        self.max_cpu_memory_bytes = max_cpu_memory_mb * 1024 * 1024
        self.warning_threshold = warning_threshold
        self.process = psutil.Process()
        self.monitoring = False
        self.monitor_thread = None
        self.gpu_available = self._check_gpu_availability()
        self.cleanup_counter = 0  # æ¸…ç†è®¡æ•°å™¨
        self.force_cleanup_threshold = 50  # å¼ºåˆ¶æ¸…ç†é˜ˆå€¼
        
    def _check_gpu_availability(self):
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        if not CUPY_AVAILABLE:
            return False
            
        try:
            cp.cuda.Device(0).use()
            return True
        except Exception as e:
            print(f"âš ï¸ GPUä¸å¯ç”¨: {str(e)}")
            return False
    
    def get_gpu_memory_usage(self):
        """è·å–GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if not self.gpu_available:
            return {'used': 0, 'free': 0, 'total': 0}
            
        try:
            mempool = cp.get_default_memory_pool()
            return {
                'used': mempool.used_bytes(),
                'total': mempool.total_bytes(),
                'free': mempool.total_bytes() - mempool.used_bytes()
            }
        except Exception:
            return {'used': 0, 'free': 0, 'total': 0}
    
    def get_cpu_memory_usage(self):
        """è·å–CPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            memory_info = self.process.memory_info()
            return {
                'rss': memory_info.rss,
                'vms': memory_info.vms,
                'percent': self.process.memory_percent(),
                'available': psutil.virtual_memory().available
            }
        except Exception:
            return {'rss': 0, 'vms': 0, 'percent': 0, 'available': 0}
    
    def is_gpu_memory_available(self, required_bytes=0):
        """æ£€æŸ¥GPUæ˜¯å¦æœ‰è¶³å¤Ÿå†…å­˜"""
        if not self.gpu_available:
            return False
            
        gpu_memory = self.get_gpu_memory_usage()
        return (gpu_memory['used'] + required_bytes) < self.max_gpu_memory_bytes
    
    def force_gpu_cleanup(self):
        """å¼ºåˆ¶GPUå†…å­˜æ¸…ç†"""
        if self.gpu_available and CUPY_AVAILABLE:
            try:
                import cupy as cp
                cp.get_default_memory_pool().free_all_blocks()
                cp.get_default_pinned_memory_pool().free_all_blocks()
            except:
                pass
        gc.collect()
        self.cleanup_counter += 1
    
    def start_monitoring(self):
        """å¼€å§‹å†…å­˜ç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_memory)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢å†…å­˜ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)
    
    def _monitor_memory(self):
        """å†…å­˜ç›‘æ§çº¿ç¨‹ - ä¼˜åŒ–ç‰ˆ"""
        while self.monitoring:
            cpu_memory = self.get_cpu_memory_usage()
            
            # CPUå†…å­˜ç›‘æ§ - æ›´ä¸¥æ ¼çš„æ§åˆ¶
            cpu_usage_ratio = cpu_memory['rss'] / self.max_cpu_memory_bytes
            if cpu_usage_ratio > self.warning_threshold:
                logger.warning(f"âš ï¸ CPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {cpu_usage_ratio:.1%}")
                # æ‰§è¡Œå¼ºåˆ¶å†…å­˜æ¸…ç†
                self.force_gpu_cleanup()
                
                # å¦‚æœå†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%ï¼Œè§¦å‘ç´§æ€¥æ¸…ç†
                if cpu_usage_ratio > 0.9:
                    logger.error(f"âŒ CPUå†…å­˜ä½¿ç”¨ç‡å±é™©: {cpu_usage_ratio:.1%}")
                    # å¼ºåˆ¶Pythonåƒåœ¾å›æ”¶
                    for _ in range(3):
                        gc.collect()
            
            # GPUå†…å­˜ç›‘æ§
            if self.gpu_available and CUPY_AVAILABLE:
                gpu_memory = self.get_gpu_memory_usage()
                if gpu_memory['total'] > 0:
                    gpu_usage_ratio = gpu_memory['used'] / gpu_memory['total']
                    if gpu_usage_ratio > self.warning_threshold:
                        logger.warning(f"âš ï¸ GPUå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {gpu_usage_ratio:.1%}")
                        self.force_gpu_cleanup()
            
            time.sleep(2)  # æ›´é¢‘ç¹çš„ç›‘æ§ï¼šæ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def get_dynamic_batch_size(self, default_batch_size=32):
        """æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µåŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°"""
        cpu_memory = self.get_cpu_memory_usage()
        cpu_usage_ratio = cpu_memory['rss'] / self.max_cpu_memory_bytes
        
        if cpu_usage_ratio > 0.8:
            return max(8, default_batch_size // 4)  # å†…å­˜ç´§å¼ æ—¶å‡å°‘åˆ°1/4
        elif cpu_usage_ratio > 0.6:
            return max(16, default_batch_size // 2)  # å†…å­˜è¾ƒç´§å¼ æ—¶å‡å°‘åˆ°1/2
        else:
            return default_batch_size


class SimilarImageDetectorGPU:
    """GPUåŠ é€Ÿçš„ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨"""
    
    def __init__(self, psnr_threshold=50.0, max_gpu_memory_mb=3072, max_cpu_memory_mb=1536, 
                 use_gpu=True, min_frame_distance=5, adjacent_frame_threshold=8):
        """
        åˆå§‹åŒ–GPUåŠ é€Ÿçš„ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨ - å†…å­˜ä¼˜åŒ–ç‰ˆ
        
        Args:
            psnr_threshold (float): PSNRé˜ˆå€¼
            max_gpu_memory_mb (int): æœ€å¤§GPUå†…å­˜ä½¿ç”¨é‡(MB) - é™ä½é»˜è®¤å€¼
            max_cpu_memory_mb (int): æœ€å¤§CPUå†…å­˜ä½¿ç”¨é‡(MB) - é™ä½é»˜è®¤å€¼
            use_gpu (bool): æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
            min_frame_distance (int): æœ€å°å¸§é—´è·ï¼Œç”¨äºè¿‡æ»¤ç›¸é‚»å¸§
            adjacent_frame_threshold (int): ç›¸é‚»å¸§ç›¸ä¼¼é˜ˆå€¼ï¼Œâ‰¤æ­¤å€¼è®¤å®šä¸ºç›¸ä¼¼
        """
        self.psnr_threshold = psnr_threshold
        self.min_frame_distance = min_frame_distance
        self.adjacent_frame_threshold = adjacent_frame_threshold
        self.memory_manager = GPUMemoryManager(max_gpu_memory_mb, max_cpu_memory_mb)
        self.use_gpu = use_gpu and self.memory_manager.gpu_available
        
        # åˆå§‹åŒ–CUDAä¸Šä¸‹æ–‡ï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰
        if self.use_gpu:
            try:
                if CUPY_AVAILABLE:
                    import cupy as cp
                    cp.cuda.Device(0).use()
                logger.info("ğŸ”§ GPUåˆå§‹åŒ–æˆåŠŸï¼Œå°†ä½¿ç”¨GPUåŠ é€Ÿç›¸ä¼¼åº¦æ£€æµ‹")
            except Exception as e:
                logger.warning(f"âš ï¸ GPUåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨CPU: {e}")
                self.use_gpu = False
        
        if not self.use_gpu:
            logger.info("ğŸ’» ä½¿ç”¨CPUå¤„ç†æ¨¡å¼è¿›è¡Œç›¸ä¼¼åº¦æ£€æµ‹")
        
        self.stats = {
            'total_images': 0,
            'similar_groups': 0,
            'similar_images': 0,
            'unique_images': 0,
            'processed_pairs': 0,
            'memory_cleanups': 0,
            'max_memory_used': 0,
            'gpu_operations': 0,
            'cpu_operations': 0,
            'adjacent_frames_filtered': 0,
            'adjacent_frames_similar': 0
        }
    
    def extract_frame_number(self, filename):
        """ä»æ–‡ä»¶åä¸­æå–å¸§å·"""
        patterns = [
            r'frame_(\d+)',           # frame_001.jpg
            r'frame(\d+)',            # frame001.jpg  
            r'_(\d+)\.jpg',           # xxx_001.jpg
            r'_(\d+)\.png',           # xxx_001.png
            r'(\d+)\.jpg',            # 001.jpg
            r'(\d+)\.png',            # 001.png
            r'-(\d+)\.',              # xxx-001.jpg
            r'(\d{3,})',              # ä»»ä½•3ä½ä»¥ä¸Šæ•°å­—
        ]
        
        filename_str = str(filename)
        for pattern in patterns:
            match = re.search(pattern, filename_str)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return -1  # æ— æ³•æå–å¸§å·
    
    def calculate_image_clarity(self, image_path):
        """è®¡ç®—å›¾ç‰‡çš„æ¸…æ™°åº¦åˆ†æ•° - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
        try:
            if not Path(image_path).exists():
                return 0.0
            
            # ä½¿ç”¨æ›´å°çš„å›¾ç‰‡å°ºå¯¸æ¥èŠ‚çœå†…å­˜
            img = cv2.imread(str(image_path))
            if img is None:
                return 0.0
            
            if img.shape[0] == 0 or img.shape[1] == 0:
                return 0.0
            
            # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œå…ˆç¼©æ”¾ä»¥èŠ‚çœå†…å­˜
            height, width = img.shape[:2]
            if height > 800 or width > 800:
                scale_factor = min(800/height, 800/width)
                new_height, new_width = int(height * scale_factor), int(width * scale_factor)
                img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # ç«‹å³é‡Šæ”¾å½©è‰²å›¾åƒå†…å­˜
            del img
            
            if self.use_gpu and CUPY_AVAILABLE:
                try:
                    import cupy as cp
                    gray_gpu = cp.asarray(gray)
                    laplacian_var = cp.var(cp.array([
                        [-1, -2, -1], [0, 0, 0], [1, 2, 1]
                    ], dtype=cp.float32))
                    quality_score = float(laplacian_var)
                    
                    # ç«‹å³é‡Šæ”¾GPUå†…å­˜
                    del gray_gpu
                    cp.get_default_memory_pool().free_all_blocks()
                    self.stats['gpu_operations'] += 1
                except:
                    quality_score = cv2.Laplacian(gray, cv2.CV_64F).var()
                    self.stats['cpu_operations'] += 1
            else:
                quality_score = cv2.Laplacian(gray, cv2.CV_64F).var()
                self.stats['cpu_operations'] += 1
            
            # ç«‹å³é‡Šæ”¾ç°åº¦å›¾åƒå†…å­˜
            del gray
            
            # ç»“åˆæ–‡ä»¶å¤§å°ä½œä¸ºè´¨é‡æŒ‡æ ‡
            try:
                file_size = os.path.getsize(image_path)
                size_factor = min(file_size / (500 * 1024), 1.0)  # 500KBä¸ºåŸºå‡†
                quality_score = quality_score * size_factor
            except OSError:
                pass
            
            return quality_score
            
        except Exception as e:
            logger.debug(f"âš ï¸ æ¸…æ™°åº¦è®¡ç®—å¤±è´¥ {Path(image_path).name}: {str(e)}")
            return 0.0
        finally:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
    
    def calculate_psnr_gpu(self, img1, img2):
        """GPUåŠ é€Ÿçš„PSNRè®¡ç®— - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
        try:
            # å¤„ç†ä¸åŒå°ºå¯¸çš„å›¾ç‰‡
            h1, w1 = img1.shape[:2]
            h2, w2 = img2.shape[:2]
            
            min_h = min(h1, h2)
            min_w = min(w1, w2)
            
            # é™åˆ¶æœ€å¤§å¤„ç†å°ºå¯¸ä»¥èŠ‚çœå†…å­˜
            max_size = 512  # æœ€å¤§å¤„ç†å°ºå¯¸
            if min_h > max_size or min_w > max_size:
                scale_factor = min(max_size/min_h, max_size/min_w)
                min_h = int(min_h * scale_factor)
                min_w = int(min_w * scale_factor)
            
            def center_crop_and_resize(img, target_h, target_w):
                h, w = img.shape[:2]
                start_h = (h - min(h, target_h * 2)) // 2  # å–ä¸­å¿ƒåŒºåŸŸ
                start_w = (w - min(w, target_w * 2)) // 2
                end_h = start_h + min(h, target_h * 2)
                end_w = start_w + min(w, target_w * 2)
                
                cropped = img[start_h:end_h, start_w:end_w]
                return cv2.resize(cropped, (target_w, target_h), interpolation=cv2.INTER_LINEAR)
            
            img1_cropped = center_crop_and_resize(img1, min_h, min_w)
            img2_cropped = center_crop_and_resize(img2, min_h, min_w)
            
            if self.use_gpu and CUPY_AVAILABLE:
                try:
                    import cupy as cp
                    img1_gpu = cp.asarray(img1_cropped, dtype=cp.float64)
                    img2_gpu = cp.asarray(img2_cropped, dtype=cp.float64)
                    mse_gpu = cp.mean((img1_gpu - img2_gpu) ** 2)
                    mse_cpu = float(mse_gpu)
                    
                    # ç«‹å³é‡Šæ”¾GPUå†…å­˜
                    del img1_gpu, img2_gpu
                    cp.get_default_memory_pool().free_all_blocks()
                    self.stats['gpu_operations'] += 1
                except:
                    mse_cpu = np.mean((img1_cropped.astype(np.float64) - img2_cropped.astype(np.float64)) ** 2)
                    self.stats['cpu_operations'] += 1
            else:
                mse_cpu = np.mean((img1_cropped.astype(np.float64) - img2_cropped.astype(np.float64)) ** 2)
                self.stats['cpu_operations'] += 1
            
            # ç«‹å³é‡Šæ”¾å¤„ç†åçš„å›¾åƒå†…å­˜
            del img1_cropped, img2_cropped
            
            if mse_cpu == 0:
                return 100.0  # å®Œå…¨ç›¸åŒ
            
            # è®¡ç®—PSNR
            max_pixel_value = 255.0
            psnr = 20 * math.log10(max_pixel_value / math.sqrt(mse_cpu))
            
            return psnr
            
        except Exception as e:
            logger.debug(f"âš ï¸ GPU PSNRè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨CPU: {str(e)}")
            return self.calculate_psnr_cpu_fallback(img1, img2)
        finally:
            # GPUå†…å­˜æ¸…ç†
            if self.use_gpu and CUPY_AVAILABLE:
                try:
                    import cupy as cp
                    cp.get_default_memory_pool().free_all_blocks()
                except:
                    pass
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
    
    def calculate_psnr_cpu_fallback(self, img1, img2):
        """CPUç‰ˆæœ¬çš„PSNRè®¡ç®—ï¼ˆä½œä¸ºGPUå¤±è´¥æ—¶çš„å›é€€ï¼‰"""
        try:
            h1, w1 = img1.shape[:2]
            h2, w2 = img2.shape[:2]
            
            min_h = min(h1, h2)
            min_w = min(w1, w2)
            
            def center_crop(img, target_h, target_w):
                h, w = img.shape[:2]
                start_h = (h - target_h) // 2
                start_w = (w - target_w) // 2
                return img[start_h:start_h + target_h, start_w:start_w + target_w]
            
            if h1 != h2 or w1 != w2:
                img1_cropped = center_crop(img1, min_h, min_w)
                img2_cropped = center_crop(img2, min_h, min_w)
            else:
                img1_cropped = img1
                img2_cropped = img2
            
            mse = np.mean((img1_cropped.astype(np.float64) - img2_cropped.astype(np.float64)) ** 2)
            
            if mse == 0:
                return 100.0
            
            max_pixel_value = 255.0
            psnr = 20 * math.log10(max_pixel_value / math.sqrt(mse))
            
            self.stats['cpu_operations'] += 1
            return psnr
            
        except Exception as e:
            logger.debug(f"âš ï¸ CPU PSNRè®¡ç®—å‡ºé”™: {str(e)}")
            return 0.0
    
    def are_images_similar(self, image_path1, image_path2, check_adjacent_frames=True, adjacent_frame_threshold=8):
        """åˆ¤æ–­ä¸¤å¼ å›¾ç‰‡æ˜¯å¦ç›¸ä¼¼ï¼ˆGPUåŠ é€Ÿç‰ˆï¼‰"""
        img1 = None
        img2 = None
        try:
            # ä¼˜å…ˆæ£€æŸ¥ç›¸é‚»å¸§ï¼šå¦‚æœå¸§é—´è·â‰¤8ï¼Œç›´æ¥è®¤å®šä¸ºç›¸ä¼¼
            if check_adjacent_frames:
                frame1 = self.extract_frame_number(image_path1.name if hasattr(image_path1, 'name') else os.path.basename(image_path1))
                frame2 = self.extract_frame_number(image_path2.name if hasattr(image_path2, 'name') else os.path.basename(image_path2))
                
                if frame1 != -1 and frame2 != -1:
                    frame_distance = abs(frame1 - frame2)
                    if frame_distance <= adjacent_frame_threshold:
                        self.stats['adjacent_frames_similar'] += 1
                        
                        clarity1 = self.calculate_image_clarity(image_path1)
                        clarity2 = self.calculate_image_clarity(image_path2)
                        
                        details = {
                            'frame1': frame1,
                            'frame2': frame2,
                            'frame_distance': frame_distance,
                            'clarity1': clarity1,
                            'clarity2': clarity2,
                            'reason': 'adjacent_frames_similar'
                        }
                        
                        return True, 95.0, details
            
            # æ£€æŸ¥å†…å­˜
            if not self.memory_manager.is_gpu_memory_available():
                self.memory_manager.force_gpu_cleanup()
            
            # è¯»å–å›¾ç‰‡
            try:
                img1 = cv2.imread(str(image_path1), cv2.IMREAD_COLOR)
                if img1 is None:
                    return False, 0.0, {'error': f'æ— æ³•è¯»å–å›¾ç‰‡1: {image_path1}'}
            except Exception as e:
                return False, 0.0, {'error': f'å›¾ç‰‡1è¯»å–å¼‚å¸¸: {str(e)}'}
            
            try:
                img2 = cv2.imread(str(image_path2), cv2.IMREAD_COLOR)
                if img2 is None:
                    return False, 0.0, {'error': f'æ— æ³•è¯»å–å›¾ç‰‡2: {image_path2}'}
            except Exception as e:
                return False, 0.0, {'error': f'å›¾ç‰‡2è¯»å–å¼‚å¸¸: {str(e)}'}
            
            # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸
            if img1.shape == (0, 0, 3) or img2.shape == (0, 0, 3):
                return False, 0.0, {'error': 'å›¾ç‰‡å°ºå¯¸æ— æ•ˆ'}
            
            # GPUåŠ é€Ÿçš„ç›¸ä¼¼åº¦è®¡ç®—
            psnr = self.calculate_psnr_gpu(img1, img2)
            
            # ç›¸ä¼¼æ€§åˆ¤æ–­
            is_similar = psnr > self.psnr_threshold
            
            details = {
                'psnr': psnr,
                'psnr_threshold': self.psnr_threshold,
                'gpu_used': self.use_gpu
            }
            
            return is_similar, psnr, details
            
        except Exception as e:
            logger.debug(f"âš ï¸ GPUç›¸ä¼¼åº¦æ£€æµ‹å‡ºé”™: {str(e)}")
            return False, 0.0, {'error': str(e)}
        finally:
            # åŠæ—¶é‡Šæ”¾å†…å­˜
            if img1 is not None:
                del img1
            if img2 is not None:
                del img2
            
            # GPUå†…å­˜æ¸…ç†
            if self.use_gpu and CUPY_AVAILABLE:
                try:
                    import cupy as cp
                    cp.get_default_memory_pool().free_all_blocks()
                except:
                    pass
            
            gc.collect()
    
    def find_similar_groups(self, image_paths, progress_callback=None):
        """GPUåŠ é€Ÿçš„ç›¸ä¼¼å›¾ç‰‡ç»„æ£€æµ‹"""
        self.memory_manager.start_monitoring()
        
        try:
            similar_groups = []
            total_comparisons = len(image_paths) - 1
            current_comparison = 0
            
            logger.info(f"ğŸš€ å¼€å§‹GPUåŠ é€Ÿç›¸ä¼¼å›¾ç‰‡æ£€æµ‹...")
            logger.info(f"   - å›¾ç‰‡æ€»æ•°: {len(image_paths)}")
            logger.info(f"   - PSNRé˜ˆå€¼: {self.psnr_threshold} dB")
            logger.info(f"   - GPUåŠ é€Ÿ: {'å¯ç”¨' if self.use_gpu else 'ç¦ç”¨'}")
            
            if len(image_paths) == 0:
                return similar_groups
            
            i = 0
            while i < len(image_paths):
                current_group = [image_paths[i]]
                
                j = i + 1
                while j < len(image_paths):
                    is_similar, score, details = self.are_images_similar(
                        image_paths[i], image_paths[j], 
                        check_adjacent_frames=True, 
                        adjacent_frame_threshold=self.adjacent_frame_threshold
                    )
                    
                    if is_similar:
                        current_group.append(image_paths[j])
                        image_paths.pop(j)
                    else:
                        j += 1
                    
                    current_comparison += 1
                    
                    if progress_callback and current_comparison % 50 == 0:
                        progress_callback(current_comparison, total_comparisons)
                
                similar_groups.append(current_group)
                i += 1
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['total_images'] = sum(len(g) for g in similar_groups)
            self.stats['similar_groups'] = len([g for g in similar_groups if len(g) > 1])
            self.stats['similar_images'] = sum(len(g) - 1 for g in similar_groups if len(g) > 1)
            self.stats['unique_images'] = len(similar_groups)
            
            logger.info(f"ğŸ“Š GPUåŠ é€Ÿæ£€æµ‹å®Œæˆ:")
            logger.info(f"   - å‘ç° {self.stats['similar_groups']} ä¸ªç›¸ä¼¼åºåˆ—")
            logger.info(f"   - ä¿ç•™ {self.stats['unique_images']} å¼ ä»£è¡¨å›¾ç‰‡")
            logger.info(f"   - è¿‡æ»¤ {self.stats['similar_images']} å¼ å†—ä½™å›¾ç‰‡")
            
            return similar_groups
            
        finally:
            self.memory_manager.stop_monitoring()
    
    def auto_deduplicate(self, image_paths, output_dir, similar_dir):
        """GPUåŠ é€Ÿçš„è‡ªåŠ¨å»é‡"""
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(similar_dir, exist_ok=True)
        
        similar_groups = self.find_similar_groups(image_paths)
        
        logger.info(f"\nğŸš€ å¼€å§‹GPUåŠ é€Ÿè‡ªåŠ¨å»é‡...")
        
        unique_images = []
        similar_pairs = []
        
        for group_idx, group in enumerate(similar_groups, 1):
            if len(group) == 1:
                unique_images.append(group[0])
            else:
                # é€‰æ‹©æ¸…æ™°åº¦æœ€é«˜çš„å›¾ç‰‡ä½œä¸ºä»£è¡¨
                best_image = group[0]
                best_clarity = self.calculate_image_clarity(group[0])
                
                for img_path in group[1:]:
                    clarity = self.calculate_image_clarity(img_path)
                    if clarity > best_clarity:
                        best_clarity = clarity
                        best_image = img_path
                
                unique_images.append(best_image)
                
                # è®°å½•ç›¸ä¼¼å›¾ç‰‡å¯¹
                for img_path in group:
                    if img_path != best_image:
                        similar_pairs.append((best_image, img_path))
        
        # ç§»åŠ¨å”¯ä¸€å›¾ç‰‡
        logger.info(f"\nğŸ“‹ ç§»åŠ¨å”¯ä¸€å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•...")
        successful_moves = 0
        for i, unique_img in enumerate(unique_images, 1):
            try:
                filename = os.path.basename(unique_img)
                dst_path = os.path.join(output_dir, filename)
                
                # å¤„ç†æ–‡ä»¶åå†²çª
                counter = 1
                while os.path.exists(dst_path):
                    name, ext = os.path.splitext(filename)
                    new_filename = f"{name}_{counter}{ext}"
                    dst_path = os.path.join(output_dir, new_filename)
                    counter += 1
                
                shutil.copy2(unique_img, dst_path)
                successful_moves += 1
                
                if i % 100 == 0:
                    logger.info(f"   è¿›åº¦: {i}/{len(unique_images)}")
                    
            except Exception as e:
                logger.error(f"ç§»åŠ¨å›¾ç‰‡å¤±è´¥ {unique_img}: {e}")
        
        # ç§»åŠ¨ç›¸ä¼¼å›¾ç‰‡
        logger.info(f"\nğŸ“‹ ç§»åŠ¨ç›¸ä¼¼å›¾ç‰‡åˆ°ç›¸ä¼¼ç›®å½•...")
        for best_img, similar_img in similar_pairs:
            try:
                filename = os.path.basename(similar_img)
                dst_path = os.path.join(similar_dir, filename)
                
                counter = 1
                while os.path.exists(dst_path):
                    name, ext = os.path.splitext(filename)
                    new_filename = f"{name}_{counter}{ext}"
                    dst_path = os.path.join(similar_dir, new_filename)
                    counter += 1
                
                shutil.copy2(similar_img, dst_path)
                
            except Exception as e:
                logger.error(f"ç§»åŠ¨ç›¸ä¼¼å›¾ç‰‡å¤±è´¥ {similar_img}: {e}")
        
        logger.info(f"   âœ… æˆåŠŸç§»åŠ¨: {successful_moves}/{len(unique_images)} å¼ å›¾ç‰‡")
        
        # GPUå†…å­˜æ¸…ç†
        if self.use_gpu and CUPY_AVAILABLE:
            try:
                import cupy as cp
                cp.get_default_memory_pool().free_all_blocks()
            except:
                pass
        
        return unique_images, similar_pairs


class FastConfig:
    """å¿«é€Ÿæ£€æµ‹é…ç½®ç±»"""
    
    def __init__(self, input_dir=None):
        """
        åˆå§‹åŒ–é…ç½®
        
        Args:
            input_dir: è¾“å…¥ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
        """
        # ç›®å½•é…ç½®
        if input_dir:
            self.INPUT_DIR = input_dir
            # è¾“å‡ºç›®å½•è®¾ç½®åœ¨è¾“å…¥ç›®å½•çš„ä¸‹ä¸€çº§
            self.OUTPUT_BASE_DIR = os.path.join(input_dir, "processed_output")
        else:
            self.INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames70'
            self.OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames70'

        # æ¨¡å‹è·¯å¾„
        self.YOLOV8S_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/yolov8s.pt'
        self.LICENSE_PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'
        
        # æ£€æµ‹é˜ˆå€¼
        self.MIN_FACE_CONFIDENCE_RETINA = 0.85     # æé«˜RetinaFaceç½®ä¿¡åº¦é˜ˆå€¼
        self.MIN_PLATE_CONFIDENCE = 0.8
        self.MIN_TEXT_CONFIDENCE = 0.5
        self.YAW_ANGLE_THRESHOLD = 18.0           # é™ä½yawè§’åº¦é˜ˆå€¼ï¼Œæ›´ä¸¥æ ¼
        
        # è¯„åˆ†ç³»ç»Ÿ
        self.SCORE_PER_CLEAR_FRONTAL_FACE = 2
        self.SCORE_PER_CLEAR_PLATE = 2
        self.SCORE_PER_TEXT = 1
        self.REQUIRED_TOTAL_SCORE = 5
        
        # è¿‘æ™¯åˆ¤æ–­å‚æ•° - æ›´ä¸¥æ ¼åœ°è¿‡æ»¤è¿œå¤„äººè„¸å’Œåè„‘å‹º
        self.MIN_FACE_SIZE = 140                   # è¿›ä¸€æ­¥æé«˜æœ€å°äººè„¸å°ºå¯¸
        self.CLOSE_UP_FACE_RATIO = 0.15            # æé«˜é¢ç§¯æ¯”ä¾‹é˜ˆå€¼
        self.MIN_FACE_AREA = 19600                 # æé«˜æœ€å°äººè„¸é¢ç§¯ (140x140)
        self.MAX_DISTANCE_THRESHOLD = 0.55         # é™ä½è¾¹ç¼˜è·ç¦»é˜ˆå€¼ï¼Œæ›´ä¸¥æ ¼
        self.MIN_FACE_RESOLUTION = 160             # æé«˜æœ€å°åˆ†è¾¨ç‡è¦æ±‚
        
        # ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹é…ç½® - å†…å­˜ä¼˜åŒ–
        self.ENABLE_SIMILARITY_DETECTION = True     # æ˜¯å¦å¯ç”¨ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹
        self.PSNR_THRESHOLD = 50.0                 # PSNRç›¸ä¼¼åº¦é˜ˆå€¼
        self.ADJACENT_FRAME_THRESHOLD = 8          # ç›¸é‚»å¸§ç›¸ä¼¼é˜ˆå€¼
        self.MIN_FRAME_DISTANCE = 5                # æœ€å°å¸§é—´è·
        self.MAX_GPU_MEMORY_MB = 3072              # æœ€å¤§GPUå†…å­˜ä½¿ç”¨é‡(MB) - é™ä½
        self.MAX_CPU_MEMORY_MB = 1536              # æœ€å¤§CPUå†…å­˜ä½¿ç”¨é‡(MB) - é™ä½
        
        # æ–‡ä»¶æ ¼å¼
        self.SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
        
        # ä¼˜åŒ–å‚æ•°ï¼ˆä¸“æ³¨é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼‰
        self.BATCH_SIZE = 16                       # é™ä½æ‰¹å¤„ç†å¤§å°
        self.ENABLE_PREFILTER = False              # ç¦ç”¨é¢„è¿‡æ»¤
        self.PROGRESS_UPDATE_FREQUENCY = 50        # æ›´é¢‘ç¹çš„è¿›åº¦æ›´æ–°
        self.MEMORY_CLEANUP_INTERVAL = 20          # æ¯20ä¸ªæ‰¹æ¬¡å¼ºåˆ¶æ¸…ç†å†…å­˜
    
    def get_output_dirs(self):
        """è·å–è¾“å‡ºç›®å½•é…ç½®"""
        return {
            'high_score': os.path.join(self.OUTPUT_BASE_DIR, "high_score_images"),
            'low_score': os.path.join(self.OUTPUT_BASE_DIR, "low_score_images"),
            'zero_score': os.path.join(self.OUTPUT_BASE_DIR, "zero_score_images"),
            'analysis': os.path.join(self.OUTPUT_BASE_DIR, "analysis"),
            'unique_high_score': os.path.join(self.OUTPUT_BASE_DIR, "unique_high_score_images"),  # æ–°å¢ï¼šå»é‡åçš„é«˜åˆ†å›¾ç‰‡
            'similar_high_score': os.path.join(self.OUTPUT_BASE_DIR, "similar_high_score_images"), # æ–°å¢ï¼šç›¸ä¼¼çš„é«˜åˆ†å›¾ç‰‡
        }

class SimpleProgressBar:
    """ç®€åŒ–çš„è¿›åº¦æ¡"""
    
    def __init__(self, total: int, prefix: str = "Progress"):
        self.total = total
        self.prefix = prefix
        self.current = 0
        self.start_time = time.time()
        self.last_update = 0
    
    def update(self, current: Optional[int] = None):
        if current is not None:
            self.current = current
        else:
            self.current += 1
        
        now = time.time()
        if now - self.last_update < 2.0 and self.current < self.total:  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡
            return
        
        self.last_update = now
        progress = self.current / self.total if self.total > 0 else 0
        percent = progress * 100
        
        elapsed = now - self.start_time
        if self.current > 0 and elapsed > 0:
            speed = self.current / elapsed
            eta = (self.total - self.current) / speed if speed > 0 else 0
            logger.info(f"{self.prefix}: {self.current}/{self.total} ({percent:.1f}%) "
                       f"é€Ÿåº¦: {speed:.1f}/s å‰©ä½™: {eta:.0f}s")
        
        if self.current >= self.total:
            logger.info(f"âœ… {self.prefix} å®Œæˆ!")

class FastProcessor:
    """å¿«é€Ÿå¤„ç†å™¨"""
    
    def __init__(self, config: FastConfig):
        self.config = config
        self.device = None
        self.models = {}
        self.ocr_reader = None
        self.similarity_detector = None  # æ–°å¢ï¼šç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨
        self.stats = {
            'high_score': 0,
            'low_score': 0,
            'zero_score': 0,
            'failed': 0,
            'unique_high_score': 0,       # æ–°å¢ï¼šå»é‡åçš„é«˜åˆ†å›¾ç‰‡ç»Ÿè®¡
            'similar_high_score': 0,      # æ–°å¢ï¼šç›¸ä¼¼çš„é«˜åˆ†å›¾ç‰‡ç»Ÿè®¡
        }
        
    def initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            if torch.cuda.is_available():
                torch.cuda.set_device(0)
                self.device = 'cuda:0'
                torch.cuda.empty_cache()
                torch.cuda.set_per_process_memory_fraction(0.7, device=0)
                logger.info(f"ğŸ”§ GPUåˆå§‹åŒ–æˆåŠŸ: {self.device}")
            else:
                self.device = 'cpu'
                logger.warning("âš ï¸  ä½¿ç”¨CPUæ¨¡å¼")
            
            logger.info("ğŸ”„ åŠ è½½YOLOäººè„¸æ¨¡å‹...")
            self.models['face'] = YOLO(self.config.YOLOV8S_MODEL_PATH)
            
            logger.info("ğŸ”„ åŠ è½½YOLOè½¦ç‰Œæ¨¡å‹...")
            self.models['plate'] = YOLO(self.config.LICENSE_PLATE_MODEL_PATH)
            
            logger.info("ğŸ”„ åˆå§‹åŒ–OCR...")
            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu='cuda' in self.device)
            
            # åˆå§‹åŒ–ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨
            if self.config.ENABLE_SIMILARITY_DETECTION:
                logger.info("ğŸ”„ åˆå§‹åŒ–GPUåŠ é€Ÿç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨...")
                self.similarity_detector = SimilarImageDetectorGPU(
                    psnr_threshold=self.config.PSNR_THRESHOLD,
                    max_gpu_memory_mb=self.config.MAX_GPU_MEMORY_MB,
                    max_cpu_memory_mb=self.config.MAX_CPU_MEMORY_MB,
                    use_gpu='cuda' in self.device,
                    min_frame_distance=self.config.MIN_FRAME_DISTANCE,
                    adjacent_frame_threshold=self.config.ADJACENT_FRAME_THRESHOLD
                )
                logger.info("âœ… ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
            
            logger.info(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ ({self.device})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            try:
                self.device = 'cpu'
                self.models['face'] = YOLO(self.config.YOLOV8S_MODEL_PATH)
                self.models['plate'] = YOLO(self.config.LICENSE_PLATE_MODEL_PATH)
                self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=False)
                
                # CPUæ¨¡å¼ä¸‹ä¹Ÿåˆå§‹åŒ–ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å™¨
                if self.config.ENABLE_SIMILARITY_DETECTION:
                    self.similarity_detector = SimilarImageDetectorGPU(
                        psnr_threshold=self.config.PSNR_THRESHOLD,
                        max_gpu_memory_mb=self.config.MAX_GPU_MEMORY_MB,
                        max_cpu_memory_mb=self.config.MAX_CPU_MEMORY_MB,
                        use_gpu=False,
                        min_frame_distance=self.config.MIN_FRAME_DISTANCE,
                        adjacent_frame_threshold=self.config.ADJACENT_FRAME_THRESHOLD
                    )
                
                logger.info("âœ… CPUæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ")
                return True
            except Exception as e2:
                logger.error(f"âŒ CPUæ¨¡å¼åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e2}")
                return False
    
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """æ”¹è¿›çš„yawè§’åº¦è®¡ç®— - æ›´å‡†ç¡®åŒºåˆ†æ­£è„¸å’Œåè„‘å‹º"""
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            # åŸºç¡€æ£€æŸ¥
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0
            
            # æ”¹è¿›çš„yawè®¡ç®—
            horizontal_offset = nose[0] - eye_center[0]
            normalized_offset = horizontal_offset / eye_width
            
            # æ›´ä¿å®ˆçš„è§’åº¦è®¡ç®—ï¼Œé¿å…è¯¯åˆ¤åè„‘å‹º
            yaw_angle = abs(normalized_offset) * 35.0  # é™ä½ç³»æ•°ä»60æ”¹ä¸º35
            
            # é¢å¤–çš„å¯¹ç§°æ€§æ£€æŸ¥
            if 'left_mouth_corner' in landmarks and 'right_mouth_corner' in landmarks:
                left_mouth = np.array(landmarks['left_mouth_corner'])
                right_mouth = np.array(landmarks['right_mouth_corner'])
                mouth_center = (left_mouth + right_mouth) / 2
                
                # å˜´éƒ¨ä¸­å¿ƒä¹Ÿåº”è¯¥åœ¨åˆç†ä½ç½®
                mouth_offset = mouth_center[0] - eye_center[0]
                mouth_normalized = mouth_offset / eye_width
                
                # å¦‚æœé¼»å­å’Œå˜´éƒ¨åç§»æ–¹å‘ä¸€è‡´ä¸”éƒ½å¾ˆå¤§ï¼Œå¯èƒ½æ˜¯ä¾§è„¸
                if abs(mouth_normalized) > 0.3 and np.sign(normalized_offset) == np.sign(mouth_normalized):
                    yaw_angle = min(yaw_angle * 1.5, 90.0)  # å¢åŠ è§’åº¦æƒ©ç½š
            
            return yaw_angle
        except Exception as e:
            logger.debug(f"Yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0
    
    def validate_frontal_face_features(self, landmarks: Dict, facial_area: List[int]) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºçœŸæ­£çš„æ­£è„¸ç‰¹å¾ï¼ˆéåè„‘å‹ºï¼‰"""
        try:
            x1, y1, x2, y2 = facial_area
            face_width = x2 - x1
            face_height = y2 - y1
            
            # è·å–å…³é”®ç‚¹
            left_eye = np.array(landmarks.get('left_eye', [0, 0]))
            right_eye = np.array(landmarks.get('right_eye', [0, 0]))
            nose = np.array(landmarks.get('nose', [0, 0]))
            left_mouth = np.array(landmarks.get('left_mouth_corner', [0, 0]))
            right_mouth = np.array(landmarks.get('right_mouth_corner', [0, 0]))
            
            # æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦éƒ½å­˜åœ¨ä¸”åœ¨åˆç†ä½ç½®
            required_points = [left_eye, right_eye, nose]
            for point in required_points:
                if np.allclose(point, [0, 0]):
                    return False  # ç¼ºå°‘å…³é”®ç‚¹
                
                # æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦åœ¨é¢éƒ¨åŒºåŸŸå†…
                if not (x1 <= point[0] <= x2 and y1 <= point[1] <= y2):
                    return False
            
            # 1. çœ¼é—´è·æ£€æŸ¥ - æ­£è„¸çš„çœ¼é—´è·åº”è¯¥åˆç†
            eye_distance = np.linalg.norm(right_eye - left_eye)
            eye_distance_ratio = eye_distance / face_width
            
            # æ­£è„¸çœ¼é—´è·é€šå¸¸å é¢éƒ¨å®½åº¦çš„25%-45%
            if not (0.20 <= eye_distance_ratio <= 0.50):
                logger.debug(f"çœ¼é—´è·å¼‚å¸¸: {eye_distance_ratio:.3f}")
                return False
            
            # 2. é¢éƒ¨å¯¹ç§°æ€§æ£€æŸ¥
            eye_center = (left_eye + right_eye) / 2
            
            # é¼»å­åº”è¯¥åœ¨çœ¼éƒ¨ä¸­å¿ƒçº¿é™„è¿‘
            nose_offset = abs(nose[0] - eye_center[0])
            nose_offset_ratio = nose_offset / face_width
            
            if nose_offset_ratio > 0.15:  # é¼»å­åç§»ä¸èƒ½è¶…è¿‡é¢éƒ¨å®½åº¦çš„15%
                logger.debug(f"é¼»å­åç§»è¿‡å¤§: {nose_offset_ratio:.3f}")
                return False
            
            # 3. å‚ç›´ä½ç½®æ£€æŸ¥
            if not np.allclose(left_mouth, [0, 0]) and not np.allclose(right_mouth, [0, 0]):
                mouth_center = (left_mouth + right_mouth) / 2
                
                # çœ¼éƒ¨ç›¸å¯¹ä½ç½®ï¼ˆåº”è¯¥åœ¨ä¸ŠåŠéƒ¨åˆ†ï¼‰
                eye_y_ratio = (eye_center[1] - y1) / face_height
                nose_y_ratio = (nose[1] - y1) / face_height
                mouth_y_ratio = (mouth_center[1] - y1) / face_height
                
                # æ­£è„¸çš„å…¸å‹å‚ç›´åˆ†å¸ƒ
                if not (0.15 <= eye_y_ratio <= 0.45):
                    logger.debug(f"çœ¼éƒ¨å‚ç›´ä½ç½®å¼‚å¸¸: {eye_y_ratio:.3f}")
                    return False
                
                if not (0.35 <= nose_y_ratio <= 0.70):
                    logger.debug(f"é¼»å­å‚ç›´ä½ç½®å¼‚å¸¸: {nose_y_ratio:.3f}")
                    return False
                
                if not (0.60 <= mouth_y_ratio <= 0.90):
                    logger.debug(f"å˜´éƒ¨å‚ç›´ä½ç½®å¼‚å¸¸: {mouth_y_ratio:.3f}")
                    return False
                
                # å˜´éƒ¨ä¹Ÿåº”è¯¥ç›¸å¯¹å±…ä¸­
                mouth_offset = abs(mouth_center[0] - eye_center[0])
                mouth_offset_ratio = mouth_offset / face_width
                
                if mouth_offset_ratio > 0.20:  # å˜´éƒ¨åç§»ä¸èƒ½è¶…è¿‡20%
                    logger.debug(f"å˜´éƒ¨åç§»è¿‡å¤§: {mouth_offset_ratio:.3f}")
                    return False
            
            # 4. çœ¼éƒ¨æ°´å¹³å¯¹é½æ£€æŸ¥
            eye_level_diff = abs(left_eye[1] - right_eye[1])
            eye_level_ratio = eye_level_diff / face_height
            
            if eye_level_ratio > 0.1:  # çœ¼éƒ¨é«˜åº¦å·®ä¸èƒ½è¶…è¿‡é¢éƒ¨é«˜åº¦çš„10%
                logger.debug(f"çœ¼éƒ¨é«˜åº¦å·®å¼‚è¿‡å¤§: {eye_level_ratio:.3f}")
                return False
            
            return True
            
        except Exception as e:
            logger.debug(f"æ­£è„¸ç‰¹å¾éªŒè¯å¤±è´¥: {e}")
            return False
    
    def process_single_image(self, image_path: str) -> Dict:
        """å¤„ç†å•å¼ å›¾ç‰‡ - å†…å­˜ä¼˜åŒ–ç‰ˆ"""
        img = None  # æå‰å£°æ˜å›¾ç‰‡å˜é‡
        try:
            filename = os.path.basename(image_path)
            start_time = time.time()
            
            total_score = 0
            frontal_face_count = 0
            clear_plate_count = 0
            text_count = 0
            
            # 1. RetinaFaceæ£€æµ‹æ­£è„¸
            try:
                detections = RetinaFace.detect_faces(image_path)
                
                if isinstance(detections, dict) and len(detections) > 0:
                    img = cv2.imread(image_path, cv2.IMREAD_COLOR)
                    if img is not None:
                        img_height, img_width = img.shape[:2]
                        img_area = img_width * img_height
                        
                        # å¦‚æœå›¾åƒå¤ªå¤§ï¼Œç¼©æ”¾ä»¥èŠ‚çœå†…å­˜
                        if img_height > 1024 or img_width > 1024:
                            scale_factor = min(1024/img_height, 1024/img_width)
                            new_height, new_width = int(img_height * scale_factor), int(img_width * scale_factor)
                            img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
                            # æ›´æ–°å›¾åƒå°ºå¯¸å’Œé¢ç§¯
                            img_height, img_width = img.shape[:2]
                            img_area = img_width * img_height
                        
                        for face_key, face_data in detections.items():
                            confidence = face_data.get('score', 0.0)
                            if confidence < self.config.MIN_FACE_CONFIDENCE_RETINA:
                                continue
                            
                            facial_area = face_data['facial_area']
                            landmarks = face_data.get('landmarks', {})
                            
                            if not landmarks:
                                continue
                            
                            x1, y1, x2, y2 = facial_area
                            face_width = x2 - x1
                            face_height = y2 - y1
                            face_area = face_width * face_height
                            
                            # åŸºç¡€å°ºå¯¸è¿‡æ»¤ - æ›´ä¸¥æ ¼
                            if min(face_width, face_height) < self.config.MIN_FACE_SIZE:
                                continue
                            
                            if face_area < self.config.MIN_FACE_AREA:
                                continue
                            
                            # åˆ†è¾¨ç‡è´¨é‡æ£€æŸ¥ - æ–°å¢
                            face_resolution = max(face_width, face_height)
                            if face_resolution < self.config.MIN_FACE_RESOLUTION:
                                continue
                            
                            # è·ç¦»å›¾ç‰‡è¾¹ç¼˜æ£€æŸ¥ - é¿å…è¾¹ç¼˜çš„è¿œæ™¯äººè„¸
                            face_center_x = (x1 + x2) / 2
                            face_center_y = (y1 + y2) / 2
                            
                            # è®¡ç®—äººè„¸ä¸­å¿ƒåˆ°å›¾ç‰‡è¾¹ç¼˜çš„æœ€å°è·ç¦»æ¯”ä¾‹
                            edge_dist_x = min(face_center_x / img_width, (img_width - face_center_x) / img_width)
                            edge_dist_y = min(face_center_y / img_height, (img_height - face_center_y) / img_height)
                            min_edge_distance = min(edge_dist_x, edge_dist_y)
                            
                            # å¦‚æœäººè„¸å¤ªæ¥è¿‘è¾¹ç¼˜ï¼Œå¯èƒ½æ˜¯è¿œæ™¯ï¼Œè¿‡æ»¤æ‰
                            if min_edge_distance < (1 - self.config.MAX_DISTANCE_THRESHOLD):
                                continue
                            
                            # é¢ç§¯æ¯”ä¾‹æ£€æŸ¥ - æ›´ä¸¥æ ¼
                            area_ratio = face_area / img_area
                            is_close_up = area_ratio >= self.config.CLOSE_UP_FACE_RATIO
                            
                            # é¢å¤–çš„è¿‘æ™¯éªŒè¯ï¼šäººè„¸å®½åº¦å å›¾ç‰‡å®½åº¦çš„æ¯”ä¾‹
                            width_ratio = face_width / img_width
                            height_ratio = face_height / img_height
                            size_ratio = max(width_ratio, height_ratio)
                            
                            # åªæœ‰è¶³å¤Ÿå¤§çš„äººè„¸æ‰è¢«è®¤ä¸ºæ˜¯è¿‘æ™¯
                            is_large_enough = size_ratio >= 0.15  # äººè„¸è‡³å°‘å å›¾ç‰‡å°ºå¯¸çš„15%
                            
                            yaw_angle = self.calculate_yaw_angle(landmarks)
                            is_frontal = yaw_angle <= self.config.YAW_ANGLE_THRESHOLD
                            
                            # æ–°å¢ï¼šéªŒè¯æ˜¯å¦ä¸ºçœŸæ­£çš„æ­£è„¸ç‰¹å¾ï¼ˆéåè„‘å‹ºï¼‰
                            is_valid_frontal = self.validate_frontal_face_features(landmarks, facial_area)
                            
                            # ç»¼åˆåˆ¤æ–­ï¼šæ­£é¢ + è¿‘æ™¯ + è¶³å¤Ÿå¤§ + ä¸åœ¨è¾¹ç¼˜ + ç‰¹å¾éªŒè¯
                            if is_frontal and is_close_up and is_large_enough and is_valid_frontal:
                                frontal_face_count += 1
                                total_score += self.config.SCORE_PER_CLEAR_FRONTAL_FACE
                                logger.debug(f"æ£€æµ‹åˆ°æ­£è„¸: yaw={yaw_angle:.1f}Â°, é¢ç§¯æ¯”={area_ratio:.3f}, å°ºå¯¸æ¯”={size_ratio:.3f}")
                            elif not is_valid_frontal:
                                logger.debug(f"æ‹’ç»åè„‘å‹º/ä¾§è„¸: yaw={yaw_angle:.1f}Â°, ç‰¹å¾éªŒè¯å¤±è´¥")
                            else:
                                logger.debug(f"æ‹’ç»äººè„¸: yaw={yaw_angle:.1f}Â°, é¢ç§¯æ¯”={area_ratio:.3f}, å°ºå¯¸æ¯”={size_ratio:.3f}")
                    
                    # é‡Šæ”¾å›¾åƒå†…å­˜
                    if img is not None:
                        del img
                        img = None
                            
            except Exception as e:
                logger.debug(f"RetinaFaceæ£€æµ‹å¤±è´¥ {image_path}: {e}")
                if img is not None:
                    del img
                    img = None
            
            # 2. æ£€æµ‹è½¦ç‰Œ
            try:
                plate_results = self.models['plate']([image_path], verbose=False, device=self.device)
                
                if plate_results and len(plate_results) > 0:
                    result = plate_results[0]
                    if result.boxes is not None and len(result.boxes) > 0:
                        for box in result.boxes:
                            confidence = float(box.conf[0])
                            if confidence >= self.config.MIN_PLATE_CONFIDENCE:
                                clear_plate_count += 1
                                total_score += self.config.SCORE_PER_CLEAR_PLATE
                                
            except Exception as e:
                logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            
            # 3. æ£€æµ‹æ–‡å­—
            try:
                if self.ocr_reader is not None:
                    img = cv2.imread(image_path, cv2.IMREAD_COLOR)
                    if img is not None:
                        # å¦‚æœå›¾åƒè¿‡å¤§ï¼Œç¼©æ”¾ä»¥èŠ‚çœå†…å­˜
                        height, width = img.shape[:2]
                        if height > 800 or width > 800:
                            scale_factor = min(800/height, 800/width)
                            new_height, new_width = int(height * scale_factor), int(width * scale_factor)
                            img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
                        
                        ocr_results = self.ocr_reader.readtext(img)
                        
                        # ç«‹å³é‡Šæ”¾å›¾åƒå†…å­˜
                        del img
                        img = None
                        
                        if ocr_results:
                            for bbox, text, confidence in ocr_results:
                                confidence = float(confidence) if confidence is not None else 0.0
                                
                                if confidence >= self.config.MIN_TEXT_CONFIDENCE:
                                    cleaned_text = text.strip()
                                    if len(cleaned_text) >= 2:
                                        text_count += 1
                                        total_score += self.config.SCORE_PER_TEXT
                                        
            except Exception as e:
                logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
                if img is not None:
                    del img
                    img = None
            
            # 4. ç¡®å®šåˆ†ç±»
            if total_score > self.config.REQUIRED_TOTAL_SCORE:
                category = 'high_score'
            elif total_score > 0:
                category = 'low_score'
            else:
                category = 'zero_score'
            
            processing_time = time.time() - start_time
            
            return {
                'filename': filename,
                'category': category,
                'total_score': total_score,
                'frontal_faces': frontal_face_count,
                'clear_plates': clear_plate_count,
                'texts': text_count,
                'processing_time': processing_time
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return {
                'filename': os.path.basename(image_path),
                'category': 'failed',
                'error': str(e),
                'total_score': 0
            }
        finally:
            # ç¡®ä¿å›¾åƒå†…å­˜è¢«é‡Šæ”¾
            if img is not None:
                del img
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
    
    def process_batch(self, image_paths: List[str]) -> List[Tuple[str, Dict]]:
        """æ‰¹é‡å¤„ç†"""
        results = []
        for image_path in image_paths:
            result = self.process_single_image(image_path)
            results.append((image_path, result))
        return results
    
    def move_image(self, image_path: str, category: str, output_dirs: Dict[str, str]) -> bool:
        """ç§»åŠ¨å›¾ç‰‡åˆ°åˆ†ç±»ç›®å½•"""
        try:
            filename = os.path.basename(image_path)
            output_dir = output_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            shutil.copy2(image_path, output_path)
            os.remove(image_path)
            return True
            
        except Exception as e:
            logger.error(f"ç§»åŠ¨å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return False
    
    def process_high_score_similarity(self, high_score_dir: str, output_dirs: Dict[str, str]):
        """å¤„ç†é«˜åˆ†å›¾ç‰‡çš„ç›¸ä¼¼åº¦æ£€æµ‹å’Œå»é‡"""
        if not self.config.ENABLE_SIMILARITY_DETECTION or not self.similarity_detector:
            logger.info("âš ï¸ ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å·²ç¦ç”¨ï¼Œè·³è¿‡é«˜åˆ†å›¾ç‰‡å»é‡")
            return
        
        logger.info("ğŸ” å¼€å§‹å¤„ç†é«˜åˆ†å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹...")
        
        # è·å–é«˜åˆ†å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨
        high_score_images = []
        for ext in self.config.SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            high_score_images.extend(Path(high_score_dir).glob(pattern))
        
        high_score_images = sorted([str(f) for f in high_score_images if f.is_file()])
        
        if len(high_score_images) == 0:
            logger.info("âŒ æœªæ‰¾åˆ°é«˜åˆ†å›¾ç‰‡ï¼Œè·³è¿‡ç›¸ä¼¼åº¦æ£€æµ‹")
            return
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(high_score_images)} å¼ é«˜åˆ†å›¾ç‰‡è¿›è¡Œç›¸ä¼¼åº¦æ£€æµ‹")
        
        try:
            # æ‰§è¡Œç›¸ä¼¼åº¦æ£€æµ‹å’Œè‡ªåŠ¨å»é‡
            unique_images, similar_pairs = self.similarity_detector.auto_deduplicate(
                high_score_images,
                output_dirs['unique_high_score'],
                output_dirs['similar_high_score']
            )
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.stats['unique_high_score'] = len(unique_images)
            self.stats['similar_high_score'] = len(similar_pairs)
            
            logger.info("âœ… é«˜åˆ†å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹å®Œæˆ!")
            logger.info(f"   - å»é‡åä¿ç•™: {self.stats['unique_high_score']} å¼ ")
            logger.info(f"   - ç›¸ä¼¼å›¾ç‰‡: {self.stats['similar_high_score']} å¼ ")
            logger.info(f"   - å‹ç¼©ç‡: {(1 - self.stats['unique_high_score'] / len(high_score_images)) * 100:.1f}%")
            
        except Exception as e:
            logger.error(f"âŒ é«˜åˆ†å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°†åŸå§‹é«˜åˆ†å›¾ç‰‡å¤åˆ¶åˆ°uniqueç›®å½•...")
            
            # å¤±è´¥æ—¶å°†æ‰€æœ‰é«˜åˆ†å›¾ç‰‡å¤åˆ¶åˆ°uniqueç›®å½•
            for img_path in high_score_images:
                try:
                    filename = os.path.basename(img_path)
                    dst_path = os.path.join(output_dirs['unique_high_score'], filename)
                    shutil.copy2(img_path, dst_path)
                    self.stats['unique_high_score'] += 1
                except Exception as copy_e:
                    logger.error(f"å¤åˆ¶å›¾ç‰‡å¤±è´¥ {img_path}: {copy_e}")
    
    def generate_similarity_report(self, output_dirs: Dict[str, str]):
        """ç”Ÿæˆç›¸ä¼¼åº¦æ£€æµ‹æŠ¥å‘Š"""
        if not self.similarity_detector:
            return
        
        try:
            report_file = os.path.join(output_dirs['analysis'], 'similarity_detection_report.txt')
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("GPUåŠ é€Ÿç›¸ä¼¼å›¾ç‰‡æ£€æµ‹æŠ¥å‘Š\n")
                f.write("=" * 60 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("é…ç½®ä¿¡æ¯:\n")
                f.write(f"  - PSNRé˜ˆå€¼: {self.config.PSNR_THRESHOLD} dB\n")
                f.write(f"  - ç›¸é‚»å¸§é˜ˆå€¼: {self.config.ADJACENT_FRAME_THRESHOLD} å¸§\n")
                f.write(f"  - æœ€å°å¸§é—´è·: {self.config.MIN_FRAME_DISTANCE} å¸§\n")
                f.write(f"  - GPUåŠ é€Ÿ: {'å¯ç”¨' if self.similarity_detector.use_gpu else 'ç¦ç”¨'}\n\n")
                
                f.write("æ£€æµ‹ç»Ÿè®¡:\n")
                f.write(f"  - å¤„ç†çš„å›¾ç‰‡å¯¹: {self.similarity_detector.stats['processed_pairs']}\n")
                f.write(f"  - GPUæ“ä½œæ¬¡æ•°: {self.similarity_detector.stats['gpu_operations']}\n")
                f.write(f"  - CPUæ“ä½œæ¬¡æ•°: {self.similarity_detector.stats['cpu_operations']}\n")
                f.write(f"  - ç›¸é‚»å¸§ç›¸ä¼¼æ£€æµ‹: {self.similarity_detector.stats['adjacent_frames_similar']}\n")
                f.write(f"  - å†…å­˜æ¸…ç†æ¬¡æ•°: {self.similarity_detector.stats['memory_cleanups']}\n\n")
                
                f.write("å»é‡ç»“æœ:\n")
                f.write(f"  - å»é‡å‰é«˜åˆ†å›¾ç‰‡: {self.stats['high_score']}\n")
                f.write(f"  - å»é‡åå”¯ä¸€å›¾ç‰‡: {self.stats['unique_high_score']}\n")
                f.write(f"  - è¯†åˆ«ä¸ºç›¸ä¼¼çš„å›¾ç‰‡: {self.stats['similar_high_score']}\n")
                
                if self.stats['high_score'] > 0:
                    compression_rate = (1 - self.stats['unique_high_score'] / self.stats['high_score']) * 100
                    f.write(f"  - å‹ç¼©ç‡: {compression_rate:.1f}%\n")
            
            logger.info(f"ğŸ“„ ç›¸ä¼¼åº¦æ£€æµ‹æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç›¸ä¼¼åº¦æ£€æµ‹æŠ¥å‘Šå¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œå¿«é€Ÿæ£€æµ‹å™¨"""
        logger.info("ğŸš€ å¯åŠ¨å¿«é€Ÿäººè„¸è½¦ç‰Œæ£€æµ‹å™¨...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {self.config.INPUT_DIR}")
        logger.info(f"ğŸ“¦ åˆå§‹æ‰¹å¤„ç†å¤§å°: {self.config.BATCH_SIZE} (å°†åŠ¨æ€è°ƒæ•´)")
        logger.info(f"ğŸ¯ é¢„è¿‡æ»¤: {'å¯ç”¨' if self.config.ENABLE_PREFILTER else 'ç¦ç”¨'}")
        logger.info(f"ğŸ” ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹: {'å¯ç”¨' if self.config.ENABLE_SIMILARITY_DETECTION else 'ç¦ç”¨'}")
        logger.info(f"ğŸ‘¤ æ”¹è¿›æ­£è„¸æ£€æµ‹: ç½®ä¿¡åº¦â‰¥{self.config.MIN_FACE_CONFIDENCE_RETINA}, yawâ‰¤{self.config.YAW_ANGLE_THRESHOLD}Â°")
        logger.info(f"ğŸ‘¤ äººè„¸è¿‡æ»¤ç­–ç•¥: æœ€å°å°ºå¯¸{self.config.MIN_FACE_SIZE}px, é¢ç§¯æ¯”ä¾‹â‰¥{self.config.CLOSE_UP_FACE_RATIO:.1%}")
        logger.info(f"ğŸ” ç‰¹å¾éªŒè¯: å¯ç”¨åè„‘å‹ºæ£€æµ‹å’Œé¢éƒ¨å¯¹ç§°æ€§éªŒè¯")
        logger.info(f"ğŸ” è¿œæ™¯è¿‡æ»¤: æœ€å°åˆ†è¾¨ç‡{self.config.MIN_FACE_RESOLUTION}px, è¾¹ç¼˜è·ç¦»â‰¥{self.config.MAX_DISTANCE_THRESHOLD:.1%}")
        logger.info(f"ğŸ’¾ å†…å­˜é™åˆ¶: GPU {self.config.MAX_GPU_MEMORY_MB}MB, CPU {self.config.MAX_CPU_MEMORY_MB}MB")
        logger.info(f"ğŸ§¹ å†…å­˜æ¸…ç†: æ¯{self.config.MEMORY_CLEANUP_INTERVAL}ä¸ªæ‰¹æ¬¡å¼ºåˆ¶æ¸…ç†")
        
        if self.config.ENABLE_SIMILARITY_DETECTION:
            logger.info(f"ğŸ“Š ç›¸ä¼¼åº¦å‚æ•°: PSNRé˜ˆå€¼{self.config.PSNR_THRESHOLD}dB, ç›¸é‚»å¸§é˜ˆå€¼{self.config.ADJACENT_FRAME_THRESHOLD}å¸§")
        
        # åˆå§‹åŒ–æ¨¡å‹
        if not self.initialize_models():
            logger.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dirs = self.config.get_output_dirs()
        for name, dir_path in output_dirs.items():
            os.makedirs(dir_path, exist_ok=True)
        
        # è·å–å›¾åƒæ–‡ä»¶
        input_path = Path(self.config.INPUT_DIR)
        image_files = []
        for ext in self.config.SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            image_files.extend(input_path.glob(pattern))
        
        image_files = sorted([str(f) for f in image_files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return
        
        # æ‰¹é‡å¤„ç† - å†…å­˜ä¼˜åŒ–ç‰ˆ
        progress = SimpleProgressBar(len(image_files), "å¤„ç†è¿›åº¦")
        processed = 0
        memory_manager = GPUMemoryManager()  # åˆ›å»ºå†…å­˜ç®¡ç†å™¨
        
        for i in range(0, len(image_files), self.config.BATCH_SIZE):
            # åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°
            current_batch_size = memory_manager.get_dynamic_batch_size(self.config.BATCH_SIZE)
            batch = image_files[i:i + current_batch_size]
            
            try:
                batch_results = self.process_batch(batch)
                
                for image_path, result in batch_results:
                    category = result.get('category', 'failed')
                    if category != 'failed':
                        if self.move_image(image_path, category, output_dirs):
                            self.stats[category] += 1
                        else:
                            self.stats['failed'] += 1
                    else:
                        self.stats['failed'] += 1
                    
                    processed += 1
                
                progress.update(processed)
                
                # æ›´é¢‘ç¹çš„å†…å­˜æ¸…ç†
                batch_number = (i // current_batch_size) + 1
                if batch_number % self.config.MEMORY_CLEANUP_INTERVAL == 0:
                    logger.info("ğŸ§¹ æ‰§è¡Œå†…å­˜æ¸…ç†...")
                    if self.device and 'cuda' in self.device:
                        torch.cuda.empty_cache()
                    memory_manager.force_gpu_cleanup()
                    # å¼ºåˆ¶Pythonåƒåœ¾å›æ”¶
                    for _ in range(3):
                        gc.collect()
                    logger.info("âœ… å†…å­˜æ¸…ç†å®Œæˆ")
                    
            except Exception as e:
                logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
                for image_path in batch:
                    self.stats['failed'] += 1
                    processed += 1
                progress.update(processed)
        
        # æ‰“å°ç»Ÿè®¡ç»“æœ
        logger.info("="*60)
        logger.info("ğŸ‰ åŸºç¡€æ£€æµ‹å®Œæˆï¼ç»Ÿè®¡ç»“æœ:")
        logger.info(f"âœ… é«˜åˆ†å›¾ç‰‡(>5åˆ†): {self.stats['high_score']:,} å¼ ")
        logger.info(f"ğŸ“Š ä½åˆ†å›¾ç‰‡(1-5åˆ†): {self.stats['low_score']:,} å¼ ")
        logger.info(f"âŒ é›¶åˆ†å›¾ç‰‡(0åˆ†): {self.stats['zero_score']:,} å¼ ")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,} å¼ ")
        
        total = sum([self.stats['high_score'], self.stats['low_score'], self.stats['zero_score'], self.stats['failed']])
        if total > 0:
            success_rate = (self.stats['high_score'] / total) * 100
            logger.info(f"ğŸ“ˆ ç¬¦åˆè¦æ±‚æ¯”ä¾‹: {success_rate:.1f}%")
        
        # å¤„ç†é«˜åˆ†å›¾ç‰‡çš„ç›¸ä¼¼åº¦æ£€æµ‹
        if self.config.ENABLE_SIMILARITY_DETECTION and self.stats['high_score'] > 0:
            logger.info("="*60)
            logger.info("ğŸ” å¼€å§‹é«˜åˆ†å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹å’Œå»é‡...")
            
            self.process_high_score_similarity(
                output_dirs['high_score'], 
                output_dirs
            )
            
            # ç”Ÿæˆç›¸ä¼¼åº¦æ£€æµ‹æŠ¥å‘Š
            self.generate_similarity_report(output_dirs)
            
            logger.info("="*60)
            logger.info("ğŸ‰ ç›¸ä¼¼åº¦æ£€æµ‹å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
            logger.info(f"âœ… åŸå§‹é«˜åˆ†å›¾ç‰‡: {self.stats['high_score']:,} å¼ ")
            logger.info(f"ğŸ¯ å»é‡åå”¯ä¸€å›¾ç‰‡: {self.stats['unique_high_score']:,} å¼ ")
            logger.info(f"ğŸ“‹ ç›¸ä¼¼å›¾ç‰‡: {self.stats['similar_high_score']:,} å¼ ")
            
            if self.stats['high_score'] > 0:
                final_compression = (1 - self.stats['unique_high_score'] / self.stats['high_score']) * 100
                logger.info(f"ğŸ“ˆ æœ€ç»ˆå‹ç¼©ç‡: {final_compression:.1f}%")
        else:
            logger.info("âš ï¸ ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹å·²ç¦ç”¨æˆ–æ— é«˜åˆ†å›¾ç‰‡")
        
        logger.info("="*60)

def get_image_files(input_dir):
    """è·å–ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å¹¶æ£€æŸ¥å®Œæ•´æ€§"""
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp', '.gif'}
    image_files = []
    corrupted_files = []
    
    input_path = Path(input_dir)
    if not input_path.exists():
        logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return []
    
    logger.info(f"ğŸ” æ‰«æå›¾ç‰‡æ–‡ä»¶...")
    all_files = []
    for ext in image_extensions:
        all_files.extend(input_path.glob(f'*{ext}'))
        all_files.extend(input_path.glob(f'*{ext.upper()}'))
    
    logger.info(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶ï¼Œæ£€æŸ¥å®Œæ•´æ€§...")
    
    for file_path in all_files:
        try:
            # ç®€å•çš„å›¾ç‰‡å®Œæ•´æ€§æ£€æŸ¥
            img = cv2.imread(str(file_path), cv2.IMREAD_COLOR)
            if img is not None and img.shape[0] > 0 and img.shape[1] > 0:
                image_files.append(file_path)
            else:
                corrupted_files.append(file_path)
        except Exception as e:
            logger.debug(f"å›¾ç‰‡è¯»å–å¤±è´¥ {file_path}: {e}")
            corrupted_files.append(file_path)
    
    if corrupted_files:
        logger.warning(f"âŒ å‘ç° {len(corrupted_files)} ä¸ªæŸåæˆ–æ— æ³•è¯»å–çš„æ–‡ä»¶:")
        for corrupted_file in corrupted_files[:10]:
            logger.warning(f"   - {corrupted_file.name}")
        if len(corrupted_files) > 10:
            logger.warning(f"   - ... è¿˜æœ‰ {len(corrupted_files) - 10} ä¸ªæ–‡ä»¶")
        logger.info(f"âœ… æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶: {len(image_files)} ä¸ª")
    else:
        logger.info(f"âœ… æ‰€æœ‰ {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶éƒ½æœ‰æ•ˆ")
    
    return sorted(image_files)


def get_user_input_directory():
    """è·å–ç”¨æˆ·è¾“å…¥çš„ç›®å½•è·¯å¾„"""
    print("ğŸš€ å¿«é€Ÿäººè„¸è½¦ç‰Œæ£€æµ‹å™¨ - äº¤äº’å¼ç‰ˆæœ¬")
    print("=" * 60)
    
    while True:
        print("\nğŸ“ è¯·è¾“å…¥è¦å¤„ç†çš„å›¾ç‰‡ç›®å½•è·¯å¾„:")
        print("   (è¾“å…¥ 'q' æˆ– 'quit' é€€å‡ºç¨‹åº)")
        print("   (è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯)")
        
        user_input = input("ğŸ‘‰ å›¾ç‰‡ç›®å½•è·¯å¾„: ").strip()
        
        # å¤„ç†é€€å‡ºå‘½ä»¤
        if user_input.lower() in ['q', 'quit', 'exit']:
            print("ğŸ‘‹ ç¨‹åºé€€å‡º")
            return None
        
        # å¤„ç†å¸®åŠ©å‘½ä»¤
        if user_input.lower() == 'help':
            print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
            print("   - è¯·è¾“å…¥åŒ…å«å›¾ç‰‡çš„å®Œæ•´ç›®å½•è·¯å¾„")
            print("   - æ”¯æŒçš„å›¾ç‰‡æ ¼å¼: .jpg, .jpeg, .png, .bmp, .webp")
            print("   - è¾“å‡ºå°†ä¿å­˜åœ¨è¾“å…¥ç›®å½•ä¸‹çš„ 'processed_output' æ–‡ä»¶å¤¹ä¸­")
            print("   - ç¨‹åºä¼šè‡ªåŠ¨æ£€æµ‹äººè„¸ã€è½¦ç‰Œå’Œæ–‡å­—ï¼Œå¹¶è¿›è¡Œç›¸ä¼¼å›¾ç‰‡å»é‡")
            print("   - ç¤ºä¾‹è·¯å¾„: /home/zhiqics/sanjian/predata/output_frames70")
            continue
        
        # éªŒè¯è¾“å…¥
        if not user_input:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ç›®å½•è·¯å¾„")
            continue
        
        # å±•å¼€ç”¨æˆ·ç›®å½•ç¬¦å·
        if user_input.startswith('~'):
            user_input = os.path.expanduser(user_input)
        
        # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        abs_path = os.path.abspath(user_input)
        
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(abs_path):
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {abs_path}")
            print("   è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
            continue
        
        if not os.path.isdir(abs_path):
            print(f"âŒ è·¯å¾„ä¸æ˜¯ç›®å½•: {abs_path}")
            continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯»å–æƒé™
        if not os.access(abs_path, os.R_OK):
            print(f"âŒ æ²¡æœ‰è¯»å–æƒé™: {abs_path}")
            continue
        
        # é¢„è§ˆç›®å½•å†…å®¹
        try:
            image_files = []
            supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
            
            for file in os.listdir(abs_path):
                file_path = os.path.join(abs_path, file)
                if os.path.isfile(file_path):
                    _, ext = os.path.splitext(file.lower())
                    if ext in supported_formats:
                        image_files.append(file)
            
            if len(image_files) == 0:
                print(f"âš ï¸ ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶: {abs_path}")
                print(f"   æ”¯æŒçš„æ ¼å¼: {', '.join(supported_formats)}")
                
                choice = input("æ˜¯å¦ç»§ç»­å¤„ç†æ­¤ç›®å½•? (y/n): ").strip().lower()
                if choice not in ['y', 'yes']:
                    continue
            else:
                print(f"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡æ–‡ä»¶")
                print(f"   ç›®å½•: {abs_path}")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶åä½œä¸ºé¢„è§ˆ
                preview_count = min(5, len(image_files))
                print(f"   é¢„è§ˆå‰{preview_count}ä¸ªæ–‡ä»¶:")
                for i, filename in enumerate(image_files[:preview_count]):
                    print(f"     {i+1}. {filename}")
                
                if len(image_files) > preview_count:
                    print(f"     ... è¿˜æœ‰ {len(image_files) - preview_count} ä¸ªæ–‡ä»¶")
        
        except Exception as e:
            print(f"âŒ è¯»å–ç›®å½•å¤±è´¥: {e}")
            continue
        
        # æ˜¾ç¤ºè¾“å‡ºç›®å½•
        output_dir = os.path.join(abs_path, "processed_output")
        print(f"\nğŸ“¤ è¾“å‡ºç›®å½•: {output_dir}")
        
        # ç¡®è®¤å¤„ç†
        print(f"\nğŸ” é…ç½®é¢„è§ˆ:")
        print(f"   - è¾“å…¥ç›®å½•: {abs_path}")
        print(f"   - è¾“å‡ºç›®å½•: {output_dir}")
        print(f"   - å›¾ç‰‡æ•°é‡: {len(image_files) if 'image_files' in locals() else 'æœªçŸ¥'}")
        print(f"   - ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹: å¯ç”¨")
        print(f"   - GPUåŠ é€Ÿ: {'å¯ç”¨' if torch.cuda.is_available() else 'ç¦ç”¨'}")
        
        confirm = input("\nç¡®è®¤å¼€å§‹å¤„ç†? (y/n): ").strip().lower()
        if confirm in ['y', 'yes']:
            return abs_path
        else:
            print("å–æ¶ˆå¤„ç†ï¼Œè¯·é‡æ–°è¾“å…¥ç›®å½•è·¯å¾„")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # è·å–ç”¨æˆ·è¾“å…¥çš„ç›®å½•
        input_dir = get_user_input_directory()
        
        if input_dir is None:
            return  # ç”¨æˆ·é€‰æ‹©é€€å‡º
        
        # åˆ›å»ºé…ç½®
        config = FastConfig(input_dir)
        
        print(f"\nğŸ”§ åˆå§‹åŒ–æ£€æµ‹å™¨...")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {config.INPUT_DIR}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {config.OUTPUT_BASE_DIR}")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        missing_models = []
        if not os.path.exists(config.YOLOV8S_MODEL_PATH):
            missing_models.append(f"YOLOv8sæ¨¡å‹: {config.YOLOV8S_MODEL_PATH}")
        
        if not os.path.exists(config.LICENSE_PLATE_MODEL_PATH):
            missing_models.append(f"è½¦ç‰Œæ£€æµ‹æ¨¡å‹: {config.LICENSE_PLATE_MODEL_PATH}")
        
        if missing_models:
            print(f"\nâš ï¸ ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨:")
            for model in missing_models:
                print(f"   - {model}")
            
            print(f"\nğŸ’¡ å»ºè®®æ“ä½œ:")
            print(f"   1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print(f"   2. ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹æ–‡ä»¶")
            print(f"   3. æˆ–è€…ç¨‹åºå°†å°è¯•è‡ªåŠ¨ä¸‹è½½é»˜è®¤æ¨¡å‹")
            
            choice = input("\næ˜¯å¦ç»§ç»­è¿è¡Œ? (y/n): ").strip().lower()
            if choice not in ['y', 'yes']:
                print("ç¨‹åºé€€å‡º")
                return
        
        # è¿è¡Œæ£€æµ‹å™¨
        processor = FastProcessor(config)
        processor.run()
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {config.OUTPUT_BASE_DIR}")
        print(f"ğŸ“Š è¯·æŸ¥çœ‹å„åˆ†ç±»ç›®å½•ä¸­çš„å›¾ç‰‡å’Œåˆ†ææŠ¥å‘Š")
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print("\nâš¡ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
        print("è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶")


if __name__ == "__main__":
    main()
