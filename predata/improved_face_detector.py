#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„æ­£è„¸æ£€æµ‹å™¨ - è§£å†³åè„‘å‹ºè¯¯åˆ¤é—®é¢˜
ä½¿ç”¨å¤šé‡éªŒè¯ç¡®ä¿æ£€æµ‹åˆ°çš„æ˜¯çœŸæ­£çš„æ­£è„¸è€Œä¸æ˜¯åè„‘å‹º
"""

import cv2
import numpy as np
import math
from typing import Dict, Tuple, List, Optional
import logging
import os
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from retinaface import RetinaFace
    RETINAFACE_AVAILABLE = True
    logger.info("âœ… RetinaFaceåº“å¯ç”¨")
except ImportError:
    RETINAFACE_AVAILABLE = False
    logger.warning("âš ï¸ RetinaFaceåº“ä¸å¯ç”¨")

class ImprovedFaceDetector:
    """æ”¹è¿›çš„æ­£è„¸æ£€æµ‹å™¨ï¼Œä¸“é—¨è§£å†³åè„‘å‹ºè¯¯åˆ¤é—®é¢˜"""
    
    def __init__(self, 
                 min_confidence=0.8,
                 max_yaw_angle=20.0,        # æ›´ä¸¥æ ¼çš„yawè§’åº¦é˜ˆå€¼
                 max_pitch_angle=25.0,      # pitchè§’åº¦é˜ˆå€¼ï¼ˆä¸Šä¸‹å€¾æ–œï¼‰
                 max_roll_angle=30.0,       # rollè§’åº¦é˜ˆå€¼ï¼ˆæ—‹è½¬ï¼‰
                 min_face_size=150,         # æ›´å¤§çš„æœ€å°äººè„¸å°ºå¯¸
                 min_area_ratio=0.015,      # æ›´å¤§çš„æœ€å°é¢ç§¯æ¯”ä¾‹
                 eye_visibility_threshold=0.7,  # çœ¼éƒ¨å¯è§æ€§é˜ˆå€¼
                 enable_eye_detection=True,      # å¯ç”¨ç‹¬ç«‹çœ¼éƒ¨æ£€æµ‹
                 enable_profile_rejection=True): # å¯ç”¨ä¾§è„¸æ‹’ç»
        
        self.min_confidence = min_confidence
        self.max_yaw_angle = max_yaw_angle
        self.max_pitch_angle = max_pitch_angle
        self.max_roll_angle = max_roll_angle
        self.min_face_size = min_face_size
        self.min_area_ratio = min_area_ratio
        self.eye_visibility_threshold = eye_visibility_threshold
        self.enable_eye_detection = enable_eye_detection
        self.enable_profile_rejection = enable_profile_rejection
        
        # åŠ è½½Haarçº§è”åˆ†ç±»å™¨ç”¨äºçœ¼éƒ¨æ£€æµ‹
        if self.enable_eye_detection:
            self.eye_cascade = self._load_eye_cascade()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'faces_detected': 0,
            'frontal_faces_found': 0,
            'rejected_by_yaw': 0,
            'rejected_by_pitch': 0,
            'rejected_by_roll': 0,
            'rejected_by_eyes': 0,
            'rejected_by_profile': 0,
            'rejected_by_size': 0
        }
    
    def _load_eye_cascade(self):
        """åŠ è½½çœ¼éƒ¨æ£€æµ‹çº§è”åˆ†ç±»å™¨"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            eye_cascade_paths = [
                '/usr/share/opencv4/haarcascades/haarcascade_eye.xml',
                '/usr/local/share/opencv4/haarcascades/haarcascade_eye.xml',
                'haarcascade_eye.xml',
                './haarcascade_eye.xml'
            ]
            
            # å°è¯•è·å–OpenCVæ•°æ®è·¯å¾„
            try:
                import cv2.data
                eye_cascade_paths.append(os.path.join(cv2.data.haarcascades, 'haarcascade_eye.xml'))
            except:
                pass
            
            for path in eye_cascade_paths:
                if os.path.exists(path):
                    logger.info(f"âœ… åŠ è½½çœ¼éƒ¨æ£€æµ‹å™¨: {path}")
                    return cv2.CascadeClassifier(path)
            
            logger.warning("âš ï¸ æœªæ‰¾åˆ°çœ¼éƒ¨æ£€æµ‹å™¨ï¼Œå°†ç¦ç”¨çœ¼éƒ¨éªŒè¯")
            return None
            
        except Exception as e:
            logger.warning(f"âš ï¸ çœ¼éƒ¨æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
            return None
    
    def calculate_advanced_pose_angles(self, landmarks: Dict) -> Tuple[float, float, float]:
        """
        è®¡ç®—æ›´ç²¾ç¡®çš„äººè„¸å§¿æ€è§’åº¦
        
        Returns:
            tuple: (yaw, pitch, roll) è§’åº¦ï¼ˆåº¦ï¼‰
        """
        try:
            # è·å–å…³é”®ç‚¹
            left_eye = np.array(landmarks.get('left_eye', [0, 0]))
            right_eye = np.array(landmarks.get('right_eye', [0, 0]))
            nose = np.array(landmarks.get('nose', [0, 0]))
            left_mouth = np.array(landmarks.get('left_mouth_corner', [0, 0]))
            right_mouth = np.array(landmarks.get('right_mouth_corner', [0, 0]))
            
            # å¦‚æœç¼ºå°‘å…³é”®ç‚¹ï¼Œè¿”å›å¤§è§’åº¦
            if np.allclose(left_eye, [0, 0]) or np.allclose(right_eye, [0, 0]) or np.allclose(nose, [0, 0]):
                return 90.0, 90.0, 90.0
            
            # 1. è®¡ç®— Yaw è§’åº¦ï¼ˆå·¦å³è½¬å¤´ï¼‰
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0, 90.0, 90.0
            
            # æ”¹è¿›çš„yawè®¡ç®—ï¼šåŸºäºé¼»å­ç›¸å¯¹äºçœ¼éƒ¨ä¸­å¿ƒçš„åç§»
            nose_to_eye_center = nose - eye_center
            horizontal_offset = nose_to_eye_center[0]
            
            # æ ‡å‡†åŒ–åç§»é‡
            normalized_offset = horizontal_offset / eye_width
            yaw_angle = abs(normalized_offset) * 45.0  # é™ä½ç³»æ•°ï¼Œæ›´ä¿å®ˆ
            
            # 2. è®¡ç®— Pitch è§’åº¦ï¼ˆä¸Šä¸‹ç‚¹å¤´ï¼‰
            if not np.allclose(left_mouth, [0, 0]) and not np.allclose(right_mouth, [0, 0]):
                mouth_center = (left_mouth + right_mouth) / 2
                eye_mouth_vector = mouth_center - eye_center
                vertical_distance = abs(eye_mouth_vector[1])
                
                # æ­£å¸¸æƒ…å†µä¸‹ï¼Œçœ¼éƒ¨åˆ°å˜´éƒ¨çš„å‚ç›´è·ç¦»åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
                expected_eye_mouth_ratio = 0.6  # ç»éªŒå€¼
                actual_ratio = vertical_distance / eye_width if eye_width > 0 else 1.0
                
                pitch_deviation = abs(actual_ratio - expected_eye_mouth_ratio) / expected_eye_mouth_ratio
                pitch_angle = pitch_deviation * 30.0
            else:
                pitch_angle = 0.0
            
            # 3. è®¡ç®— Roll è§’åº¦ï¼ˆå¤´éƒ¨å€¾æ–œï¼‰
            if eye_width > 0:
                eye_slope = (right_eye[1] - left_eye[1]) / eye_width
                roll_angle = abs(math.atan(eye_slope) * 180 / math.pi)
            else:
                roll_angle = 90.0
            
            return min(yaw_angle, 90.0), min(pitch_angle, 90.0), min(roll_angle, 90.0)
            
        except Exception as e:
            logger.debug(f"å§¿æ€è§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0, 90.0, 90.0
    
    def analyze_facial_symmetry(self, landmarks: Dict) -> float:
        """
        åˆ†æé¢éƒ¨å¯¹ç§°æ€§ï¼Œæ­£è„¸åº”è¯¥æ›´å¯¹ç§°
        
        Returns:
            float: å¯¹ç§°æ€§åˆ†æ•° (0-1ï¼Œ1è¡¨ç¤ºå®Œå…¨å¯¹ç§°)
        """
        try:
            left_eye = np.array(landmarks.get('left_eye', [0, 0]))
            right_eye = np.array(landmarks.get('right_eye', [0, 0]))
            nose = np.array(landmarks.get('nose', [0, 0]))
            left_mouth = np.array(landmarks.get('left_mouth_corner', [0, 0]))
            right_mouth = np.array(landmarks.get('right_mouth_corner', [0, 0]))
            
            if any(np.allclose(point, [0, 0]) for point in [left_eye, right_eye, nose, left_mouth, right_mouth]):
                return 0.0
            
            # è®¡ç®—é¢éƒ¨ä¸­è½´çº¿ï¼ˆé€šè¿‡é¼»å­ï¼Œå‚ç›´äºåŒçœ¼è¿çº¿ï¼‰
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            
            # é¼»å­åº”è¯¥åœ¨çœ¼éƒ¨ä¸­å¿ƒçº¿ä¸Šï¼ˆå¯¹äºæ­£è„¸ï¼‰
            nose_deviation = abs(np.dot(nose - eye_center, eye_vector)) / np.linalg.norm(eye_vector)
            
            # å˜´éƒ¨ä¸­å¿ƒä¹Ÿåº”è¯¥åœ¨ä¸­è½´çº¿ä¸Š
            mouth_center = (left_mouth + right_mouth) / 2
            mouth_deviation = abs(np.dot(mouth_center - eye_center, eye_vector)) / np.linalg.norm(eye_vector)
            
            # è®¡ç®—å¯¹ç§°æ€§åˆ†æ•°
            max_deviation = max(nose_deviation, mouth_deviation)
            symmetry_score = max(0, 1 - max_deviation / 20)  # 20åƒç´ ä½œä¸ºåŸºå‡†
            
            return symmetry_score
            
        except Exception as e:
            logger.debug(f"å¯¹ç§°æ€§åˆ†æå¤±è´¥: {e}")
            return 0.0
    
    def detect_eyes_independently(self, img: np.ndarray, face_region: Tuple[int, int, int, int]) -> bool:
        """
        ç‹¬ç«‹æ£€æµ‹çœ¼éƒ¨ï¼Œç¡®è®¤æ˜¯å¦èƒ½çœ‹åˆ°åŒçœ¼
        
        Args:
            img: è¾“å…¥å›¾åƒ
            face_region: äººè„¸åŒºåŸŸ (x1, y1, x2, y2)
            
        Returns:
            bool: æ˜¯å¦æ£€æµ‹åˆ°è¶³å¤Ÿçš„çœ¼éƒ¨ç‰¹å¾
        """
        if self.eye_cascade is None:
            return True  # å¦‚æœæ²¡æœ‰çœ¼éƒ¨æ£€æµ‹å™¨ï¼Œè·³è¿‡æ­¤æ£€æŸ¥
        
        try:
            x1, y1, x2, y2 = face_region
            face_roi = img[y1:y2, x1:x2]
            
            if face_roi.size == 0:
                return False
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray_face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY) if len(face_roi.shape) == 3 else face_roi
            
            # æ£€æµ‹çœ¼éƒ¨
            eyes = self.eye_cascade.detectMultiScale(
                gray_face,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(10, 10),
                maxSize=(100, 100)
            )
            
            # æ­£è„¸åº”è¯¥èƒ½æ£€æµ‹åˆ°è‡³å°‘1-2åªçœ¼ç›
            eye_count = len(eyes)
            
            # åˆ†æçœ¼éƒ¨åˆ†å¸ƒ
            if eye_count >= 2:
                # æ£€æŸ¥çœ¼éƒ¨æ˜¯å¦åœ¨åˆç†ä½ç½®ï¼ˆä¸ŠåŠéƒ¨åˆ†ï¼‰
                face_height = y2 - y1
                eyes_in_upper_half = sum(1 for (ex, ey, ew, eh) in eyes if ey < face_height * 0.6)
                
                return eyes_in_upper_half >= 2
            elif eye_count == 1:
                # å•çœ¼æ£€æµ‹å¯èƒ½æ˜¯ä¾§è„¸ï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯é®æŒ¡ï¼Œéœ€è¦æ›´å¤šéªŒè¯
                return True
            else:
                # æ²¡æœ‰æ£€æµ‹åˆ°çœ¼éƒ¨ï¼Œå¯èƒ½æ˜¯åè„‘å‹º
                return False
                
        except Exception as e:
            logger.debug(f"ç‹¬ç«‹çœ¼éƒ¨æ£€æµ‹å¤±è´¥: {e}")
            return True  # æ£€æµ‹å¤±è´¥æ—¶ä¿å®ˆå¤„ç†
    
    def analyze_facial_features_distribution(self, landmarks: Dict, face_area: Tuple[int, int, int, int]) -> bool:
        """
        åˆ†æé¢éƒ¨ç‰¹å¾åˆ†å¸ƒï¼Œåˆ¤æ–­æ˜¯å¦ç¬¦åˆæ­£è„¸ç‰¹å¾
        
        Args:
            landmarks: é¢éƒ¨å…³é”®ç‚¹
            face_area: äººè„¸åŒºåŸŸ
            
        Returns:
            bool: æ˜¯å¦ç¬¦åˆæ­£è„¸ç‰¹å¾åˆ†å¸ƒ
        """
        try:
            x1, y1, x2, y2 = face_area
            face_width = x2 - x1
            face_height = y2 - y1
            
            left_eye = np.array(landmarks.get('left_eye', [0, 0]))
            right_eye = np.array(landmarks.get('right_eye', [0, 0]))
            nose = np.array(landmarks.get('nose', [0, 0]))
            left_mouth = np.array(landmarks.get('left_mouth_corner', [0, 0]))
            right_mouth = np.array(landmarks.get('right_mouth_corner', [0, 0]))
            
            # æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦éƒ½åœ¨é¢éƒ¨åŒºåŸŸå†…
            for point_name, point in [('left_eye', left_eye), ('right_eye', right_eye), 
                                     ('nose', nose), ('left_mouth', left_mouth), ('right_mouth', right_mouth)]:
                if np.allclose(point, [0, 0]):
                    continue
                
                # è½¬æ¢ä¸ºç›¸å¯¹åæ ‡
                rel_x = (point[0] - x1) / face_width
                rel_y = (point[1] - y1) / face_height
                
                # æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                if not (0.1 <= rel_x <= 0.9 and 0.1 <= rel_y <= 0.9):
                    logger.debug(f"å…³é”®ç‚¹ {point_name} è¶…å‡ºåˆç†èŒƒå›´: ({rel_x:.2f}, {rel_y:.2f})")
                    return False
            
            # æ£€æŸ¥çœ¼éƒ¨é—´è·æ˜¯å¦åˆç†
            if not np.allclose(left_eye, [0, 0]) and not np.allclose(right_eye, [0, 0]):
                eye_distance = np.linalg.norm(right_eye - left_eye)
                eye_distance_ratio = eye_distance / face_width
                
                # æ­£è„¸çš„çœ¼é—´è·é€šå¸¸å é¢éƒ¨å®½åº¦çš„25%-45%
                if not (0.20 <= eye_distance_ratio <= 0.50):
                    logger.debug(f"çœ¼é—´è·æ¯”ä¾‹å¼‚å¸¸: {eye_distance_ratio:.2f}")
                    return False
            
            # æ£€æŸ¥äº”å®˜å‚ç›´åˆ†å¸ƒ
            if not any(np.allclose(point, [0, 0]) for point in [left_eye, right_eye, nose, left_mouth, right_mouth]):
                eye_center = (left_eye + right_eye) / 2
                mouth_center = (left_mouth + right_mouth) / 2
                
                # ç›¸å¯¹ä½ç½®æ£€æŸ¥
                eye_y_ratio = (eye_center[1] - y1) / face_height
                nose_y_ratio = (nose[1] - y1) / face_height
                mouth_y_ratio = (mouth_center[1] - y1) / face_height
                
                # æ­£è„¸çš„å…¸å‹æ¯”ä¾‹ï¼šçœ¼éƒ¨20%-40%ï¼Œé¼»å­40%-65%ï¼Œå˜´éƒ¨65%-85%
                if not (0.15 <= eye_y_ratio <= 0.45):
                    logger.debug(f"çœ¼éƒ¨å‚ç›´ä½ç½®å¼‚å¸¸: {eye_y_ratio:.2f}")
                    return False
                
                if not (0.35 <= nose_y_ratio <= 0.70):
                    logger.debug(f"é¼»å­å‚ç›´ä½ç½®å¼‚å¸¸: {nose_y_ratio:.2f}")
                    return False
                
                if not (0.60 <= mouth_y_ratio <= 0.90):
                    logger.debug(f"å˜´éƒ¨å‚ç›´ä½ç½®å¼‚å¸¸: {mouth_y_ratio:.2f}")
                    return False
            
            return True
            
        except Exception as e:
            logger.debug(f"ç‰¹å¾åˆ†å¸ƒåˆ†æå¤±è´¥: {e}")
            return True  # åˆ†æå¤±è´¥æ—¶ä¿å®ˆå¤„ç†
    
    def is_frontal_face(self, img: np.ndarray, face_data: Dict) -> Tuple[bool, Dict]:
        """
        ç»¼åˆåˆ¤æ–­æ˜¯å¦ä¸ºæ­£è„¸
        
        Args:
            img: è¾“å…¥å›¾åƒ
            face_data: RetinaFaceæ£€æµ‹ç»“æœ
            
        Returns:
            tuple: (æ˜¯å¦ä¸ºæ­£è„¸, è¯¦ç»†åˆ†æç»“æœ)
        """
        try:
            # åŸºæœ¬ä¿¡æ¯æå–
            confidence = face_data.get('score', 0.0)
            facial_area = face_data['facial_area']
            landmarks = face_data.get('landmarks', {})
            
            x1, y1, x2, y2 = facial_area
            face_width = x2 - x1
            face_height = y2 - y1
            face_area = face_width * face_height
            
            img_height, img_width = img.shape[:2]
            img_area = img_width * img_height
            area_ratio = face_area / img_area
            
            analysis_result = {
                'confidence': confidence,
                'face_size': (face_width, face_height),
                'area_ratio': area_ratio,
                'rejection_reasons': []
            }
            
            # 1. ç½®ä¿¡åº¦æ£€æŸ¥
            if confidence < self.min_confidence:
                analysis_result['rejection_reasons'].append(f"ç½®ä¿¡åº¦è¿‡ä½: {confidence:.3f} < {self.min_confidence}")
                return False, analysis_result
            
            # 2. å°ºå¯¸æ£€æŸ¥
            if min(face_width, face_height) < self.min_face_size:
                analysis_result['rejection_reasons'].append(f"å°ºå¯¸è¿‡å°: {min(face_width, face_height)} < {self.min_face_size}")
                self.stats['rejected_by_size'] += 1
                return False, analysis_result
            
            if area_ratio < self.min_area_ratio:
                analysis_result['rejection_reasons'].append(f"é¢ç§¯æ¯”ä¾‹è¿‡å°: {area_ratio:.4f} < {self.min_area_ratio}")
                self.stats['rejected_by_size'] += 1
                return False, analysis_result
            
            # 3. å…³é”®ç‚¹æ£€æŸ¥
            if not landmarks:
                analysis_result['rejection_reasons'].append("ç¼ºå°‘é¢éƒ¨å…³é”®ç‚¹")
                return False, analysis_result
            
            # 4. å§¿æ€è§’åº¦åˆ†æ
            yaw, pitch, roll = self.calculate_advanced_pose_angles(landmarks)
            analysis_result.update({
                'yaw_angle': yaw,
                'pitch_angle': pitch,
                'roll_angle': roll
            })
            
            if yaw > self.max_yaw_angle:
                analysis_result['rejection_reasons'].append(f"Yawè§’åº¦è¿‡å¤§: {yaw:.1f}Â° > {self.max_yaw_angle}Â°")
                self.stats['rejected_by_yaw'] += 1
                return False, analysis_result
            
            if pitch > self.max_pitch_angle:
                analysis_result['rejection_reasons'].append(f"Pitchè§’åº¦è¿‡å¤§: {pitch:.1f}Â° > {self.max_pitch_angle}Â°")
                self.stats['rejected_by_pitch'] += 1
                return False, analysis_result
            
            if roll > self.max_roll_angle:
                analysis_result['rejection_reasons'].append(f"Rollè§’åº¦è¿‡å¤§: {roll:.1f}Â° > {self.max_roll_angle}Â°")
                self.stats['rejected_by_roll'] += 1
                return False, analysis_result
            
            # 5. é¢éƒ¨å¯¹ç§°æ€§æ£€æŸ¥
            symmetry_score = self.analyze_facial_symmetry(landmarks)
            analysis_result['symmetry_score'] = symmetry_score
            
            if symmetry_score < 0.3:  # å¯¹ç§°æ€§é˜ˆå€¼
                analysis_result['rejection_reasons'].append(f"å¯¹ç§°æ€§è¿‡ä½: {symmetry_score:.3f} < 0.3")
                self.stats['rejected_by_profile'] += 1
                return False, analysis_result
            
            # 6. ç‹¬ç«‹çœ¼éƒ¨æ£€æµ‹
            if self.enable_eye_detection:
                eyes_detected = self.detect_eyes_independently(img, facial_area)
                analysis_result['eyes_detected'] = eyes_detected
                
                if not eyes_detected:
                    analysis_result['rejection_reasons'].append("æœªæ£€æµ‹åˆ°è¶³å¤Ÿçš„çœ¼éƒ¨ç‰¹å¾")
                    self.stats['rejected_by_eyes'] += 1
                    return False, analysis_result
            
            # 7. ç‰¹å¾åˆ†å¸ƒæ£€æŸ¥
            if self.enable_profile_rejection:
                features_valid = self.analyze_facial_features_distribution(landmarks, facial_area)
                analysis_result['features_distribution_valid'] = features_valid
                
                if not features_valid:
                    analysis_result['rejection_reasons'].append("é¢éƒ¨ç‰¹å¾åˆ†å¸ƒä¸ç¬¦åˆæ­£è„¸æ¨¡å¼")
                    self.stats['rejected_by_profile'] += 1
                    return False, analysis_result
            
            # 8. ç»¼åˆè¯„åˆ†
            composite_score = (
                (1 - yaw / 90.0) * 0.3 +           # yawè§’åº¦æƒé‡
                (1 - pitch / 90.0) * 0.2 +         # pitchè§’åº¦æƒé‡
                (1 - roll / 90.0) * 0.2 +          # rollè§’åº¦æƒé‡
                symmetry_score * 0.2 +              # å¯¹ç§°æ€§æƒé‡
                min(area_ratio / 0.1, 1.0) * 0.1   # å¤§å°æƒé‡
            )
            
            analysis_result['composite_score'] = composite_score
            
            # ç»¼åˆè¯„åˆ†é˜ˆå€¼
            if composite_score < 0.6:
                analysis_result['rejection_reasons'].append(f"ç»¼åˆè¯„åˆ†è¿‡ä½: {composite_score:.3f} < 0.6")
                return False, analysis_result
            
            # é€šè¿‡æ‰€æœ‰æ£€æŸ¥
            self.stats['frontal_faces_found'] += 1
            return True, analysis_result
            
        except Exception as e:
            logger.error(f"æ­£è„¸åˆ¤æ–­å¤±è´¥: {e}")
            analysis_result = {
                'confidence': 0.0,
                'face_size': (0, 0),
                'area_ratio': 0.0,
                'rejection_reasons': [f"åˆ†æå¼‚å¸¸: {str(e)}"]
            }
            return False, analysis_result
    
    def detect_frontal_faces(self, image_path: str, return_details: bool = False) -> Tuple[int, List]:
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„æ­£è„¸æ•°é‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            return_details: æ˜¯å¦è¿”å›è¯¦ç»†åˆ†æç»“æœ
            
        Returns:
            tuple: (æ­£è„¸æ•°é‡, è¯¦ç»†ç»“æœåˆ—è¡¨)
        """
        self.stats['total_processed'] += 1
        
        if not RETINAFACE_AVAILABLE:
            logger.error("RetinaFaceä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ£€æµ‹")
            return 0, []
        
        try:
            # ä½¿ç”¨RetinaFaceæ£€æµ‹
            from retinaface import RetinaFace
            detections = RetinaFace.detect_faces(image_path)
            
            if not isinstance(detections, dict) or len(detections) == 0:
                return 0, []
            
            # è¯»å–å›¾åƒ
            img = cv2.imread(image_path)
            if img is None:
                logger.error(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                return 0, []
            
            self.stats['faces_detected'] += len(detections)
            
            frontal_count = 0
            detailed_results = []
            
            for face_key, face_data in detections.items():
                is_frontal, analysis = self.is_frontal_face(img, face_data)
                
                if return_details:
                    detailed_results.append({
                        'face_key': face_key,
                        'is_frontal': is_frontal,
                        'analysis': analysis
                    })
                
                if is_frontal:
                    frontal_count += 1
            
            return frontal_count, detailed_results if return_details else []
            
        except Exception as e:
            logger.error(f"æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_faces = self.stats['faces_detected']
        total_processed = self.stats['total_processed']
        
        # åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸æ¥é¿å…ç±»å‹é—®é¢˜
        stats = {}
        
        # å¤åˆ¶åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        for key, value in self.stats.items():
            stats[key] = value
        
        if total_faces > 0:
            stats['frontal_rate'] = self.stats['frontal_faces_found'] / total_faces
            stats['rejection_breakdown'] = {
                'yaw_percentage': self.stats['rejected_by_yaw'] / total_faces * 100,
                'pitch_percentage': self.stats['rejected_by_pitch'] / total_faces * 100,
                'roll_percentage': self.stats['rejected_by_roll'] / total_faces * 100,
                'eyes_percentage': self.stats['rejected_by_eyes'] / total_faces * 100,
                'profile_percentage': self.stats['rejected_by_profile'] / total_faces * 100,
                'size_percentage': self.stats['rejected_by_size'] / total_faces * 100
            }
        
        if total_processed > 0:
            stats['average_faces_per_image'] = total_faces / total_processed
            stats['images_with_frontal_faces'] = sum(1 for _ in range(total_processed) if self.stats['frontal_faces_found'] > 0)
        
        return stats

def test_improved_detector():
    """æµ‹è¯•æ”¹è¿›çš„æ£€æµ‹å™¨"""
    detector = ImprovedFaceDetector(
        min_confidence=0.85,
        max_yaw_angle=15.0,      # æ›´ä¸¥æ ¼çš„yawè§’åº¦
        max_pitch_angle=20.0,    # æ›´ä¸¥æ ¼çš„pitchè§’åº¦
        max_roll_angle=25.0,     # æ›´ä¸¥æ ¼çš„rollè§’åº¦
        min_face_size=120,       # æ›´å¤§çš„æœ€å°å°ºå¯¸
        min_area_ratio=0.02,     # æ›´å¤§çš„æœ€å°é¢ç§¯æ¯”ä¾‹
        enable_eye_detection=True,
        enable_profile_rejection=True
    )
    
    # æµ‹è¯•ç›®å½•
    test_dir = "/home/zhiqics/sanjian/predata/output_frames70"
    
    if not os.path.exists(test_dir):
        logger.error(f"æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return
    
    # è·å–æµ‹è¯•å›¾ç‰‡
    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
    test_images = []
    
    for ext in image_extensions:
        test_images.extend(Path(test_dir).glob(f"*{ext}"))
    
    test_images = test_images[:20]  # åªæµ‹è¯•å‰20å¼ 
    
    logger.info(f"å¼€å§‹æµ‹è¯•ï¼Œå›¾ç‰‡æ•°é‡: {len(test_images)}")
    
    results = []
    for img_path in test_images:
        frontal_count, details = detector.detect_frontal_faces(str(img_path), return_details=True)
        results.append({
            'image': img_path.name,
            'frontal_count': frontal_count,
            'details': details
        })
        
        logger.info(f"ğŸ“¸ {img_path.name}: æ£€æµ‹åˆ° {frontal_count} å¼ æ­£è„¸")
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ†æ
        for detail in details:
            analysis = detail['analysis']
            if detail['is_frontal']:
                logger.info(f"  âœ… æ­£è„¸ - ç»¼åˆè¯„åˆ†: {analysis.get('composite_score', 0):.3f}")
            else:
                reasons = ', '.join(analysis.get('rejection_reasons', []))
                logger.info(f"  âŒ æ‹’ç» - åŸå› : {reasons}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = detector.get_statistics()
    logger.info("\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
    logger.info(f"  å¤„ç†å›¾ç‰‡: {stats['total_processed']}")
    logger.info(f"  æ£€æµ‹åˆ°äººè„¸: {stats['faces_detected']}")
    logger.info(f"  æ­£è„¸æ•°é‡: {stats['frontal_faces_found']}")
    
    if 'frontal_rate' in stats:
        logger.info(f"  æ­£è„¸æ¯”ä¾‹: {stats['frontal_rate']:.1%}")
    
    if 'rejection_breakdown' in stats:
        breakdown = stats['rejection_breakdown']
        logger.info("  æ‹’ç»åŸå› åˆ†å¸ƒ:")
        logger.info(f"    Yawè§’åº¦: {breakdown['yaw_percentage']:.1f}%")
        logger.info(f"    Pitchè§’åº¦: {breakdown['pitch_percentage']:.1f}%")
        logger.info(f"    Rollè§’åº¦: {breakdown['roll_percentage']:.1f}%")
        logger.info(f"    çœ¼éƒ¨æ£€æµ‹: {breakdown['eyes_percentage']:.1f}%")
        logger.info(f"    ä¾§è„¸/ç‰¹å¾: {breakdown['profile_percentage']:.1f}%")
        logger.info(f"    å°ºå¯¸è¿‡å°: {breakdown['size_percentage']:.1f}%")

if __name__ == "__main__":
    test_improved_detector()
