#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤„ç†qualifiedç›®å½•ä¸‹çš„å›¾ç‰‡ - è¶…ä¸¥æ ¼ç›¸ä¼¼å›¾ç‰‡æ£€æµ‹
ä¸“é—¨é’ˆå¯¹å·²ç»ç­›é€‰è¿‡çš„é«˜è´¨é‡å›¾ç‰‡è¿›è¡Œè¿›ä¸€æ­¥å»é‡
"""

import cv2
import numpy as np
import torch
import os
from pathlib import Path
from typing import Tuple, Dict, List
import shutil
import json
from datetime import datetime
import argparse

class QualifiedImageProcessor:
    """ä¸“é—¨å¤„ç†qualifiedå›¾ç‰‡çš„è¶…ä¸¥æ ¼æ£€æµ‹å™¨"""
    
    def __init__(self, 
                 psnr_threshold=65.0,        # è¶…é«˜PSNRè¦æ±‚
                 ssim_threshold=0.92,        # è¶…é«˜SSIMè¦æ±‚
                 composite_threshold=82.0,   # è¶…é«˜å¤åˆè¯„åˆ†
                 hist_threshold=0.95,        # è¶…ä¸¥æ ¼ç›´æ–¹å›¾é˜ˆå€¼
                 edge_threshold=0.88,        # è¾¹ç¼˜ç›¸ä¼¼åº¦é˜ˆå€¼
                 conditions_required=4):      # è¦æ±‚æ»¡è¶³4/5ä¸ªæ¡ä»¶
        
        self.psnr_threshold = psnr_threshold
        self.ssim_threshold = ssim_threshold  
        self.composite_threshold = composite_threshold
        self.hist_threshold = hist_threshold
        self.edge_threshold = edge_threshold
        self.conditions_required = conditions_required
        
        # GPUæ£€æµ‹
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_images': 0,
            'total_comparisons': 0,
            'similar_found': 0,
            'final_kept': 0,
            'processing_time': 0
        }
    
    def calculate_psnr_gpu(self, img1, img2):
        """GPUåŠ é€ŸPSNRè®¡ç®—"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬æ¢ä¸ºtorch tensor
        img1_tensor = torch.from_numpy(img1.astype(np.float32)).to(self.device)
        img2_tensor = torch.from_numpy(img2.astype(np.float32)).to(self.device)
        
        # è®¡ç®—MSE
        mse = torch.mean((img1_tensor - img2_tensor) ** 2)
        
        if mse == 0:
            return float('inf')
        
        max_pixel = 255.0
        psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))
        return psnr.cpu().item()
    
    def calculate_advanced_ssim(self, img1, img2):
        """é«˜çº§SSIMè®¡ç®—ï¼ˆå¤šå°ºåº¦ï¼‰"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬æ¢ä¸ºç°åº¦
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        gray1 = gray1.astype(np.float64)
        gray2 = gray2.astype(np.float64)
        
        # å¤šå°ºåº¦SSIM
        ssim_values = []
        scales = [1.0, 0.5, 0.25]  # ä¸åŒå°ºåº¦
        
        for scale in scales:
            if scale < 1.0:
                h, w = int(gray1.shape[0] * scale), int(gray1.shape[1] * scale)
                g1 = cv2.resize(gray1, (w, h))
                g2 = cv2.resize(gray2, (w, h))
            else:
                g1, g2 = gray1, gray2
            
            # è®¡ç®—å•å°ºåº¦SSIM
            C1 = (0.01 * 255) ** 2
            C2 = (0.03 * 255) ** 2
            
            mu1 = cv2.GaussianBlur(g1, (11, 11), 1.5)
            mu2 = cv2.GaussianBlur(g2, (11, 11), 1.5)
            
            mu1_sq = mu1 ** 2
            mu2_sq = mu2 ** 2
            mu1_mu2 = mu1 * mu2
            
            sigma1_sq = cv2.GaussianBlur(g1 ** 2, (11, 11), 1.5) - mu1_sq
            sigma2_sq = cv2.GaussianBlur(g2 ** 2, (11, 11), 1.5) - mu2_sq
            sigma12 = cv2.GaussianBlur(g1 * g2, (11, 11), 1.5) - mu1_mu2
            
            ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
            ssim_values.append(np.mean(ssim_map))
        
        # åŠ æƒå¹³å‡ï¼ˆåŸå°ºåº¦æƒé‡æ›´å¤§ï¼‰
        weights = [0.6, 0.3, 0.1]
        return np.average(ssim_values, weights=weights)
    
    def calculate_color_histogram_similarity(self, img1, img2):
        """é«˜ç²¾åº¦å½©è‰²ç›´æ–¹å›¾ç›¸ä¼¼åº¦"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        similarities = []
        
        # RGBç›´æ–¹å›¾ï¼ˆç²¾ç»†åŒ–ï¼‰
        for i in range(3):
            hist1 = cv2.calcHist([img1], [i], None, [256], [0, 256])
            hist2 = cv2.calcHist([img2], [i], None, [256], [0, 256])
            
            # æ ‡å‡†åŒ–
            hist1 = cv2.normalize(hist1, hist1).flatten()
            hist2 = cv2.normalize(hist2, hist2).flatten()
            
            # å¤šç§æ¯”è¾ƒæ–¹æ³•
            correl = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            chi_square = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR)
            intersection = cv2.compareHist(hist1, hist2, cv2.HISTCMP_INTERSECT)
            bhattacharyya = cv2.compareHist(hist1, hist2, cv2.HISTCMP_BHATTACHARYYA)
            
            # ç»¼åˆè¯„åˆ†
            chi_square_norm = 1.0 / (1.0 + chi_square)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
            bhattacharyya_norm = 1.0 - bhattacharyya
            
            channel_similarity = (correl * 0.4 + intersection * 0.3 + 
                                 chi_square_norm * 0.2 + bhattacharyya_norm * 0.1)
            similarities.append(max(0, channel_similarity))
        
        # HSVç©ºé—´
        hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)
        hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)
        
        # 2Dç›´æ–¹å›¾ï¼ˆè‰²è°ƒ-é¥±å’Œåº¦ï¼‰
        hist_hsv1 = cv2.calcHist([hsv1], [0, 1], None, [180, 256], [0, 180, 0, 256])
        hist_hsv2 = cv2.calcHist([hsv2], [0, 1], None, [180, 256], [0, 180, 0, 256])
        
        hsv_similarity = cv2.compareHist(hist_hsv1, hist_hsv2, cv2.HISTCMP_CORREL)
        
        # Labè‰²å½©ç©ºé—´
        lab1 = cv2.cvtColor(img1, cv2.COLOR_BGR2LAB)
        lab2 = cv2.cvtColor(img2, cv2.COLOR_BGR2LAB)
        
        hist_lab1 = cv2.calcHist([lab1], [1, 2], None, [256, 256], [0, 256, 0, 256])
        hist_lab2 = cv2.calcHist([lab2], [1, 2], None, [256, 256], [0, 256, 0, 256])
        
        lab_similarity = cv2.compareHist(hist_lab1, hist_lab2, cv2.HISTCMP_CORREL)
        
        # ç»¼åˆRGBã€HSVã€Lab
        rgb_avg = np.mean(similarities)
        final_similarity = (rgb_avg * 0.5 + hsv_similarity * 0.3 + lab_similarity * 0.2)
        
        return max(0, final_similarity)
    
    def calculate_edge_similarity(self, img1, img2):
        """é«˜ç²¾åº¦è¾¹ç¼˜ç›¸ä¼¼åº¦è®¡ç®—"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬ç°åº¦
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        edge_similarities = []
        
        # Cannyè¾¹ç¼˜æ£€æµ‹ï¼ˆå¤šå‚æ•°ï¼‰
        canny_params = [(50, 150), (30, 100), (70, 200)]
        for low, high in canny_params:
            edges1 = cv2.Canny(gray1, low, high)
            edges2 = cv2.Canny(gray2, low, high)
            
            # è¾¹ç¼˜ç›¸ä¼¼åº¦
            edge_diff = np.abs(edges1.astype(np.float32) - edges2.astype(np.float32))
            similarity = 1.0 - (np.mean(edge_diff) / 255.0)
            edge_similarities.append(similarity)
        
        # Sobelè¾¹ç¼˜æ£€æµ‹
        sobelx1 = cv2.Sobel(gray1, cv2.CV_64F, 1, 0, ksize=3)
        sobely1 = cv2.Sobel(gray1, cv2.CV_64F, 0, 1, ksize=3)
        sobel1 = np.sqrt(sobelx1**2 + sobely1**2)
        
        sobelx2 = cv2.Sobel(gray2, cv2.CV_64F, 1, 0, ksize=3)
        sobely2 = cv2.Sobel(gray2, cv2.CV_64F, 0, 1, ksize=3)
        sobel2 = np.sqrt(sobelx2**2 + sobely2**2)
        
        # Sobelç›¸ä¼¼åº¦
        sobel_diff = np.abs(sobel1 - sobel2)
        sobel_similarity = 1.0 - (np.mean(sobel_diff) / np.max([np.max(sobel1), np.max(sobel2)]))
        
        # ç»¼åˆè¾¹ç¼˜ç›¸ä¼¼åº¦
        canny_avg = np.mean(edge_similarities)
        final_edge_similarity = (canny_avg * 0.7 + sobel_similarity * 0.3)
        
        return max(0, final_edge_similarity)
    
    def calculate_texture_similarity(self, img1, img2):
        """çº¹ç†ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆLBPï¼‰"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # è½¬ç°åº¦
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2
        
        # ç®€åŒ–çš„LBPè®¡ç®—
        def lbp_histogram(image):
            # ç®€å•çš„å±€éƒ¨äºŒå€¼æ¨¡å¼
            h, w = image.shape
            lbp_image = np.zeros_like(image)
            
            for i in range(1, h-1):
                for j in range(1, w-1):
                    center = image[i, j]
                    code = 0
                    code |= (image[i-1, j-1] >= center) << 7
                    code |= (image[i-1, j] >= center) << 6
                    code |= (image[i-1, j+1] >= center) << 5
                    code |= (image[i, j+1] >= center) << 4
                    code |= (image[i+1, j+1] >= center) << 3
                    code |= (image[i+1, j] >= center) << 2
                    code |= (image[i+1, j-1] >= center) << 1
                    code |= (image[i, j-1] >= center) << 0
                    lbp_image[i, j] = code
            
            # è®¡ç®—ç›´æ–¹å›¾
            hist, _ = np.histogram(lbp_image.ravel(), bins=256, range=(0, 256))
            return hist
        
        hist1 = lbp_histogram(gray1)
        hist2 = lbp_histogram(gray2)
        
        # æ ‡å‡†åŒ–
        hist1 = hist1.astype(np.float32)
        hist2 = hist2.astype(np.float32)
        hist1 = hist1 / (np.sum(hist1) + 1e-10)
        hist2 = hist2 / (np.sum(hist2) + 1e-10)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        return max(0, correlation)
    
    def are_images_ultra_similar(self, img_path1, img_path2):
        """è¶…ä¸¥æ ¼ç›¸ä¼¼åº¦åˆ¤å®šï¼ˆé’ˆå¯¹qualifiedå›¾ç‰‡ï¼‰"""
        try:
            # è¯»å–å›¾åƒ
            img1 = cv2.imread(str(img_path1))
            img2 = cv2.imread(str(img_path2))
            
            if img1 is None or img2 is None:
                return False, 0, {}
            
            # 1. è¶…é«˜PSNRæ£€æµ‹
            psnr = self.calculate_psnr_gpu(img1, img2)
            is_similar_psnr = psnr > self.psnr_threshold
            
            # 2. å¤šå°ºåº¦SSIMæ£€æµ‹
            ssim = self.calculate_advanced_ssim(img1, img2)
            is_similar_ssim = ssim > self.ssim_threshold
            
            # 3. é«˜ç²¾åº¦ç›´æ–¹å›¾ç›¸ä¼¼åº¦
            hist_sim = self.calculate_color_histogram_similarity(img1, img2)
            is_similar_hist = hist_sim > self.hist_threshold
            
            # 4. è¾¹ç¼˜ç›¸ä¼¼åº¦
            edge_sim = self.calculate_edge_similarity(img1, img2)
            is_similar_edge = edge_sim > self.edge_threshold
            
            # 5. çº¹ç†ç›¸ä¼¼åº¦
            texture_sim = self.calculate_texture_similarity(img1, img2)
            is_similar_texture = texture_sim > 0.85
            
            # 6. è¶…ä¸¥æ ¼å¤åˆè¯„åˆ†
            psnr_normalized = min(psnr / 75.0, 1.0)  # åŸºå‡†æå‡åˆ°75
            composite_score = (psnr_normalized * 0.25 + ssim * 0.25 + 
                              hist_sim * 0.2 + edge_sim * 0.2 + texture_sim * 0.1) * 100
            is_similar_composite = composite_score > self.composite_threshold
            
            # è¶…ä¸¥æ ¼æ¡ä»¶æ£€æŸ¥
            conditions = [is_similar_psnr, is_similar_ssim, is_similar_hist, 
                         is_similar_edge, is_similar_composite]
            conditions_met = sum(conditions)
            
            # å¿…é¡»æ»¡è¶³æ ¸å¿ƒæ¡ä»¶ä¸”è¾¾åˆ°è¦æ±‚æ•°é‡
            is_similar = (conditions_met >= self.conditions_required and 
                         is_similar_psnr and is_similar_ssim and is_similar_hist)
            
            details = {
                'psnr': psnr,
                'ssim': ssim,
                'hist_similarity': hist_sim,
                'edge_similarity': edge_sim,
                'texture_similarity': texture_sim,
                'composite_score': composite_score,
                'conditions_met': f"{conditions_met}/5",
                'thresholds': {
                    'psnr_threshold': self.psnr_threshold,
                    'ssim_threshold': self.ssim_threshold,
                    'hist_threshold': self.hist_threshold,
                    'edge_threshold': self.edge_threshold,
                    'composite_threshold': self.composite_threshold
                },
                'is_similar_breakdown': {
                    'psnr': is_similar_psnr,
                    'ssim': is_similar_ssim,
                    'histogram': is_similar_hist,
                    'edge': is_similar_edge,
                    'texture': is_similar_texture,
                    'composite': is_similar_composite
                }
            }
            
            self.stats['total_comparisons'] += 1
            if is_similar:
                self.stats['similar_found'] += 1
                
            return is_similar, composite_score, details
            
        except Exception as e:
            print(f"âŒ æ¯”è¾ƒå¤±è´¥ {img_path1} vs {img_path2}: {e}")
            return False, 0, {}
    
    def select_best_qualified_image(self, image_group):
        """ä¸ºqualifiedå›¾ç‰‡é€‰æ‹©æœ€ä½³ä»£è¡¨"""
        best_img = None
        best_score = 0
        
        print(f"  ğŸ” è¯„ä¼° {len(image_group)} å¼ ç›¸ä¼¼å›¾ç‰‡...")
        
        for img_path in image_group:
            try:
                # è¯»å–å›¾åƒ
                img = cv2.imread(str(img_path))
                if img is None:
                    continue
                
                # æ–‡ä»¶å¤§å°æƒé‡
                file_size = img_path.stat().st_size
                size_score = min(file_size / 500000, 1.0)  # 500KBåŸºå‡†
                
                # å›¾åƒæ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                clarity = cv2.Laplacian(gray, cv2.CV_64F).var()
                clarity_score = min(clarity / 500, 1.0)  # 500åŸºå‡†
                
                # åˆ†è¾¨ç‡æƒé‡
                height, width = img.shape[:2]
                resolution_score = min((width * height) / 8000000, 1.0)  # 8MPåŸºå‡†
                
                # å›¾åƒå¯¹æ¯”åº¦
                contrast = np.std(gray)
                contrast_score = min(contrast / 50, 1.0)  # 50åŸºå‡†
                
                # è¾¹ç¼˜å¯†åº¦
                edges = cv2.Canny(gray, 50, 150)
                edge_density = np.sum(edges > 0) / (width * height)
                edge_score = min(edge_density * 10, 1.0)
                
                # ç»¼åˆè¯„åˆ†ï¼ˆä¼˜åŒ–æƒé‡ï¼‰
                score = (clarity_score * 0.35 +      # æ¸…æ™°åº¦æœ€é‡è¦
                        contrast_score * 0.25 +      # å¯¹æ¯”åº¦
                        edge_score * 0.2 +           # è¾¹ç¼˜ä¿¡æ¯
                        resolution_score * 0.15 +    # åˆ†è¾¨ç‡
                        size_score * 0.05)           # æ–‡ä»¶å¤§å°
                
                print(f"    ğŸ“Š {img_path.name}: æ¸…æ™°åº¦={clarity:.0f}, å¯¹æ¯”åº¦={contrast:.1f}, "
                      f"è¾¹ç¼˜å¯†åº¦={edge_density:.3f}, æ€»åˆ†={score:.3f}")
                
                if score > best_score:
                    best_score = score
                    best_img = img_path
                    
            except Exception as e:
                print(f"âš ï¸ è¯„ä¼°å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
                continue
        
        if best_img:
            print(f"  âœ… æœ€ä½³å›¾ç‰‡: {best_img.name} (åˆ†æ•°: {best_score:.3f})")
        
        return best_img or image_group[0]
    
    def process_qualified_directory(self, qualified_dir, output_dir=None):
        """å¤„ç†qualifiedç›®å½•"""
        qualified_path = Path(qualified_dir)
        if not qualified_path.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {qualified_path}")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = [f for f in qualified_path.glob("*") if f.suffix.lower() in image_extensions]
        
        if len(image_files) < 2:
            print("ğŸ“ å›¾ç‰‡æ•°é‡ä¸è¶³ï¼Œæ— éœ€æ£€æµ‹")
            return
        
        self.stats['total_images'] = len(image_files)
        
        print(f"ğŸ¯ å¼€å§‹è¶…ä¸¥æ ¼å¤„ç† qualified ç›®å½•: {qualified_path}")
        print(f"ğŸ“Š è¾“å…¥å›¾ç‰‡æ•°é‡: {len(image_files)}")
        print(f"âš™ï¸ è¶…ä¸¥æ ¼é˜ˆå€¼è®¾ç½®:")
        print(f"   - PSNR: {self.psnr_threshold}")
        print(f"   - SSIM: {self.ssim_threshold}")
        print(f"   - ç›´æ–¹å›¾: {self.hist_threshold}")
        print(f"   - è¾¹ç¼˜: {self.edge_threshold}")
        print(f"   - å¤åˆè¯„åˆ†: {self.composite_threshold}")
        print(f"   - æ¡ä»¶è¦æ±‚: {self.conditions_required}/5")
        print()
        
        start_time = datetime.now()
        
        duplicate_groups = []
        processed = set()
        
        for i, img1 in enumerate(image_files):
            if str(img1) in processed:
                continue
                
            current_group = [img1]
            processed.add(str(img1))
            
            print(f"ğŸ” æ£€æµ‹å›¾ç‰‡ {i+1}/{len(image_files)}: {img1.name}")
            
            for j, img2 in enumerate(image_files[i+1:], i+1):
                if str(img2) in processed:
                    continue
                    
                is_similar, score, details = self.are_images_ultra_similar(img1, img2)
                
                if is_similar:
                    print(f"  ğŸ¯ å‘ç°è¶…ç›¸ä¼¼: {img2.name}")
                    print(f"     ğŸ“Š PSNR: {details['psnr']:.1f}, SSIM: {details['ssim']:.3f}, "
                          f"ç›´æ–¹å›¾: {details['hist_similarity']:.3f}")
                    print(f"     ğŸ“Š è¾¹ç¼˜: {details['edge_similarity']:.3f}, "
                          f"å¤åˆåˆ†: {details['composite_score']:.1f}")
                    current_group.append(img2)
                    processed.add(str(img2))
            
            if len(current_group) > 1:
                duplicate_groups.append(current_group)
                print(f"  ğŸ“ ç›¸ä¼¼ç»„å¤§å°: {len(current_group)}")
            
            print()
        
        # å¤„ç†ç»“æœ
        end_time = datetime.now()
        self.stats['processing_time'] = (end_time - start_time).total_seconds()
        
        if not duplicate_groups:
            print("ğŸ‰ æœªå‘ç°è¶…ç›¸ä¼¼å›¾ç‰‡ï¼æ‰€æœ‰å›¾ç‰‡éƒ½è¶³å¤Ÿç‹¬ç‰¹ã€‚")
            self.stats['final_kept'] = len(image_files)
            
            # å¦‚æœæŒ‡å®šè¾“å‡ºç›®å½•ï¼Œå¤åˆ¶æ‰€æœ‰æ–‡ä»¶
            if output_dir:
                output_path = Path(output_dir)
                output_path.mkdir(parents=True, exist_ok=True)
                for img in image_files:
                    shutil.copy2(img, output_path / img.name)
                print(f"ğŸ“ æ‰€æœ‰å›¾ç‰‡å·²å¤åˆ¶åˆ°: {output_path}")
            return
        
        print(f"ğŸ¯ å‘ç° {len(duplicate_groups)} ä¸ªè¶…ç›¸ä¼¼ç»„:")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if output_dir:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
        else:
            output_path = qualified_path.parent / "qualified_final"
            output_path.mkdir(parents=True, exist_ok=True)
        
        kept_files = []
        removed_files = []
        
        # å¤„ç†ç›¸ä¼¼ç»„
        for i, group in enumerate(duplicate_groups):
            print(f"\nğŸ“ å¤„ç†ç›¸ä¼¼ç»„ {i+1}/{len(duplicate_groups)}: {len(group)} å¼ å›¾ç‰‡")
            
            # é€‰æ‹©æœ€ä½³å›¾ç‰‡
            best_img = self.select_best_qualified_image(group)
            
            for img in group:
                if img == best_img:
                    kept_files.append(img)
                    shutil.copy2(img, output_path / img.name)
                    print(f"  âœ… ä¿ç•™: {img.name}")
                else:
                    removed_files.append(img)
                    print(f"  ğŸ—‘ï¸ ç§»é™¤: {img.name}")
        
        # å¤åˆ¶éé‡å¤æ–‡ä»¶
        for img in image_files:
            if not any(img in group for group in duplicate_groups):
                shutil.copy2(img, output_path / img.name)
                kept_files.append(img)
        
        self.stats['final_kept'] = len(kept_files)
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = {
            'timestamp': end_time.isoformat(),
            'input_directory': str(qualified_path),
            'output_directory': str(output_path),
            'ultra_strict_settings': {
                'psnr_threshold': self.psnr_threshold,
                'ssim_threshold': self.ssim_threshold,
                'composite_threshold': self.composite_threshold,
                'hist_threshold': self.hist_threshold,
                'edge_threshold': self.edge_threshold,
                'conditions_required': self.conditions_required
            },
            'statistics': self.stats,
            'results': {
                'total_input_images': len(image_files),
                'duplicate_groups_found': len(duplicate_groups),
                'images_kept': len(kept_files),
                'images_removed': len(removed_files),
                'reduction_rate': f"{(len(removed_files)/len(image_files)*100):.1f}%"
            },
            'duplicate_groups': [
                {
                    'group_id': i+1,
                    'images': [str(img) for img in group],
                    'kept_image': str(self.select_best_qualified_image(group))
                }
                for i, group in enumerate(duplicate_groups)
            ]
        }
        
        report_path = output_path / "ultra_strict_processing_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ‰ è¶…ä¸¥æ ¼å¤„ç†å®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   â±ï¸  å¤„ç†æ—¶é—´: {self.stats['processing_time']:.1f}ç§’")
        print(f"   ğŸ“ è¾“å…¥å›¾ç‰‡: {len(image_files)}å¼ ")
        print(f"   ğŸ” æ¯”è¾ƒæ¬¡æ•°: {self.stats['total_comparisons']}")
        print(f"   ğŸ¯ ç›¸ä¼¼ç»„æ•°: {len(duplicate_groups)}")
        print(f"   âœ… ä¿ç•™å›¾ç‰‡: {len(kept_files)}å¼ ")
        print(f"   ğŸ—‘ï¸ ç§»é™¤å›¾ç‰‡: {len(removed_files)}å¼ ")
        print(f"   ğŸ“‰ å‹ç¼©ç‡: {(len(removed_files)/len(image_files)*100):.1f}%")
        print(f"   ğŸ“ è¾“å‡ºç›®å½•: {output_path}")
        print(f"   ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Qualifiedå›¾ç‰‡è¶…ä¸¥æ ¼å¤„ç†å™¨")
    parser.add_argument('qualified_dir', help='qualifiedå›¾ç‰‡ç›®å½•è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºç›®å½•ï¼ˆç­›é€‰åçš„æœ€ç»ˆå›¾ç‰‡ï¼‰')
    parser.add_argument('--psnr', type=float, default=65.0, help='PSNRé˜ˆå€¼ (é»˜è®¤: 65.0)')
    parser.add_argument('--ssim', type=float, default=0.92, help='SSIMé˜ˆå€¼ (é»˜è®¤: 0.92)')
    parser.add_argument('--composite', type=float, default=82.0, help='å¤åˆè¯„åˆ†é˜ˆå€¼ (é»˜è®¤: 82.0)')
    parser.add_argument('--hist', type=float, default=0.95, help='ç›´æ–¹å›¾é˜ˆå€¼ (é»˜è®¤: 0.95)')
    parser.add_argument('--edge', type=float, default=0.88, help='è¾¹ç¼˜é˜ˆå€¼ (é»˜è®¤: 0.88)')
    parser.add_argument('--conditions', type=int, default=4, help='å¿…é¡»æ»¡è¶³çš„æ¡ä»¶æ•° (é»˜è®¤: 4/5)')
    
    args = parser.parse_args()
    
    processor = QualifiedImageProcessor(
        psnr_threshold=args.psnr,
        ssim_threshold=args.ssim,
        composite_threshold=args.composite,
        hist_threshold=args.hist,
        edge_threshold=args.edge,
        conditions_required=args.conditions
    )
    
    processor.process_qualified_directory(args.qualified_dir, args.output)

if __name__ == "__main__":
    main()
