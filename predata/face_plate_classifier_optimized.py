#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ - é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬
ä¸»è¦ä¼˜åŒ–ç‚¹ï¼š
1. å¤šçº¿ç¨‹/å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†
2. æ‰¹é‡å›¾ç‰‡é¢„å¤„ç†
3. å†…å­˜æ± ç®¡ç†
4. å›¾ç‰‡é¢„åŠ è½½å’Œç¼“å­˜
5. ä¼˜åŒ–çš„GPUå†…å­˜ç®¡ç†
6. å‡å°‘é‡å¤è®¡ç®—
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import logging
import gc
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import threading
from queue import Queue, Empty
import multiprocessing as mp
from functools import lru_cache
import warnings
warnings.filterwarnings('ignore')

# é…ç½®ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨å¯¼å…¥æ·±åº¦å­¦ä¹ åº“ä¹‹å‰è®¾ç½®
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # å¯ç”¨GPU 0å’Œ1
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'     # å‡å°‘TensorFlowæ—¥å¿—è¾“å‡º
os.environ['OMP_NUM_THREADS'] = '4'          # é™åˆ¶OpenMPçº¿ç¨‹æ•°
os.environ['OPENBLAS_NUM_THREADS'] = '4'     # é™åˆ¶OpenBLASçº¿ç¨‹æ•°

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('face_plate_classifier_optimized.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–åº“"""
    missing_deps = []
    imported_modules = {}
    
    # æ£€æŸ¥RetinaFace
    try:
        from retinaface import RetinaFace
        imported_modules['RetinaFace'] = RetinaFace
        logger.info("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    # æ£€æŸ¥YOLO
    try:
        from ultralytics import YOLO
        imported_modules['YOLO'] = YOLO
        logger.info("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    # æ£€æŸ¥EasyOCR
    try:
        import easyocr
        imported_modules['easyocr'] = easyocr
        logger.info("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    # æ£€æŸ¥torchï¼ˆç”¨äºGPUæ£€æŸ¥ï¼‰
    try:
        import torch
        imported_modules['torch'] = torch
        logger.info("âœ… PyTorch åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ PyTorch åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("torch")
    
    if missing_deps:
        logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        logger.error("è¯·å®‰è£…ç¼ºå°‘çš„åº“:")
        for dep in missing_deps:
            logger.error(f"  pip install {dep}")
        return None
    
    return imported_modules

# æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–
modules = check_dependencies()
if modules is None:
    exit(1)

# ä»æ£€æŸ¥ç»“æœä¸­è·å–æ¨¡å—
RetinaFace = modules['RetinaFace']
YOLO = modules['YOLO']
easyocr = modules['easyocr']
torch = modules['torch']

class OptimizedConfig:
    """ä¼˜åŒ–é…ç½®ç±»"""
    
    # ç›®å½•é…ç½®
    INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames84'
    OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames84'
    PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'
    
    # æ–°è®¡åˆ†ç³»ç»Ÿé˜ˆå€¼
    SCORE_THRESHOLD = 5                # æ€»åˆ†é˜ˆå€¼ï¼ˆ>5åˆ†ç¬¦åˆè¦æ±‚ï¼‰
    CLEAR_FACE_SCORE = 2              # æ¸…æ™°æ­£è„¸å¾—åˆ†
    CLEAR_PLATE_SCORE = 2             # æ¸…æ™°è½¦ç‰Œå¾—åˆ†
    TEXT_RECOGNITION_SCORE = 2        # æ–‡å­—è¯†åˆ«å¾—åˆ†ï¼ˆæœ‰æ–‡å­—å³å¾—åˆ†ï¼‰
    
    # æ£€æµ‹é˜ˆå€¼
    YAW_ANGLE_THRESHOLD = 35.0        # yawè§’åº¦é˜ˆå€¼
    MIN_FACE_CONFIDENCE = 0.8         # æœ€å°äººè„¸ç½®ä¿¡åº¦
    MIN_PLATE_CONFIDENCE = 0.5        # æœ€å°è½¦ç‰Œç½®ä¿¡åº¦
    MIN_FACE_SIZE = 60                # æœ€å°äººè„¸å°ºå¯¸
    MIN_PLATE_SIZE = 50               # æœ€å°è½¦ç‰Œå°ºå¯¸
    MIN_FACE_CLARITY_SCORE = 30.0     # æœ€å°æ¸…æ™°åº¦åˆ†æ•°
    MAX_FACE_DISTANCE_RATIO = 0.3     # æœ€å¤§è·ç¦»æ¯”ä¾‹
    FACE_AREA_THRESHOLD = 3600        # äººè„¸é¢ç§¯é˜ˆå€¼
    MIN_TEXT_CONFIDENCE = 0.5         # æœ€å°æ–‡å­—ç½®ä¿¡åº¦
    MIN_TEXT_LENGTH = 3               # æœ€å°æ–‡å­—é•¿åº¦
    
    # å›¾åƒå¤„ç†å‚æ•°
    MAX_IMAGE_SIZE = (1280, 720)
    SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
    
    # æ€§èƒ½ä¼˜åŒ–å‚æ•°
    MAX_WORKERS = min(8, mp.cpu_count())        # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
    BATCH_SIZE = 32                             # æ‰¹å¤„ç†å¤§å°
    PREFETCH_BUFFER_SIZE = 100                  # é¢„å–ç¼“å†²åŒºå¤§å°
    IMAGE_CACHE_SIZE = 1000                     # å›¾åƒç¼“å­˜å¤§å°
    GC_FREQUENCY = 50                           # åƒåœ¾å›æ”¶é¢‘ç‡
    PROGRESS_UPDATE_FREQUENCY = 20              # è¿›åº¦æ›´æ–°é¢‘ç‡
    ENABLE_IMAGE_CACHE = True                   # å¯ç”¨å›¾åƒç¼“å­˜
    ENABLE_PARALLEL_PROCESSING = True           # å¯ç”¨å¹¶è¡Œå¤„ç†
    USE_PROCESS_POOL = False                    # ä½¿ç”¨è¿›ç¨‹æ± ï¼ˆé»˜è®¤ä½¿ç”¨çº¿ç¨‹æ± ï¼‰
    
    # GPUé…ç½®ï¼ˆå¯ç”¨GPUåŠ é€Ÿï¼‰
    USE_GPU = True
    GPU_DEVICE_ID = 1                 # ä½¿ç”¨GPU 1ï¼ˆGPU 0æ­£åœ¨è¢«å ç”¨ï¼‰
    ENABLE_TORCH_OPTIMIZATION = True
    GPU_MEMORY_FRACTION = 0.8         # GPUå†…å­˜ä½¿ç”¨æ¯”ä¾‹
    
    # å›¾åƒé¢„å¤„ç†ä¼˜åŒ– - ä¿®æ”¹ä¸ºä¿æŠ¤å›¾åƒè´¨é‡
    ENABLE_IMAGE_PREPROCESSING = False  # ç¦ç”¨å›¾åƒé¢„å¤„ç†ä»¥ä¿æŒåŸå§‹è´¨é‡
    RESIZE_FOR_SPEED = False           # ç¦ç”¨ä¸ºé€Ÿåº¦è°ƒæ•´å›¾åƒå¤§å°
    SPEED_RESIZE_SIZE = (640, 480)     # é€Ÿåº¦ä¼˜åŒ–æ—¶çš„å›¾åƒå¤§å°ï¼ˆå·²ç¦ç”¨ï¼‰
    
    # å›¾åƒè´¨é‡ä¿æŠ¤è®¾ç½®
    PRESERVE_IMAGE_QUALITY = True      # ç¡®ä¿ä¸å‹ç¼©å›¾ç‰‡
    IMAGE_READ_FLAGS = cv2.IMREAD_COLOR  # ä½¿ç”¨é«˜è´¨é‡è¯»å–æ ‡å¿—
    JPEG_QUALITY = 100                 # JPEGä¿å­˜è´¨é‡ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ï¼‰
    PNG_COMPRESSION = 0                # PNGå‹ç¼©çº§åˆ«ï¼ˆ0=æ— å‹ç¼©ï¼‰
    
    @classmethod
    def get_output_dirs(cls):
        """è·å–è¾“å‡ºç›®å½•é…ç½®"""
        return {
            'qualified': os.path.join(cls.OUTPUT_BASE_DIR, "qualified"),
            'qualified_1_4_faces': os.path.join(cls.OUTPUT_BASE_DIR, "qualified", "1-4å¼ äººè„¸"),
            'qualified_5_8_faces': os.path.join(cls.OUTPUT_BASE_DIR, "qualified", "5-8å¼ äººè„¸"),
            'qualified_9_plus_faces': os.path.join(cls.OUTPUT_BASE_DIR, "qualified", "9å¼ äººè„¸ä»¥ä¸Š"),
            'insufficient_score': os.path.join(cls.OUTPUT_BASE_DIR, "insufficient_score"),
            'no_content': os.path.join(cls.OUTPUT_BASE_DIR, "no_content"),
            'analysis': os.path.join(cls.OUTPUT_BASE_DIR, "analysis")
        }

class ImageCache:
    """çº¿ç¨‹å®‰å…¨çš„å›¾åƒç¼“å­˜"""
    
    def __init__(self, max_size: int = 1000):
        self.max_size = max_size
        self.cache = {}
        self.access_order = []
        self.lock = threading.RLock()
    
    def get(self, path: str) -> Optional[np.ndarray]:
        """è·å–ç¼“å­˜çš„å›¾åƒ"""
        with self.lock:
            if path in self.cache:
                # æ›´æ–°è®¿é—®é¡ºåº
                self.access_order.remove(path)
                self.access_order.append(path)
                return self.cache[path].copy()
            return None
    
    def put(self, path: str, image: np.ndarray):
        """æ·»åŠ å›¾åƒåˆ°ç¼“å­˜"""
        with self.lock:
            # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„
            if len(self.cache) >= self.max_size:
                oldest_path = self.access_order.pop(0)
                del self.cache[oldest_path]
            
            self.cache[path] = image.copy()
            if path in self.access_order:
                self.access_order.remove(path)
            self.access_order.append(path)
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            self.access_order.clear()

class OptimizedImageProcessor:
    """ä¼˜åŒ–çš„å›¾åƒå¤„ç†å™¨"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.image_cache = ImageCache(config.IMAGE_CACHE_SIZE) if config.ENABLE_IMAGE_CACHE else None
    
    def load_image_optimized(self, image_path: str) -> Optional[np.ndarray]:
        """ä¼˜åŒ–çš„å›¾åƒåŠ è½½ï¼Œä¿æŒåŸå§‹è´¨é‡"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            if self.image_cache:
                cached_img = self.image_cache.get(image_path)
                if cached_img is not None:
                    return cached_img
            
            # ä½¿ç”¨é«˜è´¨é‡æ ‡å¿—åŠ è½½å›¾åƒ
            img = cv2.imread(image_path, cv2.IMREAD_COLOR)
            if img is None:
                return None
            
            # è·³è¿‡å›¾åƒé¢„å¤„ç†ä»¥ä¿æŒåŸå§‹è´¨é‡
            # å›¾åƒé¢„å¤„ç†ä¼˜åŒ–å·²ç¦ç”¨ä»¥ä¿æŠ¤å›¾åƒè´¨é‡
            
            # æ·»åŠ åˆ°ç¼“å­˜
            if self.image_cache:
                self.image_cache.put(image_path, img)
            
            return img
            
        except Exception as e:
            logger.debug(f"å›¾åƒåŠ è½½å¤±è´¥ {image_path}: {e}")
            return None
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç† - å·²ç¦ç”¨ä»¥ä¿æŠ¤å›¾åƒè´¨é‡"""
        try:
            # é¢„å¤„ç†å·²ç¦ç”¨ä»¥ä¿æŒåŸå§‹å›¾åƒè´¨é‡
            # ç›´æ¥è¿”å›åŸå§‹å›¾åƒï¼Œä¸è¿›è¡Œä»»ä½•å¤„ç†
            return image
            
        except Exception as e:
            logger.debug(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            return image

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls, config: OptimizedConfig):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self, config: OptimizedConfig):
        if self._initialized:
            return
        
        self.config = config
        self.device = self._setup_device()
        self._initialize_models()
        self._initialized = True
    
    def _setup_device(self) -> str:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        try:
            if self.config.USE_GPU and torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                
                if self.config.GPU_DEVICE_ID < device_count:
                    device = f'cuda:{self.config.GPU_DEVICE_ID}'
                    gpu_name = torch.cuda.get_device_name(self.config.GPU_DEVICE_ID)
                    gpu_memory = torch.cuda.get_device_properties(self.config.GPU_DEVICE_ID).total_memory / 1024**3
                    logger.info(f"ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨: {gpu_name} (è®¾å¤‡ {self.config.GPU_DEVICE_ID})")
                    logger.info(f"ğŸ”¥ GPUæ˜¾å­˜: {gpu_memory:.1f} GB")
                    
                    # æ¸…ç†GPUç¼“å­˜
                    torch.cuda.empty_cache()
                    
                    # è®¾ç½®PyTorchä¼˜åŒ–
                    if self.config.ENABLE_TORCH_OPTIMIZATION:
                        torch.backends.cudnn.benchmark = True
                        torch.backends.cudnn.deterministic = False
                        logger.info("âš¡ PyTorchä¼˜åŒ–å·²å¯ç”¨")
                    
                    return device
                else:
                    logger.warning(f"âš ï¸  æŒ‡å®šçš„GPUè®¾å¤‡ID {self.config.GPU_DEVICE_ID} è¶…å‡ºèŒƒå›´ï¼Œå…±æœ‰ {device_count} ä¸ªGPU")
                    return 'cpu'
            else:
                if not torch.cuda.is_available():
                    logger.info("ğŸ’» æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                else:
                    logger.info("ğŸ’» GPUåŠ é€Ÿå·²ç¦ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                return 'cpu'
                
        except Exception as e:
            logger.error(f"âŒ è®¾å¤‡è®¾ç½®å¤±è´¥: {e}")
            return 'cpu'
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹"""
        try:
            # é…ç½®TensorFlow GPUä½¿ç”¨
            try:
                import tensorflow as tf
                
                if 'cuda' in self.device:
                    # é…ç½®GPUå†…å­˜å¢é•¿
                    gpus = tf.config.experimental.list_physical_devices('GPU')
                    if gpus:
                        try:
                            for gpu in gpus:
                                tf.config.experimental.set_memory_growth(gpu, True)
                                # è®¾ç½®å†…å­˜é™åˆ¶
                                memory_limit = int(tf.config.experimental.get_device_details(gpu)['device_name'])
                                tf.config.experimental.set_memory_growth(gpu, True)
                            logger.info("ğŸš€ TensorFlowå·²é…ç½®ä¸ºGPUæ¨¡å¼ï¼ˆå†…å­˜å¢é•¿ï¼‰")
                        except RuntimeError as e:
                            logger.warning(f"âš ï¸  GPUå†…å­˜å¢é•¿é…ç½®å¤±è´¥: {e}")
                else:
                    tf.config.set_visible_devices([], 'GPU')
                    logger.info("ğŸ”§ TensorFlowå·²é…ç½®ä¸ºCPUæ¨¡å¼")
            except ImportError:
                logger.info("â„¹ï¸  æœªæ£€æµ‹åˆ°TensorFlow")
            
            # åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹
            logger.info("ğŸš— åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
            self._initialize_plate_model()
            
            # åˆå§‹åŒ–OCRæ¨¡å‹
            logger.info("ğŸ“ åˆå§‹åŒ–EasyOCRæ¨¡å‹...")
            self._initialize_ocr()
            
            # åˆå§‹åŒ–RetinaFaceï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼‰
            self.retinaface_initialized = False
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _initialize_plate_model(self):
        """åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹"""
        if not os.path.exists(self.config.PLATE_MODEL_PATH):
            raise FileNotFoundError(f"è½¦ç‰Œæ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.config.PLATE_MODEL_PATH}")
        
        self.plate_model = YOLO(self.config.PLATE_MODEL_PATH)
        
        if 'cuda' in self.device:
            logger.info(f"âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆGPUæ¨¡å¼ - {self.device}ï¼‰")
        else:
            logger.info("âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆCPUæ¨¡å¼ï¼‰")
    
    def _initialize_ocr(self):
        """åˆå§‹åŒ–OCRæ¨¡å‹"""
        try:
            # è®¾ç½®EasyOCRï¼ˆæ ¹æ®è®¾å¤‡é…ç½®ï¼‰
            gpu_enabled = 'cuda' in self.device
            self.ocr_reader = easyocr.Reader(
                ['ch_sim', 'en'],  # æ”¯æŒä¸­æ–‡ç®€ä½“å’Œè‹±æ–‡
                gpu=gpu_enabled    # æ ¹æ®è®¾å¤‡é…ç½®å¯ç”¨/ç¦ç”¨GPU
            )
            
            if gpu_enabled:
                logger.info(f"âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (GPUæ¨¡å¼ - {self.device})")
            else:
                logger.info("âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (CPUæ¨¡å¼)")
                
        except Exception as e:
            logger.error(f"âŒ OCRæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ocr_reader = None
    
    def _ensure_retinaface_initialized(self):
        """ç¡®ä¿RetinaFaceå·²åˆå§‹åŒ–"""
        if not self.retinaface_initialized:
            try:
                # åˆ›å»ºæµ‹è¯•å›¾åƒ
                test_img = np.ones((100, 100, 3), dtype=np.uint8) * 128
                RetinaFace.detect_faces(test_img)
                self.retinaface_initialized = True
                logger.info("âœ… RetinaFaceæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ RetinaFaceåˆå§‹åŒ–å¤±è´¥: {e}")
                raise

class OptimizedFacePlateClassifier:
    """ä¼˜åŒ–çš„æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨"""
    
    def __init__(self, config: Optional[OptimizedConfig] = None):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        self.config = config or OptimizedConfig()
        self.start_time = time.time()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'qualified': 0,           # ç¬¦åˆæ¡ä»¶(æ€»åˆ†>5)
            'qualified_1_4_faces': 0, # ç¬¦åˆæ¡ä»¶ä¸”1-4å¼ äººè„¸
            'qualified_5_8_faces': 0, # ç¬¦åˆæ¡ä»¶ä¸”5-8å¼ äººè„¸
            'qualified_9_plus_faces': 0, # ç¬¦åˆæ¡ä»¶ä¸”9å¼ äººè„¸ä»¥ä¸Š
            'insufficient_score': 0,  # åˆ†æ•°ä¸å¤Ÿ
            'no_content': 0,          # æ— ä»»ä½•æœ‰æ•ˆå†…å®¹
            'failed': 0               # å¤„ç†å¤±è´¥
        }
        
        # è¯¦ç»†åˆ†æç»“æœ
        self.analysis_results = []
        self.analysis_lock = threading.Lock()
        
        # è·å–è¾“å‡ºç›®å½•
        self.output_dirs = self.config.get_output_dirs()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_output_dirs()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.image_processor = OptimizedImageProcessor(self.config)
        self.model_manager = ModelManager(self.config)
        
        logger.info("ğŸš€ æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆï¼ˆé«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰")
    
    def _create_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        for name, dir_path in self.output_dirs.items():
            try:
                os.makedirs(dir_path, exist_ok=True)
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
                raise
    
    def calculate_face_clarity(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """è®¡ç®—äººè„¸åŒºåŸŸçš„æ¸…æ™°åº¦ - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            x1, y1, x2, y2 = bbox
            h, w = image.shape[:2]
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w, int(x2)), min(h, int(y2))
            
            if x2 <= x1 or y2 <= y1:
                return 0.0
            
            face_region = image[y1:y2, x1:x2]
            if face_region.size == 0:
                return 0.0
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(face_region.shape) == 3:
                gray_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_region
            
            # å¿«é€Ÿæ¸…æ™°åº¦è®¡ç®—
            laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
            return float(laplacian_var)
            
        except Exception as e:
            logger.debug(f"æ¸…æ™°åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0
            
            horizontal_offset = nose[0] - eye_center[0]
            normalized_offset = horizontal_offset / eye_width
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0
    
    def is_face_clear_and_close(self, image: np.ndarray, bbox: Tuple[int, int, int, int], img_size: Tuple[int, int]) -> Tuple[bool, Dict]:
        """åˆ¤æ–­äººè„¸æ˜¯å¦æ¸…æ™°ä¸”è·ç¦»åˆé€‚"""
        try:
            clarity_score = self.calculate_face_clarity(image, bbox)
            
            x1, y1, x2, y2 = bbox
            face_area = (x2 - x1) * (y2 - y1)
            img_width, img_height = img_size
            img_area = img_width * img_height
            distance_score = face_area / img_area
            
            is_clear = clarity_score >= self.config.MIN_FACE_CLARITY_SCORE
            is_close = distance_score >= self.config.MAX_FACE_DISTANCE_RATIO
            is_large_enough = face_area >= self.config.FACE_AREA_THRESHOLD
            
            is_good_quality = is_clear and (is_close or is_large_enough)
            
            quality_info = {
                'clarity_score': clarity_score,
                'distance_score': distance_score,
                'face_area': face_area,
                'is_clear': is_clear,
                'is_close': is_close,
                'is_large_enough': is_large_enough,
                'is_good_quality': is_good_quality
            }
            
            return is_good_quality, quality_info
            
        except Exception as e:
            logger.debug(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return False, {'error': str(e)}
    
    def detect_faces_batch(self, image_batch: List[Tuple[str, np.ndarray]]) -> List[Tuple[int, List[Dict]]]:
        """æ‰¹é‡äººè„¸æ£€æµ‹ - é’ˆå¯¹å¤šä¸ªå›¾åƒ"""
        results = []
        
        # ç¡®ä¿RetinaFaceå·²åˆå§‹åŒ–
        self.model_manager._ensure_retinaface_initialized()
        
        for image_path, img in image_batch:
            try:
                detections = RetinaFace.detect_faces(img)
                
                if not isinstance(detections, dict) or len(detections) == 0:
                    results.append((0, []))
                    continue
                
                img_height, img_width = img.shape[:2]
                img_size = (img_width, img_height)
                
                clear_frontal_faces = []
                
                for face_key, face_data in detections.items():
                    try:
                        confidence = face_data.get('score', 0.0)
                        if confidence < self.config.MIN_FACE_CONFIDENCE:
                            continue
                        
                        facial_area = face_data['facial_area']
                        landmarks = face_data.get('landmarks', {})
                        
                        if not landmarks:
                            continue
                        
                        x1, y1, x2, y2 = facial_area
                        face_width = x2 - x1
                        face_height = y2 - y1
                        
                        if min(face_width, face_height) < self.config.MIN_FACE_SIZE:
                            continue
                        
                        # æ£€æŸ¥äººè„¸æ¸…æ™°åº¦å’Œè·ç¦»
                        is_good_quality, quality_info = self.is_face_clear_and_close(img, facial_area, img_size)
                        
                        if not is_good_quality:
                            continue
                        
                        # è®¡ç®—yawè§’åº¦
                        yaw_angle = self.calculate_yaw_angle(landmarks)
                        
                        # åˆ¤æ–­æ˜¯å¦ä¸ºæ­£è„¸
                        is_frontal = yaw_angle <= self.config.YAW_ANGLE_THRESHOLD
                        
                        if is_frontal:  # åªè®°å½•æ¸…æ™°çš„æ­£è„¸
                            face_info = {
                                'confidence': confidence,
                                'yaw_angle': yaw_angle,
                                'is_frontal': is_frontal,
                                'facial_area': facial_area,
                                'face_size': (face_width, face_height),
                                'quality_info': quality_info
                            }
                            
                            clear_frontal_faces.append(face_info)
                    
                    except Exception as e:
                        logger.debug(f"åˆ†æäººè„¸å¤±è´¥: {e}")
                        continue
                
                results.append((len(clear_frontal_faces), clear_frontal_faces))
                
            except Exception as e:
                logger.debug(f"äººè„¸æ£€æµ‹å¤±è´¥ {image_path}: {e}")
                results.append((0, []))
        
        return results
    
    def detect_plates_batch(self, image_batch: List[Tuple[str, np.ndarray]]) -> List[Tuple[int, List[Dict]]]:
        """æ‰¹é‡è½¦ç‰Œæ£€æµ‹"""
        results = []
        
        # å‡†å¤‡å›¾åƒè·¯å¾„åˆ—è¡¨
        image_paths = [path for path, _ in image_batch]
        
        try:
            # æ‰¹é‡æ¨ç†
            batch_results = self.model_manager.plate_model(image_paths, verbose=False, device=self.model_manager.device)
            
            for i, (image_path, img) in enumerate(image_batch):
                try:
                    if i >= len(batch_results):
                        results.append((0, []))
                        continue
                    
                    result = batch_results[i]
                    
                    if result.boxes is None or len(result.boxes) == 0:
                        results.append((0, []))
                        continue
                    
                    clear_plates = []
                    
                    for box in result.boxes:
                        try:
                            confidence = float(box.conf[0])
                            if confidence < self.config.MIN_PLATE_CONFIDENCE:
                                continue
                            
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            plate_width = x2 - x1
                            plate_height = y2 - y1
                            
                            if min(plate_width, plate_height) < self.config.MIN_PLATE_SIZE:
                                continue
                            
                            plate_info = {
                                'confidence': confidence,
                                'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                'plate_size': (float(plate_width), float(plate_height))
                            }
                            
                            clear_plates.append(plate_info)
                        
                        except Exception as e:
                            logger.debug(f"åˆ†æè½¦ç‰Œå¤±è´¥: {e}")
                            continue
                    
                    results.append((len(clear_plates), clear_plates))
                
                except Exception as e:
                    logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
                    results.append((0, []))
        
        except Exception as e:
            logger.debug(f"æ‰¹é‡è½¦ç‰Œæ£€æµ‹å¤±è´¥: {e}")
            # å¦‚æœæ‰¹é‡å¤„ç†å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
            results = [(0, [])] * len(image_batch)
        
        return results
    
    def detect_text_batch(self, image_batch: List[Tuple[str, np.ndarray]]) -> List[Tuple[int, List[Dict]]]:
        """æ‰¹é‡æ–‡å­—æ£€æµ‹"""
        results = []
        
        if self.model_manager.ocr_reader is None:
            return [(0, [])] * len(image_batch)
        
        for image_path, img in image_batch:
            try:
                ocr_results = self.model_manager.ocr_reader.readtext(img)
                
                if not ocr_results:
                    results.append((0, []))
                    continue
                
                valid_texts = []
                
                for bbox, text, confidence in ocr_results:
                    try:
                        # ç¡®ä¿confidenceæ˜¯floatç±»å‹
                        confidence = float(confidence) if confidence is not None else 0.0
                        
                        if confidence < self.config.MIN_TEXT_CONFIDENCE:
                            continue
                        
                        cleaned_text = text.strip()
                        if len(cleaned_text) < self.config.MIN_TEXT_LENGTH:
                            continue
                        
                        # è¿‡æ»¤æ‰åªåŒ…å«ç¬¦å·çš„æ–‡å­—
                        if cleaned_text.replace(' ', '').replace('.', '').replace('-', '').replace('_', ''):
                            text_info = {
                                'text': cleaned_text,
                                'confidence': confidence,
                                'bbox': bbox
                            }
                            valid_texts.append(text_info)
                    
                    except Exception as e:
                        logger.debug(f"åˆ†ææ–‡å­—å¤±è´¥: {e}")
                        continue
                
                results.append((len(valid_texts), valid_texts))
                
            except Exception as e:
                logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
                results.append((0, []))
        
        return results
    
    def process_image_batch(self, image_paths: List[str]) -> List[Tuple[str, str, Dict]]:
        """æ‰¹é‡å¤„ç†å›¾åƒ"""
        try:
            # åŠ è½½å›¾åƒæ‰¹æ¬¡
            image_batch = []
            for path in image_paths:
                img = self.image_processor.load_image_optimized(path)
                if img is not None:
                    image_batch.append((path, img))
                else:
                    # å¦‚æœå›¾åƒåŠ è½½å¤±è´¥ï¼Œè·³è¿‡
                    continue
            
            if not image_batch:
                return []
            
            # æ‰¹é‡æ£€æµ‹
            face_results = self.detect_faces_batch(image_batch)
            plate_results = self.detect_plates_batch(image_batch)
            text_results = self.detect_text_batch(image_batch)
            
            # æ•´åˆç»“æœ
            batch_results = []
            for i, (image_path, img) in enumerate(image_batch):
                try:
                    filename = os.path.basename(image_path)
                    
                    # è·å–æ£€æµ‹ç»“æœ
                    frontal_count, face_details = face_results[i] if i < len(face_results) else (0, [])
                    plate_count, plate_details = plate_results[i] if i < len(plate_results) else (0, [])
                    text_count, text_details = text_results[i] if i < len(text_results) else (0, [])
                    
                    # æ–°è®¡åˆ†ç³»ç»Ÿ
                    score = 0
                    score_details = []
                    
                    # æ¸…æ™°æ­£è„¸ï¼šæ¯å¼ 2åˆ†
                    if frontal_count > 0:
                        face_score = frontal_count * self.config.CLEAR_FACE_SCORE
                        score += face_score
                        score_details.append(f"æ¸…æ™°æ­£è„¸ {frontal_count} å¼  Ã— {self.config.CLEAR_FACE_SCORE} = {face_score} åˆ†")
                    
                    # æ¸…æ™°è½¦ç‰Œï¼šæ¯å¼ 2åˆ†
                    if plate_count > 0:
                        plate_score = plate_count * self.config.CLEAR_PLATE_SCORE
                        score += plate_score
                        score_details.append(f"æ¸…æ™°è½¦ç‰Œ {plate_count} å¼  Ã— {self.config.CLEAR_PLATE_SCORE} = {plate_score} åˆ†")
                    
                    # å¯è¯†åˆ«æ–‡å­—ï¼šæœ‰æ–‡å­—å°±å¾—åˆ†
                    if text_count > 0:
                        text_score = self.config.TEXT_RECOGNITION_SCORE
                        score += text_score
                        score_details.append(f"å¯è¯†åˆ«æ–‡å­— {text_count} ä¸ªå­—æ®µ = {text_score} åˆ†")
                    
                    # åˆ¤æ–­æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼ˆæ€»åˆ†>5ï¼‰
                    meets_requirements = score > self.config.SCORE_THRESHOLD
                    
                    # åˆ›å»ºåˆ†æç»“æœ
                    analysis = {
                        'filename': filename,
                        'frontal_faces': frontal_count,
                        'license_plates': plate_count,
                        'text_count': text_count,
                        'total_score': score,
                        'score_details': score_details,
                        'meets_requirements': meets_requirements,
                        'score_threshold': self.config.SCORE_THRESHOLD,
                        'face_details': face_details,
                        'plate_details': plate_details,
                        'text_details': text_details,
                        'timestamp': time.time()
                    }
                    
                    # åˆ†ç±»é€»è¾‘
                    if meets_requirements:
                        # æ ¹æ®äººè„¸æ•°é‡è¿›ä¸€æ­¥åˆ†ç±»
                        face_category = self.get_face_count_category(frontal_count)
                        category = face_category
                        analysis['qualification_reason'] = f'æ€»åˆ† {score} åˆ† > {self.config.SCORE_THRESHOLD} åˆ†ï¼Œç¬¦åˆè¦æ±‚'
                        analysis['face_count_category'] = face_category
                        
                        # æ·»åŠ äººè„¸æ•°é‡è¯´æ˜
                        if frontal_count == 0:
                            analysis['face_count_description'] = 'æ— äººè„¸ä½†å…¶ä»–æ¡ä»¶æ»¡è¶³'
                        elif 1 <= frontal_count <= 4:
                            analysis['face_count_description'] = f'{frontal_count}å¼ äººè„¸ (1-4å¼ )'
                        elif 5 <= frontal_count <= 8:
                            analysis['face_count_description'] = f'{frontal_count}å¼ äººè„¸ (5-8å¼ )'
                        else:
                            analysis['face_count_description'] = f'{frontal_count}å¼ äººè„¸ (9å¼ ä»¥ä¸Š)'
                    else:
                        if score == 0:
                            category = 'no_content'
                            analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ†ï¼Œæ— ä»»ä½•æœ‰æ•ˆå†…å®¹'
                        else:
                            category = 'insufficient_score'
                            analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ† â‰¤ {self.config.SCORE_THRESHOLD} åˆ†ï¼Œä¸ç¬¦åˆè¦æ±‚'
                    
                    analysis['category'] = category
                    
                    batch_results.append((image_path, category, analysis))
                
                except Exception as e:
                    logger.error(f"âŒ å›¾åƒåˆ†æå¤±è´¥ {image_path}: {e}")
                    error_analysis = {'filename': os.path.basename(image_path), 'error': str(e)}
                    batch_results.append((image_path, 'failed', error_analysis))
            
            return batch_results
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return []
    
    def get_face_count_category(self, face_count: int) -> str:
        """æ ¹æ®äººè„¸æ•°é‡ç¡®å®šåˆ†ç±»"""
        if 1 <= face_count <= 4:
            return 'qualified_1_4_faces'
        elif 5 <= face_count <= 8:
            return 'qualified_5_8_faces'
        elif face_count >= 9:
            return 'qualified_9_plus_faces'
        else:
            return 'qualified'  # é»˜è®¤åˆ†ç±»ï¼ˆ0å¼ äººè„¸ä½†å…¶ä»–æ¡ä»¶æ»¡è¶³ï¼‰
    
    def move_image_to_category(self, image_path: str, category: str) -> bool:
        """ç§»åŠ¨å›¾åƒåˆ°å¯¹åº”åˆ†ç±»ç›®å½•"""
        try:
            filename = os.path.basename(image_path)
            
            if category not in self.output_dirs:
                return False
            
            output_dir = self.output_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            shutil.move(image_path, output_path)
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def get_image_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        files = []
        input_path = Path(self.config.INPUT_DIR)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.config.INPUT_DIR}")
            return []
        
        logger.info(f"ğŸ” æ‰«æç›®å½•: {self.config.INPUT_DIR}")
        
        for ext in self.config.SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            files.extend(input_path.glob(pattern))
        
        image_files = sorted([str(f) for f in files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            analysis_dir = self.output_dirs['analysis']
            
            # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
            analysis_file = os.path.join(analysis_dir, "classification_analysis_optimized.json")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
            summary = {
                'total_processed': len(self.analysis_results),
                'statistics': self.stats.copy(),
                'processing_time': time.time() - self.start_time,
                'optimization_config': {
                    'max_workers': self.config.MAX_WORKERS,
                    'batch_size': self.config.BATCH_SIZE,
                    'enable_parallel_processing': self.config.ENABLE_PARALLEL_PROCESSING,
                    'enable_image_cache': self.config.ENABLE_IMAGE_CACHE,
                    'use_gpu': self.config.USE_GPU,
                    'gpu_device_id': self.config.GPU_DEVICE_ID
                },
                'scoring_system': {
                    'clear_face_score': self.config.CLEAR_FACE_SCORE,
                    'clear_plate_score': self.config.CLEAR_PLATE_SCORE,
                    'text_recognition_score': self.config.TEXT_RECOGNITION_SCORE,
                    'score_threshold': self.config.SCORE_THRESHOLD
                },
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(analysis_dir, "classification_summary_optimized.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        total_processed = (self.stats['qualified'] + self.stats['insufficient_score'] + 
                          self.stats['no_content'] + self.stats['failed'])
        
        logger.info("="*80)
        logger.info("ğŸ‰ æ­£è„¸å’Œè½¦ç‰Œåˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡ï¼ˆé«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰:")
        logger.info(f"âš¡ æ€§èƒ½é…ç½®:")
        logger.info(f"  - æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.config.MAX_WORKERS}")
        logger.info(f"  - æ‰¹å¤„ç†å¤§å°: {self.config.BATCH_SIZE}")
        logger.info(f"  - å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if self.config.ENABLE_PARALLEL_PROCESSING else 'ç¦ç”¨'}")
        logger.info(f"  - å›¾åƒç¼“å­˜: {'å¯ç”¨' if self.config.ENABLE_IMAGE_CACHE else 'ç¦ç”¨'}")
        logger.info(f"  - GPUåŠ é€Ÿ: {'å¯ç”¨' if self.config.USE_GPU else 'ç¦ç”¨'}")
        logger.info(f"  - è®¡ç®—è®¾å¤‡: {self.model_manager.device}")
        logger.info(f"âœ… ç¬¦åˆæ¡ä»¶æ€»è®¡(>{self.config.SCORE_THRESHOLD}åˆ†): {self.stats['qualified']:,}")
        logger.info(f"  ğŸ“¸ 1-4å¼ äººè„¸: {self.stats['qualified_1_4_faces']:,}")
        logger.info(f"  ğŸ‘¥ 5-8å¼ äººè„¸: {self.stats['qualified_5_8_faces']:,}")
        logger.info(f"  ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ 9å¼ äººè„¸ä»¥ä¸Š: {self.stats['qualified_9_plus_faces']:,}")
        logger.info(f"âŒ åˆ†æ•°ä¸å¤Ÿ(â‰¤{self.config.SCORE_THRESHOLD}åˆ†): {self.stats['insufficient_score']:,}")
        logger.info(f"âŒ æ— ä»»ä½•å†…å®¹: {self.stats['no_content']:,}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,}")
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,}")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            avg_speed = total_processed / processing_time
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            success_rate = (self.stats['qualified'] / total_processed) * 100
            logger.info(f"ğŸ“ˆ ç¬¦åˆæ¡ä»¶æ¯”ä¾‹: {success_rate:.1f}%")
        
        logger.info("="*80)
    
    def worker_function(self, image_batch: List[str]) -> List[Tuple[str, str, Dict]]:
        """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
        return self.process_image_batch(image_batch)
    
    def run(self):
        """è¿è¡Œåˆ†ç±»å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ï¼ˆé«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ï¼‰...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {self.config.INPUT_DIR}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.config.OUTPUT_BASE_DIR}")
        logger.info(f"ğŸ’» è®¡ç®—è®¾å¤‡: {self.model_manager.device}")
        logger.info(f"âš¡ æ€§èƒ½é…ç½®:")
        logger.info(f"  - æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.config.MAX_WORKERS}")
        logger.info(f"  - æ‰¹å¤„ç†å¤§å°: {self.config.BATCH_SIZE}")
        logger.info(f"  - å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if self.config.ENABLE_PARALLEL_PROCESSING else 'ç¦ç”¨'}")
        logger.info(f"  - å›¾åƒç¼“å­˜: {'å¯ç”¨' if self.config.ENABLE_IMAGE_CACHE else 'ç¦ç”¨'}")
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files()
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return
        
        try:
            if self.config.ENABLE_PARALLEL_PROCESSING and len(image_files) > self.config.BATCH_SIZE:
                self._run_parallel(image_files)
            else:
                self._run_sequential(image_files)
        
        finally:
            # ä¿å­˜ç»“æœå’Œç»Ÿè®¡
            self.save_analysis_results()
            self.print_final_statistics()
            
            # æ¸…ç†ç¼“å­˜
            if self.image_processor.image_cache:
                self.image_processor.image_cache.clear()
            
            # æ¸…ç†GPUå†…å­˜
            if 'cuda' in self.model_manager.device:
                torch.cuda.empty_cache()
    
    def _run_sequential(self, image_files: List[str]):
        """é¡ºåºå¤„ç†æ¨¡å¼"""
        logger.info("ğŸ”„ ä½¿ç”¨é¡ºåºå¤„ç†æ¨¡å¼...")
        
        # åˆ†æ‰¹å¤„ç†
        total_batches = (len(image_files) + self.config.BATCH_SIZE - 1) // self.config.BATCH_SIZE
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * self.config.BATCH_SIZE
            end_idx = min(start_idx + self.config.BATCH_SIZE, len(image_files))
            batch = image_files[start_idx:end_idx]
            
            # å¤„ç†æ‰¹æ¬¡
            batch_results = self.process_image_batch(batch)
            self._process_batch_results(batch_results)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (batch_idx + 1) / total_batches * 100
            processed = end_idx
            total = len(image_files)
            print(f"\rè¿›åº¦: {processed}/{total} ({progress:.1f}%) - æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}", 
                  end='', flush=True)
            
            # å®šæœŸåƒåœ¾å›æ”¶
            if batch_idx % 10 == 0:
                gc.collect()
                if 'cuda' in self.model_manager.device:
                    torch.cuda.empty_cache()
        
        print()  # æ¢è¡Œ
    
    def _run_parallel(self, image_files: List[str]):
        """å¹¶è¡Œå¤„ç†æ¨¡å¼"""
        logger.info(f"ğŸš€ ä½¿ç”¨å¹¶è¡Œå¤„ç†æ¨¡å¼ ({self.config.MAX_WORKERS} ä¸ªå·¥ä½œçº¿ç¨‹)...")
        
        # åˆ†æ‰¹æ¬¡
        batches = []
        for i in range(0, len(image_files), self.config.BATCH_SIZE):
            batches.append(image_files[i:i + self.config.BATCH_SIZE])
        
        logger.info(f"ğŸ“¦ åˆ†ä¸º {len(batches)} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æ¬¡æœ€å¤š {self.config.BATCH_SIZE} å¼ å›¾ç‰‡")
        
        processed_count = 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± 
        if self.config.USE_PROCESS_POOL:
            executor_class = ProcessPoolExecutor
            logger.info("ğŸ”§ ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†")
        else:
            executor_class = ThreadPoolExecutor
            logger.info("ğŸ”§ ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†")
        
        with executor_class(max_workers=self.config.MAX_WORKERS) as executor:
            # æäº¤ä»»åŠ¡
            future_to_batch = {executor.submit(self.worker_function, batch): batch for batch in batches}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_batch):
                try:
                    batch_results = future.result()
                    self._process_batch_results(batch_results)
                    
                    processed_count += len(future_to_batch[future])
                    progress = processed_count / len(image_files) * 100
                    print(f"\rè¿›åº¦: {processed_count}/{len(image_files)} ({progress:.1f}%)", 
                          end='', flush=True)
                    
                except Exception as e:
                    batch = future_to_batch[future]
                    logger.error(f"âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
                    # æ ‡è®°æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å›¾ç‰‡ä¸ºå¤±è´¥
                    for image_path in batch:
                        self.stats['failed'] += 1
                        error_analysis = {'filename': os.path.basename(image_path), 'error': str(e)}
                        with self.analysis_lock:
                            self.analysis_results.append(error_analysis)
        
        print()  # æ¢è¡Œ
    
    def _process_batch_results(self, batch_results: List[Tuple[str, str, Dict]]):
        """å¤„ç†æ‰¹æ¬¡ç»“æœ"""
        for image_path, category, analysis in batch_results:
            try:
                if category != 'failed':
                    # ç§»åŠ¨åˆ°å¯¹åº”ç›®å½•
                    if self.move_image_to_category(image_path, category):
                        self.stats[category] += 1
                        # å¦‚æœæ˜¯ç¬¦åˆæ¡ä»¶çš„åˆ†ç±»ï¼ŒåŒæ—¶æ›´æ–°æ€»çš„qualifiedç»Ÿè®¡
                        if category.startswith('qualified_'):
                            # æ³¨æ„ï¼šè¿™é‡Œä¸è¦é‡å¤åŠ ï¼Œå› ä¸ºqualified_*å·²ç»åŒ…å«åœ¨qualifiedç»Ÿè®¡ä¸­
                            pass
                    else:
                        self.stats['failed'] += 1
                        analysis['move_failed'] = True
                else:
                    self.stats['failed'] += 1
                
                # ä¿å­˜åˆ†æç»“æœï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
                with self.analysis_lock:
                    self.analysis_results.append(analysis)
            
            except Exception as e:
                logger.error(f"âŒ å¤„ç†ç»“æœå¤±è´¥ {image_path}: {e}")
                self.stats['failed'] += 1

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºé…ç½®
        config = OptimizedConfig()
        
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(config.INPUT_DIR):
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {config.INPUT_DIR}")
            return
        
        # æ£€æŸ¥è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        if not os.path.exists(config.PLATE_MODEL_PATH):
            logger.error(f"âŒ è½¦ç‰Œæ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {config.PLATE_MODEL_PATH}")
            return
        
        # åˆ›å»ºåˆ†ç±»å™¨å¹¶è¿è¡Œ
        classifier = OptimizedFacePlateClassifier(config)
        classifier.run()
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
