#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ - æ”¹è¿›ç‰ˆæœ¬
ä½¿ç”¨æ–°çš„è®¡åˆ†ç³»ç»Ÿï¼š
- ä¸€å¼ æ¸…æ™°æ­£è„¸è®°2åˆ†
- ä¸€å¼ æ¸…æ™°è½¦ç‰Œè®°2åˆ†
- å¯è¯†åˆ«æ–‡å­—10ä¸ªå­—æ®µè®°2åˆ†
- æ€»åˆ†>5åˆ†è®¤ä¸ºç¬¦åˆè¦æ±‚

æ”¹è¿›ç‚¹ï¼š
1. ä¿®å¤äº†ä»£ç æ ¼å¼å’Œå¯¼å…¥é—®é¢˜
2. ä¼˜åŒ–äº†é”™è¯¯å¤„ç†
3. æ”¹è¿›äº†æ¨¡å‹åˆå§‹åŒ–æµç¨‹
4. å¢å¼ºäº†æ—¥å¿—è®°å½•
5. ä¼˜åŒ–äº†å†…å­˜ç®¡ç†
6. ç¡®ä¿å›¾ç‰‡å¤„ç†è¿‡ç¨‹ä¸­ä¸å‹ç¼© - ä¿æŒåŸå§‹è´¨é‡

å›¾ç‰‡è´¨é‡ä¿æŠ¤æªæ–½ï¼š
- ä½¿ç”¨cv2.IMREAD_COLORç¡®ä¿é«˜è´¨é‡è¯»å–
- ä½¿ç”¨shutil.copy2ä¿æŒæ–‡ä»¶å®Œæ•´æ€§
- é¿å…ä¸å¿…è¦çš„å›¾åƒé‡å†™æ“ä½œ
- ç›´æ¥ä¼ é€’æ–‡ä»¶è·¯å¾„ç»™æ£€æµ‹æ¨¡å‹
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
import gc
from collections import defaultdict

# é…ç½®ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨å¯¼å…¥æ·±åº¦å­¦ä¹ åº“ä¹‹å‰è®¾ç½®
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # å¯ç”¨GPU 0å’Œ1
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'     # å‡å°‘TensorFlowæ—¥å¿—è¾“å‡º

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('face_plate_classifier.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–åº“"""
    missing_deps = []
    imported_modules = {}
    
    # æ£€æŸ¥RetinaFace
    try:
        from retinaface import RetinaFace
        imported_modules['RetinaFace'] = RetinaFace
        logger.info("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    # æ£€æŸ¥YOLO
    try:
        from ultralytics import YOLO
        imported_modules['YOLO'] = YOLO
        logger.info("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    # æ£€æŸ¥EasyOCR
    try:
        import easyocr
        imported_modules['easyocr'] = easyocr
        logger.info("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    # æ£€æŸ¥torchï¼ˆç”¨äºGPUæ£€æŸ¥ï¼‰
    try:
        import torch
        imported_modules['torch'] = torch
        logger.info("âœ… PyTorch åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ PyTorch åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("torch")
    
    if missing_deps:
        logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        logger.error("è¯·å®‰è£…ç¼ºå°‘çš„åº“:")
        for dep in missing_deps:
            logger.error(f"  pip install {dep}")
        return None
    
    return imported_modules

# æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–
modules = check_dependencies()
if modules is None:
    exit(1)

# ä»æ£€æŸ¥ç»“æœä¸­è·å–æ¨¡å—
RetinaFace = modules['RetinaFace']
YOLO = modules['YOLO']
easyocr = modules['easyocr']
torch = modules['torch']

# === å‚æ•°é…ç½® ===
class Config:
    """é…ç½®ç±»"""
    
    # ç›®å½•é…ç½®
    INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames68'
    OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames68'
    PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'
    
    # æ–°è®¡åˆ†ç³»ç»Ÿé˜ˆå€¼
    SCORE_THRESHOLD = 5                # æ€»åˆ†é˜ˆå€¼ï¼ˆ>5åˆ†ç¬¦åˆè¦æ±‚ï¼‰
    CLEAR_FACE_SCORE = 2              # æ¸…æ™°æ­£è„¸å¾—åˆ†
    CLEAR_PLATE_SCORE = 2             # æ¸…æ™°è½¦ç‰Œå¾—åˆ†
    TEXT_RECOGNITION_SCORE = 2        # æ–‡å­—è¯†åˆ«å¾—åˆ†ï¼ˆæœ‰æ–‡å­—å³å¾—åˆ†ï¼‰
    # TEXT_FIELDS_THRESHOLD = 10        # æ–‡å­—å­—æ®µæ•°é‡é˜ˆå€¼ï¼ˆå·²åˆ é™¤é™åˆ¶ï¼‰
    
    # æ£€æµ‹é˜ˆå€¼ - ä¼˜åŒ–åçš„å‚æ•°
    YAW_ANGLE_THRESHOLD = 35.0        # yawè§’åº¦é˜ˆå€¼
    MIN_FACE_CONFIDENCE = 0.8         # æœ€å°äººè„¸ç½®ä¿¡åº¦
    MIN_PLATE_CONFIDENCE = 0.5        # æœ€å°è½¦ç‰Œç½®ä¿¡åº¦
    MIN_FACE_SIZE = 60                # æœ€å°äººè„¸å°ºå¯¸
    MIN_PLATE_SIZE = 50               # æœ€å°è½¦ç‰Œå°ºå¯¸
    MIN_FACE_CLARITY_SCORE = 30.0     # æœ€å°æ¸…æ™°åº¦åˆ†æ•°
    MAX_FACE_DISTANCE_RATIO = 0.3     # æœ€å¤§è·ç¦»æ¯”ä¾‹
    FACE_AREA_THRESHOLD = 3600        # äººè„¸é¢ç§¯é˜ˆå€¼
    MIN_TEXT_CONFIDENCE = 0.5         # æœ€å°æ–‡å­—ç½®ä¿¡åº¦
    MIN_TEXT_LENGTH = 3               # æœ€å°æ–‡å­—é•¿åº¦
    
    # å›¾åƒå¤„ç†å‚æ•°
    MAX_IMAGE_SIZE = (1280, 720)
    SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
    
    # å›¾åƒè´¨é‡ä¿æŠ¤è®¾ç½®
    PRESERVE_IMAGE_QUALITY = True      # ç¡®ä¿ä¸å‹ç¼©å›¾ç‰‡
    IMAGE_READ_FLAGS = cv2.IMREAD_COLOR  # ä½¿ç”¨é«˜è´¨é‡è¯»å–æ ‡å¿—
    JPEG_QUALITY = 100                 # JPEGä¿å­˜è´¨é‡ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ï¼‰
    PNG_COMPRESSION = 0                # PNGå‹ç¼©çº§åˆ«ï¼ˆ0=æ— å‹ç¼©ï¼‰
    
    # æ€§èƒ½å‚æ•°
    VERBOSE_LOGGING = True
    GC_FREQUENCY = 100                # åƒåœ¾å›æ”¶é¢‘ç‡
    PROGRESS_UPDATE_FREQUENCY = 50    # è¿›åº¦æ›´æ–°é¢‘ç‡
    
    # å®‰å…¨æ€§æ”¹è¿›
    MAX_PROCESSING_TIME_PER_IMAGE = 30  # æ¯å¼ å›¾ç‰‡æœ€å¤§å¤„ç†æ—¶é—´(ç§’)
    ENABLE_ERROR_RECOVERY = True        # å¯ç”¨é”™è¯¯æ¢å¤
    BACKUP_ORIGINAL_ON_ERROR = True     # é”™è¯¯æ—¶å¤‡ä»½åŸæ–‡ä»¶
    
    # é€Ÿåº¦ä¼˜åŒ–è®¾ç½® (ä¸å½±å“å›¾ç‰‡è´¨é‡)
    ENABLE_SMART_SKIP = True            # å¯ç”¨æ™ºèƒ½è·³è¿‡
    SKIP_PROCESSED_FILES = True         # è·³è¿‡å·²å¤„ç†æ–‡ä»¶
    ENABLE_FAST_PREPROCESSING = True    # å¯ç”¨å¿«é€Ÿé¢„å¤„ç†
    BATCH_DETECTION_SIZE = 4            # æ‰¹é‡æ£€æµ‹å¤§å°
    ENABLE_RESULT_CACHE = True          # å¯ç”¨ç»“æœç¼“å­˜
    CACHE_SIZE_LIMIT = 1000             # ç¼“å­˜å¤§å°é™åˆ¶
    MIN_FILE_SIZE = 1024                # æœ€å°æ–‡ä»¶å¤§å°(å­—èŠ‚)
    EARLY_STOP_ON_SCORE = True          # è¾¾åˆ°é«˜åˆ†æ—¶æå‰åœæ­¢æ£€æµ‹
    
    # GPUé…ç½®ï¼ˆå¯ç”¨GPUåŠ é€Ÿï¼‰
    USE_GPU = True
    GPU_DEVICE_ID = 0                 # ä½¿ç”¨GPU 1ï¼ˆGPU 0æ­£åœ¨è¢«å ç”¨ï¼‰
    ENABLE_TORCH_OPTIMIZATION = True
    
    @classmethod
    def get_output_dirs(cls):
        """è·å–è¾“å‡ºç›®å½•é…ç½®"""
        return {
            'qualified': os.path.join(cls.OUTPUT_BASE_DIR, "qualified"),
            'qualified_1_4_faces': os.path.join(cls.OUTPUT_BASE_DIR, "qualified", "1-4å¼ äººè„¸"),
            'qualified_5_8_faces': os.path.join(cls.OUTPUT_BASE_DIR, "qualified", "5-8å¼ äººè„¸"),
            'qualified_9_plus_faces': os.path.join(cls.OUTPUT_BASE_DIR, "qualified", "9å¼ äººè„¸ä»¥ä¸Š"),
            'insufficient_score': os.path.join(cls.OUTPUT_BASE_DIR, "insufficient_score"),
            'no_content': os.path.join(cls.OUTPUT_BASE_DIR, "no_content"),
            'analysis': os.path.join(cls.OUTPUT_BASE_DIR, "analysis"),
            'backup': os.path.join(cls.OUTPUT_BASE_DIR, "backup")  # æ–°å¢ï¼šå¤‡ä»½ç›®å½•
        }

class FacePlateClassifier:
    """æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ - æ”¹è¿›ç‰ˆæœ¬"""
    
    def __init__(self, config: Optional[Config] = None):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        self.config = config or Config()
        self.start_time = time.time()
        
        # éªŒè¯å›¾åƒè´¨é‡ä¿æŠ¤è®¾ç½®
        self._verify_image_quality_settings()
        
        # é€Ÿåº¦ä¼˜åŒ–ï¼šç»“æœç¼“å­˜
        self.result_cache = {} if self.config.ENABLE_RESULT_CACHE else None
        self.processed_hashes = set()  # å·²å¤„ç†æ–‡ä»¶çš„å“ˆå¸Œå€¼
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'qualified': 0,           # ç¬¦åˆæ¡ä»¶(æ€»åˆ†>5)
            'qualified_1_4_faces': 0, # ç¬¦åˆæ¡ä»¶ä¸”1-4å¼ äººè„¸
            'qualified_5_8_faces': 0, # ç¬¦åˆæ¡ä»¶ä¸”5-8å¼ äººè„¸
            'qualified_9_plus_faces': 0, # ç¬¦åˆæ¡ä»¶ä¸”9å¼ äººè„¸ä»¥ä¸Š
            'insufficient_score': 0,  # åˆ†æ•°ä¸å¤Ÿ
            'no_content': 0,          # æ— ä»»ä½•æœ‰æ•ˆå†…å®¹
            'failed': 0,              # å¤„ç†å¤±è´¥
            'skipped_duplicate': 0,   # è·³è¿‡é‡å¤æ–‡ä»¶
            'skipped_small': 0,       # è·³è¿‡è¿‡å°æ–‡ä»¶
            'skipped_processed': 0,   # è·³è¿‡å·²å¤„ç†æ–‡ä»¶
            'cache_hits': 0           # ç¼“å­˜å‘½ä¸­æ¬¡æ•°
        }
        
        # è¯¦ç»†åˆ†æç»“æœ
        self.analysis_results = []
        
        # è·å–è¾“å‡ºç›®å½•
        self.output_dirs = self.config.get_output_dirs()
        
        # è®¾å¤‡é…ç½®
        self.device = self._setup_device()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_output_dirs()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        # åˆå§‹åŒ–OCR
        self._initialize_ocr()
        
        # åŠ è½½å·²å¤„ç†æ–‡ä»¶ä¿¡æ¯
        self._load_processed_files()
        
        logger.info("ğŸš€ æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰")
        logger.info("ğŸ“¸ å›¾åƒè´¨é‡ä¿æŠ¤ï¼šå·²å¯ç”¨ï¼Œç¡®ä¿å¤„ç†è¿‡ç¨‹ä¸­ä¸å‹ç¼©å›¾ç‰‡")
        logger.info(f"âš¡ é€Ÿåº¦ä¼˜åŒ–ï¼šå·²å¯ç”¨ï¼ŒåŒ…æ‹¬æ™ºèƒ½è·³è¿‡å’Œç»“æœç¼“å­˜")
    
    def _verify_image_quality_settings(self):
        """éªŒè¯å›¾åƒè´¨é‡ä¿æŠ¤è®¾ç½®"""
        if self.config.PRESERVE_IMAGE_QUALITY:
            logger.info("âœ… å›¾åƒè´¨é‡ä¿æŠ¤å·²å¯ç”¨")
            logger.info(f"ğŸ“‹ å›¾åƒè¯»å–æ ‡å¿—: cv2.IMREAD_COLOR")
            logger.info(f"ğŸ“‹ JPEGè´¨é‡è®¾ç½®: {self.config.JPEG_QUALITY}%")
            logger.info(f"ğŸ“‹ PNGå‹ç¼©çº§åˆ«: {self.config.PNG_COMPRESSION} (0=æ— å‹ç¼©)")
        else:
            logger.warning("âš ï¸  å›¾åƒè´¨é‡ä¿æŠ¤æœªå¯ç”¨")
    
    def _load_processed_files(self):
        """åŠ è½½å·²å¤„ç†æ–‡ä»¶ä¿¡æ¯"""
        try:
            if not self.config.SKIP_PROCESSED_FILES:
                return
            
            # ä»å„ä¸ªè¾“å‡ºç›®å½•æ”¶é›†å·²å¤„ç†çš„æ–‡ä»¶
            for category_name, category_dir in self.output_dirs.items():
                if category_name == 'analysis' or not os.path.exists(category_dir):
                    continue
                
                for filename in os.listdir(category_dir):
                    if filename.lower().endswith(tuple(self.config.SUPPORTED_FORMATS)):
                        # ç§»é™¤å¯èƒ½çš„é‡å‘½ååç¼€
                        original_name = filename
                        if '_' in filename:
                            parts = filename.split('_')
                            if len(parts) > 1 and parts[-1].split('.')[0].isdigit():
                                original_name = '_'.join(parts[:-1]) + '.' + parts[-1].split('.')[1]
                        
                        self.processed_hashes.add(original_name)
            
            if self.processed_hashes:
                logger.info(f"ğŸ“‹ å·²åŠ è½½ {len(self.processed_hashes)} ä¸ªå·²å¤„ç†æ–‡ä»¶çš„è®°å½•")
                
        except Exception as e:
            logger.warning(f"âš ï¸  åŠ è½½å·²å¤„ç†æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶çš„å¿«é€Ÿå“ˆå¸Œå€¼ï¼ˆç”¨äºé‡å¤æ£€æµ‹ï¼‰"""
        try:
            import hashlib
            
            # åªè¯»å–æ–‡ä»¶çš„å‰1KBå’Œæœ€å1KBæ¥å¿«é€Ÿè®¡ç®—å“ˆå¸Œ
            # è¿™æ ·æ—¢å¿«é€Ÿåˆèƒ½æœ‰æ•ˆæ£€æµ‹é‡å¤
            hash_md5 = hashlib.md5()
            file_size = os.path.getsize(file_path)
            
            with open(file_path, 'rb') as f:
                # è¯»å–å‰1KB
                chunk = f.read(1024)
                hash_md5.update(chunk)
                
                # å¦‚æœæ–‡ä»¶å¤§äº2KBï¼Œè¯»å–æœ€å1KB
                if file_size > 2048:
                    f.seek(-1024, 2)  # ä»æ–‡ä»¶æœ«å°¾å‘å‰1KB
                    chunk = f.read(1024)
                    hash_md5.update(chunk)
                
                # æ·»åŠ æ–‡ä»¶å¤§å°åˆ°å“ˆå¸Œä¸­
                hash_md5.update(str(file_size).encode())
            
            return hash_md5.hexdigest()[:16]  # åªå–å‰16ä½ï¼Œè¶³å¤Ÿç”¨äºé‡å¤æ£€æµ‹
            
        except Exception as e:
            logger.debug(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    def _should_skip_file(self, image_path: str) -> Tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶å¤„ç†"""
        try:
            filename = os.path.basename(image_path)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if self.config.MIN_FILE_SIZE > 0:
                file_size = os.path.getsize(image_path)
                if file_size < self.config.MIN_FILE_SIZE:
                    return True, f"æ–‡ä»¶è¿‡å°: {file_size} < {self.config.MIN_FILE_SIZE} bytes"
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if self.config.SKIP_PROCESSED_FILES and filename in self.processed_hashes:
                return True, "æ–‡ä»¶å·²å¤„ç†"
            
            # æ£€æŸ¥é‡å¤æ–‡ä»¶ï¼ˆé€šè¿‡å¿«é€Ÿå“ˆå¸Œï¼‰
            if self.config.ENABLE_SMART_SKIP:
                file_hash = self._calculate_file_hash(image_path)
                if file_hash and file_hash in self.processed_hashes:
                    return True, "é‡å¤æ–‡ä»¶ï¼ˆå“ˆå¸ŒåŒ¹é…ï¼‰"
                
                # è®°å½•è¿™ä¸ªå“ˆå¸Œ
                if file_hash:
                    self.processed_hashes.add(file_hash)
            
            return False, ""
            
        except Exception as e:
            logger.debug(f"æ–‡ä»¶è·³è¿‡æ£€æŸ¥å¤±è´¥ {image_path}: {e}")
            return False, ""
    
    def _setup_device(self) -> str:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        try:
            if self.config.USE_GPU and torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                
                if self.config.GPU_DEVICE_ID < device_count:
                    device = f'cuda:{self.config.GPU_DEVICE_ID}'
                    gpu_name = torch.cuda.get_device_name(self.config.GPU_DEVICE_ID)
                    gpu_memory = torch.cuda.get_device_properties(self.config.GPU_DEVICE_ID).total_memory / 1024**3
                    logger.info(f"ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨: {gpu_name} (è®¾å¤‡ {self.config.GPU_DEVICE_ID})")
                    logger.info(f"ğŸ”¥ GPUæ˜¾å­˜: {gpu_memory:.1f} GB")
                    
                    # æ¸…ç†GPUç¼“å­˜
                    torch.cuda.empty_cache()
                    
                    # è®¾ç½®PyTorchä¼˜åŒ–
                    if self.config.ENABLE_TORCH_OPTIMIZATION:
                        torch.backends.cudnn.benchmark = True
                        torch.backends.cudnn.deterministic = False
                        logger.info("âš¡ PyTorchä¼˜åŒ–å·²å¯ç”¨")
                    
                    return device
                else:
                    logger.warning(f"âš ï¸  æŒ‡å®šçš„GPUè®¾å¤‡ID {self.config.GPU_DEVICE_ID} è¶…å‡ºèŒƒå›´ï¼Œå…±æœ‰ {device_count} ä¸ªGPU")
                    return 'cpu'
            else:
                if not torch.cuda.is_available():
                    logger.info("ğŸ’» æœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                else:
                    logger.info("ğŸ’» GPUåŠ é€Ÿå·²ç¦ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                return 'cpu'
                
        except Exception as e:
            logger.error(f"âŒ è®¾å¤‡è®¾ç½®å¤±è´¥: {e}")
            return 'cpu'
    
    def _create_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        for name, dir_path in self.output_dirs.items():
            try:
                os.makedirs(dir_path, exist_ok=True)
                logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
                raise
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹"""
        try:
            # é…ç½®TensorFlow GPUä½¿ç”¨
            try:
                import tensorflow as tf
                
                if 'cuda' in self.device:
                    # é…ç½®GPUå†…å­˜å¢é•¿
                    gpus = tf.config.experimental.list_physical_devices('GPU')
                    if gpus:
                        try:
                            for gpu in gpus:
                                tf.config.experimental.set_memory_growth(gpu, True)
                            logger.info("ğŸš€ TensorFlowå·²é…ç½®ä¸ºGPUæ¨¡å¼ï¼ˆå†…å­˜å¢é•¿ï¼‰")
                        except RuntimeError as e:
                            logger.warning(f"âš ï¸  GPUå†…å­˜å¢é•¿é…ç½®å¤±è´¥: {e}")
                else:
                    tf.config.set_visible_devices([], 'GPU')
                    logger.info("ğŸ”§ TensorFlowå·²é…ç½®ä¸ºCPUæ¨¡å¼")
            except ImportError:
                logger.info("â„¹ï¸  æœªæ£€æµ‹åˆ°TensorFlow")
            
            # åˆå§‹åŒ–RetinaFace
            if 'cuda' in self.device:
                logger.info("ğŸ” åˆå§‹åŒ–RetinaFaceæ¨¡å‹ï¼ˆGPUæ¨¡å¼ï¼‰...")
            else:
                logger.info("ğŸ” åˆå§‹åŒ–RetinaFaceæ¨¡å‹ï¼ˆCPUæ¨¡å¼ï¼‰...")
            self._test_retinaface()
            
            # åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹
            logger.info("ğŸš— åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
            self._initialize_plate_model()
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _test_retinaface(self):
        """æµ‹è¯•RetinaFaceæ¨¡å‹"""
        try:
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            test_img = np.ones((100, 100, 3), dtype=np.uint8) * 128
            
            # å°è¯•æ£€æµ‹
            result = RetinaFace.detect_faces(test_img)
            logger.info("âœ… RetinaFaceæ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆCPUæ¨¡å¼ï¼‰")
            
        except Exception as e:
            logger.error(f"âŒ RetinaFaceåˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°è¯•é‡æ–°åˆå§‹åŒ–RetinaFace...")
            
            # æ¸…ç†çŠ¶æ€
            try:
                # å°è¯•æ¸…ç†TensorFlowä¼šè¯ï¼Œä½†å¿½ç•¥ä»»ä½•é”™è¯¯
                pass
            except:
                pass
            
            # é‡æ–°å°è¯•
            test_img = np.ones((100, 100, 3), dtype=np.uint8) * 128
            RetinaFace.detect_faces(test_img)
            logger.info("âœ… RetinaFaceæ¨¡å‹é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
    
    def _initialize_plate_model(self):
        """åˆå§‹åŒ–è½¦ç‰Œæ£€æµ‹æ¨¡å‹"""
        if not os.path.exists(self.config.PLATE_MODEL_PATH):
            raise FileNotFoundError(f"è½¦ç‰Œæ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.config.PLATE_MODEL_PATH}")
        
        # åˆå§‹åŒ–YOLOæ¨¡å‹ï¼ˆä½¿ç”¨é…ç½®çš„è®¾å¤‡ï¼‰
        self.plate_model = YOLO(self.config.PLATE_MODEL_PATH)
        
        if 'cuda' in self.device:
            logger.info(f"âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆGPUæ¨¡å¼ - {self.device}ï¼‰")
        else:
            logger.info("âœ… è½¦ç‰Œæ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆCPUæ¨¡å¼ï¼‰")
    
    def _initialize_ocr(self):
        """åˆå§‹åŒ–OCRæ¨¡å‹"""
        try:
            logger.info("ğŸ“ åˆå§‹åŒ–EasyOCRæ¨¡å‹...")
            
            # è®¾ç½®EasyOCRï¼ˆæ ¹æ®è®¾å¤‡é…ç½®ï¼‰
            gpu_enabled = 'cuda' in self.device
            self.ocr_reader = easyocr.Reader(
                ['ch_sim', 'en'],  # æ”¯æŒä¸­æ–‡ç®€ä½“å’Œè‹±æ–‡
                gpu=gpu_enabled    # æ ¹æ®è®¾å¤‡é…ç½®å¯ç”¨/ç¦ç”¨GPU
            )
            
            if gpu_enabled:
                logger.info(f"âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (GPUæ¨¡å¼ - {self.device})")
            else:
                logger.info("âœ… EasyOCRæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (CPUæ¨¡å¼)")
                
        except Exception as e:
            logger.error(f"âŒ OCRæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ocr_reader = None
    
    def calculate_face_clarity(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        """è®¡ç®—äººè„¸åŒºåŸŸçš„æ¸…æ™°åº¦"""
        try:
            x1, y1, x2, y2 = bbox
            h, w = image.shape[:2]
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w, int(x2)), min(h, int(y2))
            
            if x2 <= x1 or y2 <= y1:
                return 0.0
            
            face_region = image[y1:y2, x1:x2]
            if face_region.size == 0:
                return 0.0
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(face_region.shape) == 3:
                gray_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
            else:
                gray_face = face_region
            
            # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è®¡ç®—æ¸…æ™°åº¦
            laplacian_var = cv2.Laplacian(gray_face, cv2.CV_64F).var()
            
            # é¢å¤–çš„æ¸…æ™°åº¦æŒ‡æ ‡ï¼šæ¢¯åº¦å¹…å€¼
            grad_x = cv2.Sobel(gray_face, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray_face, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            gradient_mean = np.mean(gradient_magnitude)
            
            # ç»¼åˆæ¸…æ™°åº¦åˆ†æ•°
            clarity_score = laplacian_var + gradient_mean * 0.1
            
            return float(clarity_score)
            
        except Exception as e:
            logger.debug(f"æ¸…æ™°åº¦è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0
            
            horizontal_offset = nose[0] - eye_center[0]
            normalized_offset = horizontal_offset / eye_width
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0
    
    def is_face_clear_and_close(self, image: np.ndarray, bbox: Tuple[int, int, int, int], img_size: Tuple[int, int]) -> Tuple[bool, Dict]:
        """åˆ¤æ–­äººè„¸æ˜¯å¦æ¸…æ™°ä¸”è·ç¦»åˆé€‚"""
        try:
            clarity_score = self.calculate_face_clarity(image, bbox)
            
            x1, y1, x2, y2 = bbox
            face_area = (x2 - x1) * (y2 - y1)
            img_width, img_height = img_size
            img_area = img_width * img_height
            distance_score = face_area / img_area
            
            is_clear = clarity_score >= self.config.MIN_FACE_CLARITY_SCORE
            is_close = distance_score >= self.config.MAX_FACE_DISTANCE_RATIO
            is_large_enough = face_area >= self.config.FACE_AREA_THRESHOLD
            
            is_good_quality = is_clear and (is_close or is_large_enough)
            
            quality_info = {
                'clarity_score': clarity_score,
                'distance_score': distance_score,
                'face_area': face_area,
                'is_clear': is_clear,
                'is_close': is_close,
                'is_large_enough': is_large_enough,
                'is_good_quality': is_good_quality
            }
            
            return is_good_quality, quality_info
            
        except Exception as e:
            logger.debug(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return False, {'error': str(e)}
    
    def detect_faces(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨RetinaFaceæ£€æµ‹æ¸…æ™°æ­£è„¸ï¼Œç¡®ä¿ä¸å‹ç¼©åŸå›¾"""
        try:
            # ç›´æ¥ä¼ é€’å›¾ç‰‡è·¯å¾„ç»™RetinaFaceï¼Œé¿å…é‡å¤è¯»å–å’Œæ½œåœ¨çš„å‹ç¼©
            detections = RetinaFace.detect_faces(image_path)
            
            if not isinstance(detections, dict) or len(detections) == 0:
                return 0, []
            
            # åªåœ¨éœ€è¦æ—¶è¯»å–åŸå›¾è¿›è¡Œè´¨é‡è¯„ä¼°
            img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # æ˜ç¡®æŒ‡å®šè¯»å–å½©è‰²å›¾åƒ
            if img is None:
                return 0, []
            
            img_height, img_width = img.shape[:2]
            img_size = (img_width, img_height)
            
            clear_frontal_faces = []
            
            for face_key, face_data in detections.items():
                try:
                    confidence = face_data.get('score', 0.0)
                    if confidence < self.config.MIN_FACE_CONFIDENCE:
                        continue
                    
                    facial_area = face_data['facial_area']
                    landmarks = face_data.get('landmarks', {})
                    
                    if not landmarks:
                        continue
                    
                    x1, y1, x2, y2 = facial_area
                    face_width = x2 - x1
                    face_height = y2 - y1
                    
                    if min(face_width, face_height) < self.config.MIN_FACE_SIZE:
                        continue
                    
                    # æ£€æŸ¥äººè„¸æ¸…æ™°åº¦å’Œè·ç¦»
                    is_good_quality, quality_info = self.is_face_clear_and_close(img, facial_area, img_size)
                    
                    if not is_good_quality:
                        continue
                    
                    # è®¡ç®—yawè§’åº¦
                    yaw_angle = self.calculate_yaw_angle(landmarks)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ­£è„¸
                    is_frontal = yaw_angle <= self.config.YAW_ANGLE_THRESHOLD
                    
                    if is_frontal:  # åªè®°å½•æ¸…æ™°çš„æ­£è„¸
                        face_info = {
                            'confidence': confidence,
                            'yaw_angle': yaw_angle,
                            'is_frontal': is_frontal,
                            'facial_area': facial_area,
                            'face_size': (face_width, face_height),
                            'quality_info': quality_info
                        }
                        
                        clear_frontal_faces.append(face_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æäººè„¸å¤±è´¥: {e}")
                    continue
            
            return len(clear_frontal_faces), clear_frontal_faces
            
        except Exception as e:
            logger.debug(f"äººè„¸æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_license_plates(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨YOLOæ£€æµ‹æ¸…æ™°è½¦ç‰Œ"""
        try:
            # ä½¿ç”¨é…ç½®çš„è®¾å¤‡è¿›è¡Œæ¨ç†
            results = self.plate_model(image_path, verbose=False, device=self.device)
            
            if not results or len(results) == 0:
                return 0, []
            
            result = results[0]
            
            if result.boxes is None or len(result.boxes) == 0:
                return 0, []
            
            clear_plates = []
            
            for box in result.boxes:
                try:
                    confidence = float(box.conf[0])
                    if confidence < self.config.MIN_PLATE_CONFIDENCE:
                        continue
                    
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    plate_width = x2 - x1
                    plate_height = y2 - y1
                    
                    if min(plate_width, plate_height) < self.config.MIN_PLATE_SIZE:
                        continue
                    
                    plate_info = {
                        'confidence': confidence,
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'plate_size': (float(plate_width), float(plate_height))
                    }
                    
                    clear_plates.append(plate_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†æè½¦ç‰Œå¤±è´¥: {e}")
                    continue
            
            return len(clear_plates), clear_plates
            
        except Exception as e:
            logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def detect_text(self, image_path: str) -> Tuple[int, List[Dict]]:
        """ä½¿ç”¨OCRæ£€æµ‹å¯è¯†åˆ«çš„æ–‡å­—ï¼Œç¡®ä¿ä¸å‹ç¼©åŸå›¾"""
        try:
            if self.ocr_reader is None:
                return 0, []
            
            # ç›´æ¥è¯»å–åŸå›¾ï¼Œä½¿ç”¨æœ€é«˜è´¨é‡è®¾ç½®
            img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # æ˜ç¡®æŒ‡å®šè¯»å–å½©è‰²å›¾åƒ
            if img is None:
                return 0, []
            
            results = self.ocr_reader.readtext(img)
            
            if not results:
                return 0, []
            
            valid_texts = []
            
            for bbox, text, confidence in results:
                try:
                    # ç¡®ä¿confidenceæ˜¯floatç±»å‹
                    confidence = float(confidence) if confidence is not None else 0.0
                    
                    if confidence < self.config.MIN_TEXT_CONFIDENCE:
                        continue
                    
                    cleaned_text = text.strip()
                    if len(cleaned_text) < self.config.MIN_TEXT_LENGTH:
                        continue
                    
                    # è¿‡æ»¤æ‰åªåŒ…å«ç¬¦å·çš„æ–‡å­—
                    if cleaned_text.replace(' ', '').replace('.', '').replace('-', '').replace('_', ''):
                        text_info = {
                            'text': cleaned_text,
                            'confidence': confidence,
                            'bbox': bbox
                        }
                        valid_texts.append(text_info)
                
                except Exception as e:
                    logger.debug(f"åˆ†ææ–‡å­—å¤±è´¥: {e}")
                    continue
            
            return len(valid_texts), valid_texts
            
        except Exception as e:
            logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            return 0, []
    
    def get_face_count_category(self, face_count: int) -> str:
        """æ ¹æ®äººè„¸æ•°é‡ç¡®å®šåˆ†ç±»"""
        if 1 <= face_count <= 4:
            return 'qualified_1_4_faces'
        elif 5 <= face_count <= 8:
            return 'qualified_5_8_faces'
        elif face_count >= 9:
            return 'qualified_9_plus_faces'
        else:
            return 'qualified'  # é»˜è®¤åˆ†ç±»ï¼ˆ0å¼ äººè„¸ä½†å…¶ä»–æ¡ä»¶æ»¡è¶³ï¼‰
    
    def classify_image(self, image_path: str) -> Tuple[str, Dict]:
        """ä½¿ç”¨æ–°è®¡åˆ†ç³»ç»Ÿåˆ†ç±»å›¾åƒï¼ŒåŒ…å«é€Ÿåº¦ä¼˜åŒ–"""
        start_time = time.time()
        
        try:
            filename = os.path.basename(image_path)
            
            # é€Ÿåº¦ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
            should_skip, skip_reason = self._should_skip_file(image_path)
            if should_skip:
                if "æ–‡ä»¶å·²å¤„ç†" in skip_reason:
                    self.stats['skipped_processed'] += 1
                elif "æ–‡ä»¶è¿‡å°" in skip_reason:
                    self.stats['skipped_small'] += 1
                elif "é‡å¤æ–‡ä»¶" in skip_reason:
                    self.stats['skipped_duplicate'] += 1
                
                return 'skipped', {
                    'filename': filename, 
                    'skip_reason': skip_reason,
                    'processing_time': time.time() - start_time
                }
            
            # æ£€æŸ¥ç¼“å­˜
            if self.result_cache:
                cache_key = self._get_cache_key(image_path)
                if cache_key in self.result_cache:
                    self.stats['cache_hits'] += 1
                    cached_result = self.result_cache[cache_key].copy()
                    cached_result['from_cache'] = True
                    cached_result['processing_time'] = time.time() - start_time
                    return cached_result['category'], cached_result
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å’Œæœ‰æ•ˆ
            if not os.path.exists(image_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return 'failed', {'filename': filename, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}
            
            file_size = os.path.getsize(image_path)
            if file_size == 0:
                logger.error(f"âŒ æ–‡ä»¶ä¸ºç©º: {image_path}")
                return 'failed', {'filename': filename, 'error': 'æ–‡ä»¶ä¸ºç©º'}
            
            # æ™ºèƒ½æ£€æµ‹é¡ºåºï¼šå…ˆæ£€æµ‹å®¹æ˜“å¾—åˆ†çš„é¡¹ç›®
            score = 0
            score_details = []
            frontal_count = 0
            plate_count = 0 
            text_count = 0
            face_details = []
            plate_details = []
            text_details = []
            
            # 1. é¦–å…ˆæ£€æµ‹è½¦ç‰Œï¼ˆé€šå¸¸æ›´å¿«ä¸”å®¹æ˜“æ£€æµ‹ï¼‰
            plate_count, plate_details = self.detect_license_plates(image_path)
            if plate_count > 0:
                plate_score = plate_count * self.config.CLEAR_PLATE_SCORE
                score += plate_score
                score_details.append(f"æ¸…æ™°è½¦ç‰Œ {plate_count} å¼  Ã— {self.config.CLEAR_PLATE_SCORE} = {plate_score} åˆ†")
            
            # æ£€æŸ¥å¤„ç†æ—¶é—´
            if time.time() - start_time > self.config.MAX_PROCESSING_TIME_PER_IMAGE:
                logger.warning(f"âš ï¸  å›¾åƒå¤„ç†è¶…æ—¶: {image_path}")
                return 'failed', {'filename': filename, 'error': 'å¤„ç†è¶…æ—¶'}
            
            # 2. æ£€æµ‹æ–‡å­—ï¼ˆOCRç›¸å¯¹è¾ƒå¿«ï¼‰
            text_count, text_details = self.detect_text(image_path)
            if text_count > 0:
                text_score = self.config.TEXT_RECOGNITION_SCORE
                score += text_score
                score_details.append(f"å¯è¯†åˆ«æ–‡å­— {text_count} ä¸ªå­—æ®µ = {text_score} åˆ†")
            
            # æ—©æœŸåœæ­¢ï¼šå¦‚æœå·²ç»è¾¾åˆ°é«˜åˆ†ï¼Œå¯ä»¥è·³è¿‡äººè„¸æ£€æµ‹
            if self.config.EARLY_STOP_ON_SCORE and score > self.config.SCORE_THRESHOLD + 2:
                logger.debug(f"æ—©æœŸåœæ­¢ï¼šåˆ†æ•°å·²è¶³å¤Ÿé«˜ ({score})")
            else:
                # 3. æœ€åæ£€æµ‹äººè„¸ï¼ˆé€šå¸¸æœ€è€—æ—¶ï¼‰
                if time.time() - start_time < self.config.MAX_PROCESSING_TIME_PER_IMAGE:
                    frontal_count, face_details = self.detect_faces(image_path)
                    if frontal_count > 0:
                        face_score = frontal_count * self.config.CLEAR_FACE_SCORE
                        score += face_score
                        score_details.append(f"æ¸…æ™°æ­£è„¸ {frontal_count} å¼  Ã— {self.config.CLEAR_FACE_SCORE} = {face_score} åˆ†")
            
            # åˆ¤æ–­æ˜¯å¦ç¬¦åˆè¦æ±‚
            meets_requirements = score > self.config.SCORE_THRESHOLD
            processing_time = time.time() - start_time
            
            # åˆ›å»ºåˆ†æç»“æœ
            analysis = {
                'filename': filename,
                'frontal_faces': frontal_count,
                'license_plates': plate_count,
                'text_count': text_count,
                'total_score': score,
                'score_details': score_details,
                'meets_requirements': meets_requirements,
                'score_threshold': self.config.SCORE_THRESHOLD,
                'face_details': face_details,
                'plate_details': plate_details,
                'text_details': text_details,
                'processing_time': processing_time,
                'file_size': file_size,
                'timestamp': time.time()
            }
            
            # åˆ†ç±»é€»è¾‘
            if meets_requirements:
                face_category = self.get_face_count_category(frontal_count)
                category = face_category
                analysis['qualification_reason'] = f'æ€»åˆ† {score} åˆ† > {self.config.SCORE_THRESHOLD} åˆ†ï¼Œç¬¦åˆè¦æ±‚'
                analysis['face_count_category'] = face_category
                
                if frontal_count == 0:
                    analysis['face_count_description'] = 'æ— äººè„¸ä½†å…¶ä»–æ¡ä»¶æ»¡è¶³'
                elif 1 <= frontal_count <= 4:
                    analysis['face_count_description'] = f'{frontal_count}å¼ äººè„¸ (1-4å¼ )'
                elif 5 <= frontal_count <= 8:
                    analysis['face_count_description'] = f'{frontal_count}å¼ äººè„¸ (5-8å¼ )'
                else:
                    analysis['face_count_description'] = f'{frontal_count}å¼ äººè„¸ (9å¼ ä»¥ä¸Š)'
            else:
                if score == 0:
                    category = 'no_content'
                    analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ†ï¼Œæ— ä»»ä½•æœ‰æ•ˆå†…å®¹'
                else:
                    category = 'insufficient_score'
                    analysis['reject_reason'] = f'æ€»åˆ† {score} åˆ† â‰¤ {self.config.SCORE_THRESHOLD} åˆ†ï¼Œä¸ç¬¦åˆè¦æ±‚'
            
            analysis['category'] = category
            
            # ç¼“å­˜ç»“æœ
            if self.result_cache and len(self.result_cache) < self.config.CACHE_SIZE_LIMIT:
                cache_key = self._get_cache_key(image_path)
                self.result_cache[cache_key] = analysis.copy()
            
            return category, analysis
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ å›¾åƒåˆ†ç±»å¤±è´¥ {image_path}: {e}")
            return 'failed', {
                'filename': os.path.basename(image_path), 
                'error': str(e),
                'processing_time': processing_time
            }
    
    def _get_cache_key(self, image_path: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        try:
            stat = os.stat(image_path)
            return f"{os.path.basename(image_path)}_{stat.st_size}_{int(stat.st_mtime)}"
        except:
            return os.path.basename(image_path)
    
    def move_image_to_category(self, image_path: str, category: str) -> bool:
        """ç§»åŠ¨å›¾åƒåˆ°å¯¹åº”åˆ†ç±»ç›®å½•ï¼Œç¡®ä¿ä¸å‹ç¼©å›¾ç‰‡ï¼ŒåŒ…å«é”™è¯¯æ¢å¤æœºåˆ¶"""
        backup_path = None  # åˆå§‹åŒ–å¤‡ä»½è·¯å¾„
        
        try:
            filename = os.path.basename(image_path)
            
            if category not in self.output_dirs:
                logger.error(f"âŒ æœªçŸ¥åˆ†ç±»: {category}")
                return False
            
            output_dir = self.output_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            # å®‰å…¨ç§»åŠ¨ï¼šå…ˆå¤‡ä»½ï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œå†å¤åˆ¶ï¼Œæœ€ååˆ é™¤åŸæ–‡ä»¶
            if self.config.BACKUP_ORIGINAL_ON_ERROR:
                backup_dir = self.output_dirs.get('backup')
                if backup_dir and os.path.exists(backup_dir):
                    backup_path = os.path.join(backup_dir, f"backup_{int(time.time())}_{filename}")
                    shutil.copy2(image_path, backup_path)
            
            # ä½¿ç”¨shutil.copy2ä¿æŒåŸå§‹æ–‡ä»¶è´¨é‡å’Œå…ƒæ•°æ®
            shutil.copy2(image_path, output_path)
            
            # éªŒè¯å¤åˆ¶æ˜¯å¦æˆåŠŸ
            if not os.path.exists(output_path):
                logger.error(f"âŒ æ–‡ä»¶å¤åˆ¶å¤±è´¥: {output_path}")
                return False
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            original_size = os.path.getsize(image_path)
            copied_size = os.path.getsize(output_path)
            if original_size != copied_size:
                logger.warning(f"âš ï¸  æ–‡ä»¶å¤§å°ä¸åŒ¹é…: åŸå§‹={original_size}, å¤åˆ¶={copied_size}")
            
            # åˆ é™¤åŸæ–‡ä»¶
            os.remove(image_path)
            
            # å¦‚æœæœ‰å¤‡ä»½ä¸”æ“ä½œæˆåŠŸï¼Œåˆ é™¤å¤‡ä»½
            if backup_path and os.path.exists(backup_path):
                try:
                    os.remove(backup_path)
                except:
                    pass  # å¤‡ä»½åˆ é™¤å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å›¾åƒå¤±è´¥ {image_path}: {e}")
            
            # é”™è¯¯æ¢å¤ï¼šå¦‚æœæœ‰å¤‡ä»½ï¼Œå°è¯•æ¢å¤
            if self.config.ENABLE_ERROR_RECOVERY and backup_path and os.path.exists(backup_path):
                try:
                    if not os.path.exists(image_path):
                        shutil.move(backup_path, image_path)
                        logger.info(f"âœ… å·²ä»å¤‡ä»½æ¢å¤æ–‡ä»¶: {image_path}")
                except Exception as recovery_error:
                    logger.error(f"âŒ é”™è¯¯æ¢å¤å¤±è´¥: {recovery_error}")
            
            return False
    
    def get_image_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        files = []
        input_path = Path(self.config.INPUT_DIR)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.config.INPUT_DIR}")
            return []
        
        logger.info(f"ğŸ” æ‰«æç›®å½•: {self.config.INPUT_DIR}")
        
        for ext in self.config.SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            files.extend(input_path.glob(pattern))
        
        image_files = sorted([str(f) for f in files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            analysis_dir = self.output_dirs['analysis']
            
            # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
            analysis_file = os.path.join(analysis_dir, "classification_analysis.json")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
            summary = {
                'total_processed': len(self.analysis_results),
                'statistics': self.stats.copy(),
                'processing_time': time.time() - self.start_time,
                'scoring_system': {
                    'clear_face_score': self.config.CLEAR_FACE_SCORE,
                    'clear_plate_score': self.config.CLEAR_PLATE_SCORE,
                    'text_recognition_score': self.config.TEXT_RECOGNITION_SCORE,
                    'score_threshold': self.config.SCORE_THRESHOLD
                },
                'configuration': {
                    'yaw_angle_threshold': self.config.YAW_ANGLE_THRESHOLD,
                    'min_face_confidence': self.config.MIN_FACE_CONFIDENCE,
                    'min_plate_confidence': self.config.MIN_PLATE_CONFIDENCE,
                    'min_text_confidence': self.config.MIN_TEXT_CONFIDENCE
                },
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(analysis_dir, "classification_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        # ä¿®æ­£æ€»æ•°è®¡ç®—ï¼šä¸é‡å¤è®¡ç®—qualifiedçš„å­åˆ†ç±»ï¼Œå¹¶åŒ…å«è·³è¿‡çš„æ–‡ä»¶
        total_processed = (self.stats['qualified'] + self.stats['insufficient_score'] + 
                          self.stats['no_content'] + self.stats['failed'] +
                          self.stats['skipped_duplicate'] + self.stats['skipped_small'] + 
                          self.stats['skipped_processed'])
        
        logger.info("="*80)
        logger.info("ğŸ‰ æ­£è„¸å’Œè½¦ç‰Œåˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        logger.info("æ–°çš„è®¡åˆ†ç³»ç»Ÿ:")
        logger.info(f"  - ä¸€å¼ æ¸…æ™°æ­£è„¸ = {self.config.CLEAR_FACE_SCORE} åˆ†")
        logger.info(f"  - ä¸€å¼ æ¸…æ™°è½¦ç‰Œ = {self.config.CLEAR_PLATE_SCORE} åˆ†")  
        logger.info(f"  - å¯è¯†åˆ«æ–‡å­— = {self.config.TEXT_RECOGNITION_SCORE} åˆ†")
        logger.info(f"  - æ€»åˆ† > {self.config.SCORE_THRESHOLD} åˆ† = ç¬¦åˆè¦æ±‚")
        logger.info(f"âœ… ç¬¦åˆæ¡ä»¶æ€»è®¡(>{self.config.SCORE_THRESHOLD}åˆ†): {self.stats['qualified']:,}")
        logger.info(f"  ğŸ“¸ 1-4å¼ äººè„¸: {self.stats['qualified_1_4_faces']:,}")
        logger.info(f"  ğŸ‘¥ 5-8å¼ äººè„¸: {self.stats['qualified_5_8_faces']:,}")
        logger.info(f"  ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ 9å¼ äººè„¸ä»¥ä¸Š: {self.stats['qualified_9_plus_faces']:,}")
        logger.info(f"âŒ åˆ†æ•°ä¸å¤Ÿ(â‰¤{self.config.SCORE_THRESHOLD}åˆ†): {self.stats['insufficient_score']:,}")
        logger.info(f"âŒ æ— ä»»ä½•å†…å®¹: {self.stats['no_content']:,}")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,}")
        
        # é€Ÿåº¦ä¼˜åŒ–ç»Ÿè®¡
        logger.info(f"âš¡ é€Ÿåº¦ä¼˜åŒ–ç»Ÿè®¡:")
        logger.info(f"  ï¿½ è·³è¿‡é‡å¤æ–‡ä»¶: {self.stats['skipped_duplicate']:,}")
        logger.info(f"  ğŸ“ è·³è¿‡è¿‡å°æ–‡ä»¶: {self.stats['skipped_small']:,}")
        logger.info(f"  âœ… è·³è¿‡å·²å¤„ç†æ–‡ä»¶: {self.stats['skipped_processed']:,}")
        logger.info(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {self.stats['cache_hits']:,}")
        
        total_skipped = (self.stats['skipped_duplicate'] + self.stats['skipped_small'] + 
                        self.stats['skipped_processed'])
        if total_skipped > 0:
            logger.info(f"  ï¿½ğŸ“Š æ€»è·³è¿‡æ–‡ä»¶: {total_skipped:,}")
            logger.info(f"  âš¡ è·³è¿‡ç‡: {(total_skipped/total_processed)*100:.1f}%")
        
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,}")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            # è®¡ç®—å®é™…å¤„ç†çš„æ–‡ä»¶æ•°ï¼ˆæ’é™¤è·³è¿‡çš„ï¼‰
            actually_processed = total_processed - total_skipped
            if actually_processed > 0:
                avg_speed = actually_processed / processing_time
                logger.info(f"ğŸš€ å®é™…å¤„ç†é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            # åŒ…å«è·³è¿‡æ–‡ä»¶çš„æ€»ä½“é€Ÿåº¦
            total_speed = total_processed / processing_time
            logger.info(f"ğŸš€ æ€»ä½“å¤„ç†é€Ÿåº¦: {total_speed:.1f} å¼ /ç§’")
            
            success_rate = (self.stats['qualified'] / actually_processed) * 100 if actually_processed > 0 else 0
            logger.info(f"ğŸ“ˆ ç¬¦åˆæ¡ä»¶æ¯”ä¾‹: {success_rate:.1f}%")
        
        # æ˜¾ç¤ºå„ç›®å½•æ–‡ä»¶æ•°é‡
        logger.info("\nğŸ“‚ å„åˆ†ç±»ç›®å½•ç»Ÿè®¡:")
        categories = [
            ("ç¬¦åˆæ¡ä»¶-1-4å¼ äººè„¸", self.output_dirs['qualified_1_4_faces']),
            ("ç¬¦åˆæ¡ä»¶-5-8å¼ äººè„¸", self.output_dirs['qualified_5_8_faces']),
            ("ç¬¦åˆæ¡ä»¶-9å¼ äººè„¸ä»¥ä¸Š", self.output_dirs['qualified_9_plus_faces']),
            ("åˆ†æ•°ä¸å¤Ÿ", self.output_dirs['insufficient_score']),
            ("æ— ä»»ä½•å†…å®¹", self.output_dirs['no_content'])
        ]
        
        for name, dir_path in categories:
            if os.path.exists(dir_path):
                count = len([f for f in os.listdir(dir_path) 
                           if f.lower().endswith(tuple(self.config.SUPPORTED_FORMATS))])
                logger.info(f"  ğŸ“ {name}: {count} å¼ å›¾ç‰‡")
        
        logger.info("="*80)
    
    def run(self):
        """è¿è¡Œåˆ†ç±»å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ­£è„¸å’Œè½¦ç‰Œæ£€æµ‹åˆ†ç±»å™¨ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {self.config.INPUT_DIR}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.config.OUTPUT_BASE_DIR}")
        logger.info(f"ğŸ’» è®¡ç®—è®¾å¤‡: {self.device}")
        logger.info(f"ğŸ“Š è®¡åˆ†è§„åˆ™:")
        logger.info(f"  - æ¸…æ™°æ­£è„¸: {self.config.CLEAR_FACE_SCORE} åˆ†/å¼ ")
        logger.info(f"  - æ¸…æ™°è½¦ç‰Œ: {self.config.CLEAR_PLATE_SCORE} åˆ†/å¼ ")
        logger.info(f"  - å¯è¯†åˆ«æ–‡å­—: {self.config.TEXT_RECOGNITION_SCORE} åˆ†(æœ‰æ–‡å­—å³å¾—åˆ†)")
        logger.info(f"  - é€šè¿‡é˜ˆå€¼: > {self.config.SCORE_THRESHOLD} åˆ†")
        logger.info(f"ğŸ“ yawè§’åº¦é˜ˆå€¼: {self.config.YAW_ANGLE_THRESHOLD}Â°")
        logger.info(f"ğŸ¯ äººè„¸ç½®ä¿¡åº¦é˜ˆå€¼: {self.config.MIN_FACE_CONFIDENCE}")
        logger.info(f"ğŸ¯ è½¦ç‰Œç½®ä¿¡åº¦é˜ˆå€¼: {self.config.MIN_PLATE_CONFIDENCE}")
        logger.info(f"ğŸ¯ æ–‡å­—è¯†åˆ«ç½®ä¿¡åº¦é˜ˆå€¼: {self.config.MIN_TEXT_CONFIDENCE}")
        logger.info(f"ğŸ” æœ€å°æ¸…æ™°åº¦åˆ†æ•°: {self.config.MIN_FACE_CLARITY_SCORE}")
        logger.info(f"ğŸ“ æœ€å°äººè„¸é¢ç§¯: {self.config.FACE_AREA_THRESHOLD}pxÂ²")
        logger.info(f"â±ï¸  å•å›¾ç‰‡æœ€å¤§å¤„ç†æ—¶é—´: {self.config.MAX_PROCESSING_TIME_PER_IMAGE}ç§’")
        logger.info(f"ğŸ›¡ï¸  é”™è¯¯æ¢å¤: {'å¯ç”¨' if self.config.ENABLE_ERROR_RECOVERY else 'ç¦ç”¨'}")
        logger.info(f"ğŸ’¾ åŸæ–‡ä»¶å¤‡ä»½: {'å¯ç”¨' if self.config.BACKUP_ORIGINAL_ON_ERROR else 'ç¦ç”¨'}")
        
        # è·å–å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files()
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return
        
        total_files = len(image_files)
        logger.info(f"ğŸ“Š æ‰¾åˆ° {total_files} å¼ å›¾ç‰‡å¾…å¤„ç†")
        
        # å¼€å§‹å¤„ç†
        try:
            start_time = time.time()
            failed_files = []
            timeout_files = []
            
            # æ”¹è¿›çš„è¿›åº¦æ˜¾ç¤º
            for i, image_path in enumerate(image_files):
                current_time = time.time()
                
                try:
                    # åˆ†ç±»å›¾åƒ
                    category, analysis = self.classify_image(image_path)
                    
                    # å¤„ç†è·³è¿‡çš„æ–‡ä»¶
                    if category == 'skipped':
                        # è·³è¿‡çš„æ–‡ä»¶ä¸éœ€è¦ç§»åŠ¨ï¼Œç»Ÿè®¡å·²åœ¨classify_imageä¸­æ›´æ–°
                        pass
                    elif category != 'failed':
                        # ç§»åŠ¨åˆ°å¯¹åº”ç›®å½•
                        if self.move_image_to_category(image_path, category):
                            self.stats[category] += 1
                            # å¦‚æœæ˜¯ç¬¦åˆæ¡ä»¶çš„åˆ†ç±»ï¼ŒåŒæ—¶æ›´æ–°æ€»çš„qualifiedç»Ÿè®¡
                            if category.startswith('qualified_'):
                                self.stats['qualified'] += 1
                        else:
                            self.stats['failed'] += 1
                            analysis['move_failed'] = True
                            failed_files.append(image_path)
                    else:
                        self.stats['failed'] += 1
                        failed_files.append(image_path)
                    
                    # è®°å½•è¶…æ—¶æ–‡ä»¶
                    if analysis.get('error') == 'å¤„ç†è¶…æ—¶':
                        timeout_files.append(image_path)
                    
                    # ä¿å­˜åˆ†æç»“æœï¼ˆè·³è¿‡çš„æ–‡ä»¶ä¹Ÿè®°å½•ï¼‰
                    self.analysis_results.append(analysis)
                    
                    # æ™ºèƒ½è¿›åº¦æ˜¾ç¤º
                    if (i + 1) % self.config.PROGRESS_UPDATE_FREQUENCY == 0 or i == total_files - 1:
                        progress = (i + 1) / total_files * 100
                        elapsed = current_time - start_time
                        
                        if i > 0:
                            avg_time = elapsed / (i + 1)
                            remaining_files = total_files - (i + 1)
                            eta = remaining_files * avg_time
                            
                            # æ ¼å¼åŒ–ETA
                            if eta > 3600:
                                eta_str = f"{eta/3600:.1f}å°æ—¶"
                            elif eta > 60:
                                eta_str = f"{eta/60:.1f}åˆ†é’Ÿ"
                            else:
                                eta_str = f"{eta:.0f}ç§’"
                            
                            print(f"\rğŸ“Š è¿›åº¦: {i+1}/{total_files} ({progress:.1f}%) "
                                  f"| å·²ç”¨æ—¶: {elapsed/60:.1f}åˆ†é’Ÿ "
                                  f"| é¢„è®¡å‰©ä½™: {eta_str} "
                                  f"| é€Ÿåº¦: {(i+1)/elapsed:.1f}å¼ /ç§’", end='', flush=True)
                        else:
                            print(f"\rğŸ“Š è¿›åº¦: {i+1}/{total_files} ({progress:.1f}%)", end='', flush=True)
                    
                    # å®šæœŸå†…å­˜æ¸…ç†
                    if (i + 1) % self.config.GC_FREQUENCY == 0:
                        gc.collect()
                        # å¦‚æœä½¿ç”¨GPUï¼Œæ¸…ç†GPUå†…å­˜
                        if 'cuda' in self.device:
                            torch.cuda.empty_cache()
                
                except KeyboardInterrupt:
                    logger.info("\nâš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
                    break
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
                    self.stats['failed'] += 1
                    failed_files.append(image_path)
            
            # å®Œæˆåæ¢è¡Œ
            print()
            
            # æ˜¾ç¤ºå¤„ç†æ‘˜è¦
            total_time = time.time() - start_time
            if failed_files:
                logger.warning(f"âš ï¸  å¤±è´¥æ–‡ä»¶æ•°: {len(failed_files)}")
                if len(failed_files) <= 10:
                    for failed_file in failed_files:
                        logger.warning(f"  - {os.path.basename(failed_file)}")
                else:
                    logger.warning(f"  æ˜¾ç¤ºå‰10ä¸ª: {[os.path.basename(f) for f in failed_files[:10]]}")
            
            if timeout_files:
                logger.warning(f"â±ï¸  è¶…æ—¶æ–‡ä»¶æ•°: {len(timeout_files)}")
        
        finally:
            # ä¿å­˜ç»“æœå’Œç»Ÿè®¡
            self.save_analysis_results()
            self.print_final_statistics()

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºé…ç½®
        config = Config()
        
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(config.INPUT_DIR):
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {config.INPUT_DIR}")
            return
        
        # æ£€æŸ¥è½¦ç‰Œæ£€æµ‹æ¨¡å‹
        if not os.path.exists(config.PLATE_MODEL_PATH):
            logger.error(f"âŒ è½¦ç‰Œæ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {config.PLATE_MODEL_PATH}")
            return
        
        # åˆ›å»ºåˆ†ç±»å™¨å¹¶è¿è¡Œ
        classifier = FacePlateClassifier(config)
        classifier.run()
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
