#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨ - ä¼˜åŒ–ç‰ˆæœ¬
å¢åŠ äº†ä»¥ä¸‹ä¼˜åŒ–ç­–ç•¥ï¼š
1. æ‰¹é‡å¤„ç† - ä¸€æ¬¡å¤„ç†å¤šå¼ å›¾ç‰‡
2. å•è¿›ç¨‹æ¨¡å¼ - é¿å…CUDAå¤šè¿›ç¨‹åˆå§‹åŒ–å†²çª
3. GPUæ‰¹é‡æ¨ç† - å‡å°‘GPUä¸Šä¸‹æ–‡åˆ‡æ¢
4. é¢„è¿‡æ»¤æœºåˆ¶ - å¿«é€Ÿè·³è¿‡æ˜æ˜¾ä¸ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡
5. å†…å­˜æ± ç®¡ç† - å‡å°‘å†…å­˜åˆ†é…å¼€é”€
6. æ™ºèƒ½åˆ†ç»„ - æŒ‰å›¾ç‰‡å¤§å°/ç±»å‹åˆ†ç»„å¤„ç†

ä¿®å¤è¯´æ˜ï¼š
- ä½¿ç”¨spawnå¯åŠ¨æ–¹æ³•é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜
- æ”¹ç”¨å•è¿›ç¨‹æ‰¹å¤„ç†æ¨¡å¼æé«˜ç¨³å®šæ€§
- å¢å¼ºGPUåˆå§‹åŒ–é”™è¯¯å¤„ç†å’Œå›é€€æœºåˆ¶
"""

import os
import cv2
import numpy as np
import json
import time
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import gc
from collections import defaultdict
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import threading
from queue import Queue
import hashlib
import sys

# è®¾ç½®ç¯å¢ƒå˜é‡ - å¿…é¡»åœ¨å¯¼å…¥æ·±åº¦å­¦ä¹ åº“ä¹‹å‰
os.environ['CUDA_VISIBLE_DEVICES'] = '0'     # åªä½¿ç”¨GPU 0
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'     # å‡å°‘TensorFlowæ—¥å¿—è¾“å‡º

# ä¿®å¤CUDAå¤šè¿›ç¨‹é—®é¢˜ - è®¾ç½®spawnå¯åŠ¨æ–¹æ³•
if __name__ == "__main__":
    mp.set_start_method('spawn', force=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('advanced_face_plate_detector_optimized.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class ProgressBar:
    """ç®€å•çš„è¿›åº¦æ¡æ˜¾ç¤ºå™¨"""
    
    def __init__(self, total: int, prefix: str = "Progress", length: int = 50):
        self.total = total
        self.prefix = prefix
        self.length = length
        self.current = 0
        self.start_time = time.time()
        self.last_update = 0
    
    def update(self, current: Optional[int] = None):
        """æ›´æ–°è¿›åº¦æ¡"""
        if current is not None:
            self.current = current
        else:
            self.current += 1
        
        # é¿å…è¿‡äºé¢‘ç¹çš„æ›´æ–°
        now = time.time()
        if now - self.last_update < 0.1 and self.current < self.total:  # æ¯100msæ›´æ–°ä¸€æ¬¡
            return
        
        self.last_update = now
        
        # è®¡ç®—è¿›åº¦
        progress = self.current / self.total if self.total > 0 else 0
        percent = progress * 100
        
        # è®¡ç®—æ—¶é—´ä¿¡æ¯
        elapsed = now - self.start_time
        if self.current > 0 and elapsed > 0:
            speed = self.current / elapsed
            if speed > 0:
                eta = (self.total - self.current) / speed
                eta_str = self._format_time(eta)
            else:
                eta_str = "N/A"
        else:
            speed = 0
            eta_str = "N/A"
        
        # ç»˜åˆ¶è¿›åº¦æ¡
        filled_length = int(self.length * progress)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (self.length - filled_length)
        
        # æ ¼å¼åŒ–è¾“å‡º
        elapsed_str = self._format_time(elapsed)
        speed_str = f"{speed:.1f}/s" if speed > 0 else "0/s"
        
        # è¾“å‡ºè¿›åº¦æ¡
        print(f'\r{self.prefix}: |{bar}| {self.current}/{self.total} '
              f'({percent:.1f}%) ç”¨æ—¶:{elapsed_str} é€Ÿåº¦:{speed_str} å‰©ä½™:{eta_str}', 
              end='', flush=True)
        
        # å®Œæˆæ—¶æ¢è¡Œ
        if self.current >= self.total:
            print()
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.0f}s"
        elif seconds < 3600:
            minutes = seconds // 60
            secs = seconds % 60
            return f"{minutes:.0f}m{secs:.0f}s"
        else:
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            return f"{hours:.0f}h{minutes:.0f}m"
    
    def finish(self):
        """å®Œæˆè¿›åº¦æ¡"""
        self.update(self.total)

class ProgressTracker:
    """å¤šé˜¶æ®µè¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.stages = {}
        self.current_stage = None
        self.overall_start = time.time()
    
    def add_stage(self, name: str, total: int, prefix: Optional[str] = None):
        """æ·»åŠ ä¸€ä¸ªå¤„ç†é˜¶æ®µ"""
        if prefix is None:
            prefix = name
        self.stages[name] = {
            'progress_bar': ProgressBar(total, prefix),
            'total': total,
            'completed': False
        }
    
    def start_stage(self, name: str):
        """å¼€å§‹ä¸€ä¸ªé˜¶æ®µ"""
        if name in self.stages:
            self.current_stage = name
            print(f"\nğŸ”„ å¼€å§‹é˜¶æ®µ: {name}")
        else:
            print(f"âš ï¸  æœªçŸ¥é˜¶æ®µ: {name}")
    
    def update_stage(self, name: Optional[str] = None, current: Optional[int] = None):
        """æ›´æ–°å½“å‰é˜¶æ®µè¿›åº¦"""
        stage_name = name or self.current_stage
        if stage_name and stage_name in self.stages:
            self.stages[stage_name]['progress_bar'].update(current)
    
    def finish_stage(self, name: Optional[str] = None):
        """å®Œæˆä¸€ä¸ªé˜¶æ®µ"""
        stage_name = name or self.current_stage
        if stage_name and stage_name in self.stages:
            self.stages[stage_name]['progress_bar'].finish()
            self.stages[stage_name]['completed'] = True
            elapsed = time.time() - self.overall_start
            print(f"âœ… é˜¶æ®µ '{stage_name}' å®Œæˆ (æ€»ç”¨æ—¶: {self._format_time(elapsed)})")
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.0f}s"
        elif seconds < 3600:
            minutes = seconds // 60
            secs = seconds % 60
            return f"{minutes:.0f}m{secs:.0f}s"
        else:
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            return f"{hours:.0f}h{minutes:.0f}m"
    
    def print_summary(self):
        """æ‰“å°æ‰€æœ‰é˜¶æ®µçš„æ‘˜è¦"""
        total_time = time.time() - self.overall_start
        print(f"\nğŸ“Š å¤„ç†æ‘˜è¦ (æ€»æ—¶é—´: {self._format_time(total_time)}):")
        for name, stage in self.stages.items():
            status = "âœ… å®Œæˆ" if stage['completed'] else "âŒ æœªå®Œæˆ"
            print(f"  {name}: {status}")

def check_dependencies():
    """æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–åº“"""
    missing_deps = []
    imported_modules = {}
    
    # æ£€æŸ¥RetinaFace
    try:
        from retinaface import RetinaFace
        imported_modules['RetinaFace'] = RetinaFace
        logger.info("âœ… RetinaFace åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ RetinaFace åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("retina-face")
    
    # æ£€æŸ¥YOLO
    try:
        from ultralytics import YOLO
        imported_modules['YOLO'] = YOLO
        logger.info("âœ… YOLO åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ YOLO åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("ultralytics")
    
    # æ£€æŸ¥EasyOCR
    try:
        import easyocr
        imported_modules['easyocr'] = easyocr
        logger.info("âœ… EasyOCR åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ EasyOCR åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("easyocr")
    
    # æ£€æŸ¥torch
    try:
        import torch
        imported_modules['torch'] = torch
        logger.info("âœ… PyTorch åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        logger.error(f"âŒ PyTorch åº“å¯¼å…¥å¤±è´¥: {e}")
        missing_deps.append("torch")
    
    if missing_deps:
        logger.error(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {', '.join(missing_deps)}")
        logger.error("è¯·å®‰è£…ç¼ºå°‘çš„åº“:")
        for dep in missing_deps:
            logger.error(f"  pip install {dep}")
        return None
    
    return imported_modules

# æ£€æŸ¥å¹¶å¯¼å…¥ä¾èµ–
modules = check_dependencies()
if modules is None:
    exit(1)

# ä»æ£€æŸ¥ç»“æœä¸­è·å–æ¨¡å—
RetinaFace = modules['RetinaFace']
YOLO = modules['YOLO']
easyocr = modules['easyocr']
torch = modules['torch']

class OptimizedConfig:
    """ä¼˜åŒ–é…ç½®ç±»"""
    
    # ç›®å½•é…ç½®
    INPUT_DIR = '/home/zhiqics/sanjian/predata/output_frames87'  # è¾“å…¥ç›®å½•
    OUTPUT_BASE_DIR = '/home/zhiqics/sanjian/predata/output_frames87'  # è¾“å‡ºåŸºç¡€ç›®å½•
    
    # æ¨¡å‹è·¯å¾„
    YOLOV8S_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/yolov8s.pt'
    LICENSE_PLATE_MODEL_PATH = '/home/zhiqics/sanjian/predata/models/license_plate_detector.pt'
    
    # æ£€æµ‹é˜ˆå€¼
    REQUIRED_CLOSE_FRONTAL_FACES = 4      # éœ€è¦çš„è¿‘æ™¯æ­£è„¸æ•°é‡ï¼ˆä¿ç•™ç”¨äºå‘ä¸‹å…¼å®¹ï¼‰
    MIN_FACE_CONFIDENCE_YOLO = 0.5        # YOLOäººè„¸æœ€å°ç½®ä¿¡åº¦
    MIN_FACE_CONFIDENCE_RETINA = 0.8      # RetinaFaceæœ€å°ç½®ä¿¡åº¦
    MIN_PLATE_CONFIDENCE = 0.5            # è½¦ç‰Œæœ€å°ç½®ä¿¡åº¦
    MIN_TEXT_CONFIDENCE = 0.5             # æ–‡å­—æœ€å°ç½®ä¿¡åº¦
    YAW_ANGLE_THRESHOLD = 30.0            # yawè§’åº¦é˜ˆå€¼ï¼ˆæ­£è„¸ï¼‰
    
    # æ–°çš„è¯„åˆ†ç³»ç»Ÿ
    SCORE_PER_CLEAR_FRONTAL_FACE = 2      # æ¯å¼ æ¸…æ™°æ­£è„¸çš„åˆ†æ•°
    SCORE_PER_CLEAR_PLATE = 2             # æ¯å¼ æ¸…æ™°è½¦ç‰Œçš„åˆ†æ•°
    SCORE_PER_TEXT = 1                    # å¯è¯†åˆ«æ–‡å­—çš„åˆ†æ•°
    REQUIRED_TOTAL_SCORE = 5              # éœ€è¦çš„æœ€ä½æ€»åˆ†æ•°
    
    # è¿‘æ™¯åˆ¤æ–­å‚æ•°
    MIN_FACE_SIZE = 80                    # æœ€å°äººè„¸å°ºå¯¸ï¼ˆåƒç´ ï¼‰
    CLOSE_UP_FACE_RATIO = 0.08           # è¿‘æ™¯äººè„¸æœ€å°é¢ç§¯æ¯”ä¾‹
    MIN_FACE_AREA = 6400                 # æœ€å°äººè„¸é¢ç§¯ï¼ˆ80x80ï¼‰
    
    # å›¾åƒè´¨é‡ä¿æŠ¤
    PRESERVE_IMAGE_QUALITY = True
    IMAGE_READ_FLAGS = cv2.IMREAD_COLOR
    JPEG_QUALITY = 100
    PNG_COMPRESSION = 0
    
    # GPUé…ç½®
    USE_GPU = True
    PREFERRED_GPU = 0                     # åªä½¿ç”¨GPU 0
    FALLBACK_GPU = 0                      # å¤‡ç”¨ä¹Ÿæ˜¯GPU 0
    
    # æ–‡ä»¶æ ¼å¼
    SUPPORTED_FORMATS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}
    
    # ä¼˜åŒ–å‚æ•°
    BATCH_SIZE = 32                       # è¿›ä¸€æ­¥å¢å¤§æ‰¹å¤„ç†å¤§å°æé«˜æ•ˆç‡
    MAX_WORKERS = 1                       # ä½¿ç”¨å•è¿›ç¨‹é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜
    THREAD_POOL_SIZE = 2                  # å‡å°‘çº¿ç¨‹æ± å¤§å°
    PREFILTER_ENABLED = False             # æš‚æ—¶ç¦ç”¨é¢„è¿‡æ»¤ä»¥åŠ å¿«é€Ÿåº¦
    SMART_GROUPING = False                # æš‚æ—¶ç¦ç”¨æ™ºèƒ½åˆ†ç»„ä»¥ç®€åŒ–å¤„ç†
    USE_MULTIPROCESSING = False           # ç¦ç”¨å¤šè¿›ç¨‹ï¼Œä½¿ç”¨å•è¿›ç¨‹æ‰¹å¤„ç†
    PREFILTER_SAMPLE_RATE = 0.1           # å¦‚æœå¯ç”¨é¢„è¿‡æ»¤ï¼Œåªå¯¹10%çš„å›¾ç‰‡è¿›è¡Œé¢„è¿‡æ»¤
    
    # åˆ†ç»„å‚æ•°
    SMALL_IMAGE_THRESHOLD = 500 * 500     # å°å›¾ç‰‡é˜ˆå€¼
    MEDIUM_IMAGE_THRESHOLD = 1000 * 1000  # ä¸­ç­‰å›¾ç‰‡é˜ˆå€¼
    LARGE_IMAGE_THRESHOLD = 2000 * 2000   # å¤§å›¾ç‰‡é˜ˆå€¼
    
    # æ€§èƒ½å‚æ•°
    GC_FREQUENCY = 100                    # åƒåœ¾å›æ”¶é¢‘ç‡
    PROGRESS_UPDATE_FREQUENCY = 50        # è¿›åº¦æ›´æ–°é¢‘ç‡
    MAX_PROCESSING_TIME_PER_IMAGE = 60    # å•å¼ å›¾ç‰‡æœ€å¤§å¤„ç†æ—¶é—´
    MEMORY_LIMIT_GB = 8                   # å†…å­˜é™åˆ¶ï¼ˆGBï¼‰
    
    @classmethod
    def get_output_dirs(cls):
        """è·å–è¾“å‡ºç›®å½•é…ç½®"""
        return {
            'high_score': os.path.join(cls.OUTPUT_BASE_DIR, "high_score_images"),  # æ€»åˆ†>5åˆ†çš„å›¾ç‰‡
            'low_score': os.path.join(cls.OUTPUT_BASE_DIR, "low_score_images"),   # 1-5åˆ†çš„å›¾ç‰‡
            'zero_score': os.path.join(cls.OUTPUT_BASE_DIR, "zero_score_images"), # 0åˆ†çš„å›¾ç‰‡
            'analysis': os.path.join(cls.OUTPUT_BASE_DIR, "analysis"),
            # ä¿ç•™åŸåˆ†ç±»ç›®å½•ä»¥å¤‡å…¼å®¹
            'satisfied_4_faces': os.path.join(cls.OUTPUT_BASE_DIR, "satisfied_4_close_frontal_faces"),
            'satisfied_with_plate': os.path.join(cls.OUTPUT_BASE_DIR, "satisfied_with_plate_text"),
            'insufficient_faces': os.path.join(cls.OUTPUT_BASE_DIR, "insufficient_faces"),
            'no_faces': os.path.join(cls.OUTPUT_BASE_DIR, "no_faces"),
        }

class ImageGrouper:
    """å›¾ç‰‡åˆ†ç»„å™¨ - æŒ‰å¤§å°å’Œç‰¹å¾æ™ºèƒ½åˆ†ç»„"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
    
    def get_image_info(self, image_path: str) -> Dict:
        """è·å–å›¾ç‰‡åŸºæœ¬ä¿¡æ¯"""
        try:
            # è·å–æ–‡ä»¶ä¿¡æ¯
            stat = os.stat(image_path)
            file_size = stat.st_size
            
            # å¿«é€Ÿè¯»å–å›¾ç‰‡å°ºå¯¸ï¼ˆä¸åŠ è½½å®Œæ•´å›¾ç‰‡ï¼‰
            with open(image_path, 'rb') as f:
                # å°è¯•å¿«é€Ÿè§£æå›¾ç‰‡å°ºå¯¸
                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                if img is not None:
                    height, width = img.shape
                    pixel_count = width * height
                else:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨PILè·å–å°ºå¯¸
                    from PIL import Image
                    with Image.open(image_path) as pil_img:
                        width, height = pil_img.size
                        pixel_count = width * height
            
            return {
                'path': image_path,
                'file_size': file_size,
                'width': width,
                'height': height,
                'pixel_count': pixel_count,
                'aspect_ratio': width / height if height > 0 else 1.0
            }
        except Exception as e:
            logger.debug(f"è·å–å›¾ç‰‡ä¿¡æ¯å¤±è´¥ {image_path}: {e}")
            return {
                'path': image_path,
                'file_size': 0,
                'width': 0,
                'height': 0,
                'pixel_count': 0,
                'aspect_ratio': 1.0
            }
    
    def group_by_size(self, image_files: List[str]) -> Dict[str, List[str]]:
        """æŒ‰å›¾ç‰‡å¤§å°åˆ†ç»„"""
        groups = {
            'small': [],      # å°å›¾ç‰‡
            'medium': [],     # ä¸­ç­‰å›¾ç‰‡
            'large': [],      # å¤§å›¾ç‰‡
            'extra_large': [] # è¶…å¤§å›¾ç‰‡
        }
        
        logger.info("ğŸ“Š æŒ‰å›¾ç‰‡å¤§å°åˆ†ç»„...")
        
        for image_path in image_files:
            info = self.get_image_info(image_path)
            pixel_count = info['pixel_count']
            
            if pixel_count <= self.config.SMALL_IMAGE_THRESHOLD:
                groups['small'].append(image_path)
            elif pixel_count <= self.config.MEDIUM_IMAGE_THRESHOLD:
                groups['medium'].append(image_path)
            elif pixel_count <= self.config.LARGE_IMAGE_THRESHOLD:
                groups['large'].append(image_path)
            else:
                groups['extra_large'].append(image_path)
        
        # æ˜¾ç¤ºåˆ†ç»„ç»Ÿè®¡
        for group_name, files in groups.items():
            if files:
                logger.info(f"  ğŸ“¸ {group_name}: {len(files)} å¼ å›¾ç‰‡")
        
        return groups
    
    def group_by_batch(self, image_files: List[str], batch_size: int) -> List[List[str]]:
        """æŒ‰æ‰¹æ¬¡åˆ†ç»„"""
        batches = []
        for i in range(0, len(image_files), batch_size):
            batch = image_files[i:i + batch_size]
            batches.append(batch)
        
        logger.info(f"ğŸ“¦ åˆ›å»º {len(batches)} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} å¼ å›¾ç‰‡")
        return batches
    
    def create_balanced_groups(self, image_files: List[str], num_workers: int) -> List[List[str]]:
        """åˆ›å»ºè´Ÿè½½å‡è¡¡çš„åˆ†ç»„"""
        if not image_files:
            return []
        
        # è·å–æ‰€æœ‰å›¾ç‰‡ä¿¡æ¯
        image_infos = [self.get_image_info(path) for path in image_files]
        
        # æŒ‰å¤„ç†å¤æ‚åº¦æ’åºï¼ˆå¤§å›¾ç‰‡å¤„ç†æ—¶é—´æ›´é•¿ï¼‰
        image_infos.sort(key=lambda x: x['pixel_count'], reverse=True)
        
        # åˆ›å»ºå‡è¡¡åˆ†ç»„
        groups = [[] for _ in range(num_workers)]
        group_loads = [0] * num_workers
        
        for info in image_infos:
            # æ‰¾åˆ°è´Ÿè½½æœ€å°çš„ç»„
            min_load_idx = min(range(num_workers), key=lambda i: group_loads[i])
            groups[min_load_idx].append(info['path'])
            group_loads[min_load_idx] += info['pixel_count']
        
        # è¿‡æ»¤ç©ºç»„
        groups = [group for group in groups if group]
        
        logger.info(f"âš–ï¸  åˆ›å»º {len(groups)} ä¸ªå‡è¡¡åˆ†ç»„")
        for i, group in enumerate(groups):
            if group:
                avg_pixels = group_loads[i] / len(group) if group else 0
                logger.info(f"  ğŸ“¸ ç»„ {i+1}: {len(group)} å¼ å›¾ç‰‡ï¼Œå¹³å‡åƒç´ : {avg_pixels:,.0f}")
        
        return groups

class PreFilter:
    """é¢„è¿‡æ»¤å™¨ - å¿«é€Ÿè¿‡æ»¤æ˜æ˜¾ä¸ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
    
    def quick_face_check(self, image_path: str) -> Tuple[bool, str]:
        """å¿«é€Ÿäººè„¸æ£€æŸ¥ - ä½¿ç”¨ç®€å•æ–¹æ³•é¢„åˆ¤æ˜¯å¦å¯èƒ½æœ‰äººè„¸"""
        try:
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¤ªå°çš„æ–‡ä»¶å¯èƒ½æ²¡æœ‰æ¸…æ™°å†…å®¹ï¼‰
            file_size = os.path.getsize(image_path)
            if file_size < 50000:  # å°äº50KB
                return False, "æ–‡ä»¶å¤ªå°"
            
            # å¿«é€Ÿè¯»å–å›¾ç‰‡åŸºæœ¬ä¿¡æ¯
            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                return False, "æ— æ³•è¯»å–å›¾ç‰‡"
            
            # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸
            height, width = img.shape
            if min(height, width) < 300:
                return False, "åˆ†è¾¨ç‡å¤ªä½"
            
            # å¿«é€Ÿè¾¹ç¼˜æ£€æµ‹ï¼ˆæ›¿ä»£Haarçº§è”ï¼‰
            # ç¼©å°å›¾ç‰‡è¿›è¡Œå¿«é€Ÿåˆ†æ
            scale_factor = 0.2  # æ›´å¤§çš„ç¼©æ”¾æ¯”ä¾‹
            small_img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor)
            
            # è®¡ç®—è¾¹ç¼˜å¯†åº¦å’Œå¯¹æ¯”åº¦
            edges = cv2.Canny(small_img, 30, 100)
            edge_density = np.sum(edges > 0) / edges.size
            
            # è®¡ç®—å›¾åƒå¯¹æ¯”åº¦
            contrast = np.std(small_img)
            
            # ç®€å•çš„å¯å‘å¼è§„åˆ™
            if edge_density < 0.05:  # è¾¹ç¼˜å¤ªå°‘
                return False, "è¾¹ç¼˜å¯†åº¦ä¸è¶³"
            
            if contrast < 20:  # å¯¹æ¯”åº¦å¤ªä½
                return False, "å¯¹æ¯”åº¦ä¸è¶³"
            
            # æ£€æŸ¥å›¾åƒæ˜¯å¦è¿‡äºæ¨¡ç³Š
            laplacian_var = cv2.Laplacian(small_img, cv2.CV_64F).var()
            if laplacian_var < 50:
                return False, "å›¾åƒæ¨¡ç³Š"
            
            return True, "é€šè¿‡å¿«é€Ÿæ£€æŸ¥"
        
        except Exception as e:
            logger.debug(f"é¢„è¿‡æ»¤å¤±è´¥ {image_path}: {e}")
            return True, "é¢„è¿‡æ»¤å¼‚å¸¸ï¼Œä¿ç•™"

class BatchProcessor:
    """æ‰¹å¤„ç†å™¨"""
    
    def __init__(self, config: OptimizedConfig):
        self.config = config
        self.device = None
        self.models = {}
        self.ocr_reader = None
        
    def initialize_models(self, device: str):
        """åˆå§‹åŒ–æ¨¡å‹ï¼ˆåœ¨å­è¿›ç¨‹ä¸­è°ƒç”¨ï¼‰"""
        try:
            # å…ˆæ£€æŸ¥CUDAå¯ç”¨æ€§
            if torch.cuda.is_available():
                # è®¾ç½®GPUè®¾å¤‡
                torch.cuda.set_device(0)  # å¼ºåˆ¶ä½¿ç”¨GPU 0
                self.device = 'cuda:0'
                
                # æ¸…ç†GPUç¼“å­˜
                torch.cuda.empty_cache()
                
                # è®¾ç½®GPUå†…å­˜ç®¡ç†
                torch.cuda.set_per_process_memory_fraction(0.7, device=0)  # ä½¿ç”¨70%çš„GPUå†…å­˜
                
                logger.info(f"ğŸ”§ GPUåˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            else:
                self.device = 'cpu'
                logger.warning("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
            
            # åˆå§‹åŒ–YOLOæ¨¡å‹
            logger.info("ğŸ”„ åˆå§‹åŒ–YOLOäººè„¸æ£€æµ‹æ¨¡å‹...")
            self.models['face'] = YOLO(self.config.YOLOV8S_MODEL_PATH)
            self.models['face'].to(self.device)
            
            logger.info("ğŸ”„ åˆå§‹åŒ–YOLOè½¦ç‰Œæ£€æµ‹æ¨¡å‹...")
            self.models['plate'] = YOLO(self.config.LICENSE_PLATE_MODEL_PATH)
            self.models['plate'].to(self.device)
            
            # åˆå§‹åŒ–OCR
            logger.info("ğŸ”„ åˆå§‹åŒ–OCRæ¨¡å‹...")
            gpu_enabled = 'cuda' in self.device
            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=gpu_enabled)
            
            device_info = f"{self.device} ({'GPU' if 'cuda' in self.device else 'CPU'}æ¨¡å¼)"
            logger.info(f"âœ… æ‰¹å¤„ç†å™¨æ¨¡å‹åˆå§‹åŒ–å®Œæˆ ({device_info})")
            return True
            
        except RuntimeError as e:
            if "CUDA" in str(e):
                logger.error(f"âŒ CUDAåˆå§‹åŒ–å¤±è´¥: {e}")
                logger.info("ğŸ”„ å°è¯•ä½¿ç”¨CPUæ¨¡å¼...")
                try:
                    self.device = 'cpu'
                    self.models['face'] = YOLO(self.config.YOLOV8S_MODEL_PATH)
                    self.models['plate'] = YOLO(self.config.LICENSE_PLATE_MODEL_PATH)
                    self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=False)
                    logger.info(f"âœ… æ‰¹å¤„ç†å™¨æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (CPUæ¨¡å¼)")
                    return True
                except Exception as e2:
                    logger.error(f"âŒ CPUæ¨¡å¼åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e2}")
                    return False
            else:
                raise e
        except Exception as e:
            logger.error(f"âŒ æ‰¹å¤„ç†å™¨æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            # å¦‚æœGPUåˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨CPU
            try:
                logger.info("ğŸ”„ å°è¯•ä½¿ç”¨CPUæ¨¡å¼...")
                self.device = 'cpu'
                self.models['face'] = YOLO(self.config.YOLOV8S_MODEL_PATH)
                self.models['plate'] = YOLO(self.config.LICENSE_PLATE_MODEL_PATH)
                self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=False)
                logger.info(f"âœ… æ‰¹å¤„ç†å™¨æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (CPUæ¨¡å¼)")
                return True
            except Exception as e2:
                logger.error(f"âŒ CPUæ¨¡å¼åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e2}")
                return False
    
    def process_batch(self, image_paths: List[str]) -> List[Tuple[str, Dict]]:
        """æ‰¹é‡å¤„ç†å›¾ç‰‡"""
        results = []
        
        try:
            # æ‰¹é‡YOLOæ£€æµ‹
            face_results = self.models['face'](image_paths, verbose=False, device=self.device)
            
            for i, image_path in enumerate(image_paths):
                try:
                    # å¤„ç†å•å¼ å›¾ç‰‡
                    result = self.process_single_image(
                        image_path, 
                        face_results[i] if i < len(face_results) else None
                    )
                    results.append((image_path, result))
                    
                except Exception as e:
                    logger.error(f"æ‰¹å¤„ç†ä¸­å•å¼ å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
                    results.append((image_path, {'error': str(e)}))
            
        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†å¤±è´¥: {e}")
            # å¦‚æœæ‰¹å¤„ç†å¤±è´¥ï¼Œå°è¯•å•ç‹¬å¤„ç†æ¯å¼ å›¾ç‰‡
            for image_path in image_paths:
                try:
                    result = self.process_single_image(image_path, None)
                    results.append((image_path, result))
                except Exception as e2:
                    results.append((image_path, {'error': str(e2)}))
        
        return results
    
    def process_single_image(self, image_path: str, yolo_result=None) -> Dict:
        """å¤„ç†å•å¼ å›¾ç‰‡ - ä½¿ç”¨æ–°çš„è¯„åˆ†ç³»ç»Ÿ"""
        try:
            filename = os.path.basename(image_path)
            start_time = time.time()
            
            # åˆå§‹åŒ–åˆ†æ•°å’Œæ£€æµ‹ç»“æœ
            total_score = 0
            frontal_face_count = 0
            clear_plate_count = 0
            text_count = 0
            
            # è¯¦ç»†æ£€æµ‹ç»“æœ
            detection_details = {
                'yolo_faces': [],
                'retina_faces': [],
                'plates': [],
                'texts': []
            }
            
            # 1. ä½¿ç”¨RetinaFaceæ£€æµ‹æ¸…æ™°æ­£è„¸
            try:
                detections = RetinaFace.detect_faces(image_path)
                
                if isinstance(detections, dict) and len(detections) > 0:
                    # è¯»å–å›¾åƒä¿¡æ¯
                    img = cv2.imread(image_path, cv2.IMREAD_COLOR)
                    if img is not None:
                        img_height, img_width = img.shape[:2]
                        img_area = img_width * img_height
                        
                        for face_key, face_data in detections.items():
                            confidence = face_data.get('score', 0.0)
                            if confidence < self.config.MIN_FACE_CONFIDENCE_RETINA:
                                continue
                            
                            facial_area = face_data['facial_area']
                            landmarks = face_data.get('landmarks', {})
                            
                            if not landmarks:
                                continue
                            
                            x1, y1, x2, y2 = facial_area
                            face_width = x2 - x1
                            face_height = y2 - y1
                            face_area = face_width * face_height
                            
                            # æ£€æŸ¥æœ€å°å°ºå¯¸
                            if min(face_width, face_height) < self.config.MIN_FACE_SIZE:
                                continue
                            
                            if face_area < self.config.MIN_FACE_AREA:
                                continue
                            
                            # è®¡ç®—yawè§’åº¦åˆ¤æ–­æ˜¯å¦ä¸ºæ­£è„¸
                            yaw_angle = self.calculate_yaw_angle(landmarks)
                            is_frontal = yaw_angle <= self.config.YAW_ANGLE_THRESHOLD
                            
                            # åˆ¤æ–­æ˜¯å¦ä¸ºè¿‘æ™¯
                            area_ratio = face_area / img_area
                            is_close_up = area_ratio >= self.config.CLOSE_UP_FACE_RATIO
                            
                            # åªæœ‰æ¸…æ™°çš„è¿‘æ™¯æ­£è„¸æ‰è®¡åˆ†
                            if is_frontal and is_close_up:
                                frontal_face_count += 1
                                total_score += self.config.SCORE_PER_CLEAR_FRONTAL_FACE
                            
                            face_info = {
                                'confidence': confidence,
                                'yaw_angle': yaw_angle,
                                'is_frontal': is_frontal,
                                'area_ratio': area_ratio,
                                'is_close_up': is_close_up,
                                'scored': is_frontal and is_close_up
                            }
                            detection_details['retina_faces'].append(face_info)
                            
            except Exception as e:
                logger.debug(f"RetinaFaceæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            
            # 2. æ£€æµ‹æ¸…æ™°è½¦ç‰Œ
            try:
                plate_results = self.models['plate']([image_path], verbose=False, device=self.device)
                
                if plate_results and len(plate_results) > 0:
                    result = plate_results[0]
                    if result.boxes is not None and len(result.boxes) > 0:
                        for box in result.boxes:
                            confidence = float(box.conf[0])
                            if confidence >= self.config.MIN_PLATE_CONFIDENCE:
                                clear_plate_count += 1
                                total_score += self.config.SCORE_PER_CLEAR_PLATE
                                
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                plate_info = {
                                    'confidence': confidence,
                                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                    'scored': True
                                }
                                detection_details['plates'].append(plate_info)
                                
            except Exception as e:
                logger.debug(f"è½¦ç‰Œæ£€æµ‹å¤±è´¥ {image_path}: {e}")
            
            # 3. æ£€æµ‹å¯è¯†åˆ«æ–‡å­—
            try:
                if self.ocr_reader is not None:
                    img = cv2.imread(image_path, cv2.IMREAD_COLOR)
                    if img is not None:
                        ocr_results = self.ocr_reader.readtext(img)
                        
                        if ocr_results:
                            for bbox, text, confidence in ocr_results:
                                confidence = float(confidence) if confidence is not None else 0.0
                                
                                if confidence >= self.config.MIN_TEXT_CONFIDENCE:
                                    cleaned_text = text.strip()
                                    if len(cleaned_text) >= 2:  # è‡³å°‘2ä¸ªå­—ç¬¦æ‰ç®—æœ‰æ•ˆæ–‡å­—
                                        text_count += 1
                                        total_score += self.config.SCORE_PER_TEXT
                                        
                                        text_info = {
                                            'text': cleaned_text,
                                            'confidence': confidence,
                                            'bbox': bbox,
                                            'scored': True
                                        }
                                        detection_details['texts'].append(text_info)
                                        
            except Exception as e:
                logger.debug(f"æ–‡å­—æ£€æµ‹å¤±è´¥ {image_path}: {e}")
            
            # 4. æ ¹æ®æ€»åˆ†æ•°ç¡®å®šåˆ†ç±»
            if total_score > self.config.REQUIRED_TOTAL_SCORE:
                category = 'high_score'
                result_msg = f'é«˜åˆ†å›¾ç‰‡: æ€»åˆ†{total_score}åˆ† (æ­£è„¸{frontal_face_count}Ã—2 + è½¦ç‰Œ{clear_plate_count}Ã—2 + æ–‡å­—{text_count}Ã—1)'
            elif total_score > 0:
                category = 'low_score'
                result_msg = f'ä½åˆ†å›¾ç‰‡: æ€»åˆ†{total_score}åˆ† (æ­£è„¸{frontal_face_count}Ã—2 + è½¦ç‰Œ{clear_plate_count}Ã—2 + æ–‡å­—{text_count}Ã—1)'
            else:
                category = 'zero_score'
                result_msg = f'é›¶åˆ†å›¾ç‰‡: æœªæ£€æµ‹åˆ°ä»»ä½•æœ‰æ•ˆç‰¹å¾'
            
            processing_time = time.time() - start_time
            
            analysis = {
                'filename': filename,
                'category': category,
                'result': result_msg,
                'scoring': {
                    'total_score': total_score,
                    'frontal_faces': frontal_face_count,
                    'clear_plates': clear_plate_count,
                    'texts': text_count,
                    'score_breakdown': {
                        'face_score': frontal_face_count * self.config.SCORE_PER_CLEAR_FRONTAL_FACE,
                        'plate_score': clear_plate_count * self.config.SCORE_PER_CLEAR_PLATE,
                        'text_score': text_count * self.config.SCORE_PER_TEXT
                    }
                },
                'detection_details': detection_details,
                'processing_time': processing_time,
                'timestamp': time.time()
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"å¤„ç†å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
            return {
                'filename': os.path.basename(image_path),
                'category': 'failed',
                'error': str(e),
                'scoring': {'total_score': 0},
                'processing_time': 0
            }
    
    def calculate_yaw_angle(self, landmarks: Dict) -> float:
        """åŸºäºRetinaFaceå…³é”®ç‚¹è®¡ç®—yawè§’åº¦"""
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            
            eye_center = (left_eye + right_eye) / 2
            eye_vector = right_eye - left_eye
            eye_width = np.linalg.norm(eye_vector)
            
            if eye_width < 10:
                return 90.0
            
            horizontal_offset = nose[0] - eye_center[0]
            normalized_offset = horizontal_offset / eye_width
            yaw_angle = abs(normalized_offset) * 60.0
            
            return yaw_angle
            
        except Exception as e:
            logger.debug(f"yawè§’åº¦è®¡ç®—å¤±è´¥: {e}")
            return 90.0

# æ³¨é‡Šæ‰å¤šè¿›ç¨‹å‡½æ•°ï¼Œç°åœ¨ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼
# def process_image_group(args):
#     """å¤„ç†å›¾ç‰‡åˆ†ç»„çš„å·¥ä½œå‡½æ•°ï¼ˆç”¨äºå¤šè¿›ç¨‹ï¼‰- å·²ç¦ç”¨"""
#     # è¯¥å‡½æ•°å·²è¢«å•è¿›ç¨‹æ‰¹å¤„ç†æ¨¡å¼æ›¿ä»£
#     pass

class OptimizedFacePlateDetector:
    """ä¼˜åŒ–çš„é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨"""
    
    def __init__(self, config: Optional[OptimizedConfig] = None):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        self.config = config or OptimizedConfig()
        self.start_time = time.time()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'high_score': 0,       # æ€»åˆ†>5åˆ†çš„å›¾ç‰‡
            'low_score': 0,        # 1-5åˆ†çš„å›¾ç‰‡
            'zero_score': 0,       # 0åˆ†çš„å›¾ç‰‡
            'failed': 0,           # å¤„ç†å¤±è´¥
            'prefiltered': 0,      # é¢„è¿‡æ»¤è·³è¿‡
            # ä¿ç•™åŸç»Ÿè®¡é¡¹ä»¥å¤‡å…¼å®¹
            'satisfied_4_faces': 0,
            'satisfied_with_plate': 0,
            'insufficient_faces': 0,
            'no_faces': 0,
        }
        
        # è¯¦ç»†åˆ†æç»“æœ
        self.analysis_results = []
        
        # è¿›åº¦è·Ÿè¸ªå™¨
        self.progress_tracker = ProgressTracker()
        
        # è·å–è¾“å‡ºç›®å½•
        self.output_dirs = self.config.get_output_dirs()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_output_dirs()
        
        logger.info("ğŸš€ ä¼˜åŒ–çš„é«˜çº§äººè„¸è½¦ç‰Œæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ï¿½ GPUé…ç½®: åªä½¿ç”¨GPU 0 (é¿å…å¤šGPUå†²çª)")
        logger.info(f"ï¿½ğŸ“Š æ–°è¯„åˆ†ç³»ç»Ÿ: æ¸…æ™°æ­£è„¸{self.config.SCORE_PER_CLEAR_FRONTAL_FACE}åˆ† + "
                   f"æ¸…æ™°è½¦ç‰Œ{self.config.SCORE_PER_CLEAR_PLATE}åˆ† + "
                   f"å¯è¯†åˆ«æ–‡å­—{self.config.SCORE_PER_TEXT}åˆ†")
        logger.info(f"ğŸ¯ åˆ†ç±»æ ‡å‡†: >{self.config.REQUIRED_TOTAL_SCORE}åˆ†(ç¬¦åˆè¦æ±‚) | "
                   f"1-{self.config.REQUIRED_TOTAL_SCORE}åˆ†(éƒ¨åˆ†ç¬¦åˆ) | 0åˆ†(ä¸ç¬¦åˆ)")
        logger.info(f"âš¡ å¯ç”¨ä¼˜åŒ–: æ‰¹å¤„ç†({self.config.BATCH_SIZE}), "
                   f"å•GPUè¿›ç¨‹({self.config.MAX_WORKERS}), "
                   f"é¢„è¿‡æ»¤({self.config.PREFILTER_ENABLED})")
    
    def _create_output_dirs(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        for name, dir_path in self.output_dirs.items():
            try:
                os.makedirs(dir_path, exist_ok=True)
                logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {dir_path}: {e}")
                raise
    
    def get_image_files(self) -> List[str]:
        """è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶"""
        files = []
        input_path = Path(self.config.INPUT_DIR)
        
        if not input_path.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.config.INPUT_DIR}")
            return []
        
        logger.info(f"ğŸ” æ‰«æç›®å½•: {self.config.INPUT_DIR}")
        
        for ext in self.config.SUPPORTED_FORMATS:
            pattern = f"*{ext}"
            files.extend(input_path.glob(pattern))
        
        image_files = sorted([str(f) for f in files if f.is_file()])
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        
        return image_files
    
    def move_image_to_category(self, image_path: str, category: str) -> bool:
        """ç§»åŠ¨å›¾åƒåˆ°å¯¹åº”åˆ†ç±»ç›®å½•"""
        try:
            filename = os.path.basename(image_path)
            
            if category not in self.output_dirs:
                logger.error(f"âŒ æœªçŸ¥åˆ†ç±»: {category}")
                return False
            
            output_dir = self.output_dirs[category]
            output_path = os.path.join(output_dir, filename)
            
            # å¤„ç†æ–‡ä»¶åå†²çª
            counter = 1
            while os.path.exists(output_path):
                name, ext = os.path.splitext(filename)
                new_filename = f"{name}_{counter}{ext}"
                output_path = os.path.join(output_dir, new_filename)
                counter += 1
            
            # ä½¿ç”¨shutil.copy2ä¿æŒåŸå§‹æ–‡ä»¶è´¨é‡å’Œå…ƒæ•°æ®
            shutil.copy2(image_path, output_path)
            
            # éªŒè¯å¤åˆ¶æ˜¯å¦æˆåŠŸ
            if not os.path.exists(output_path):
                logger.error(f"âŒ æ–‡ä»¶å¤åˆ¶å¤±è´¥: {output_path}")
                return False
            
            # åˆ é™¤åŸæ–‡ä»¶
            os.remove(image_path)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨å›¾åƒå¤±è´¥ {image_path}: {e}")
            return False
    
    def save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            analysis_dir = self.output_dirs['analysis']
            
            # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
            analysis_file = os.path.join(analysis_dir, "optimized_classification_analysis.json")
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
            summary = {
                'total_processed': len(self.analysis_results),
                'statistics': self.stats.copy(),
                'processing_time': time.time() - self.start_time,
                'optimization_config': {
                    'batch_size': self.config.BATCH_SIZE,
                    'max_workers': self.config.MAX_WORKERS,
                    'prefilter_enabled': self.config.PREFILTER_ENABLED,
                    'smart_grouping': self.config.SMART_GROUPING,
                },
                'timestamp': time.time()
            }
            
            summary_file = os.path.join(analysis_dir, "optimized_classification_summary.json")
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜åˆ°: {analysis_file}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        processing_time = time.time() - self.start_time
        total_processed = sum(self.stats.values())
        
        logger.info("="*80)
        logger.info("ğŸ‰ åŸºäºè¯„åˆ†ç³»ç»Ÿçš„å›¾ç‰‡åˆ†ç±»å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        logger.info("ğŸ“Š è¯„åˆ†è§„åˆ™: æ¸…æ™°æ­£è„¸2åˆ† + æ¸…æ™°è½¦ç‰Œ2åˆ† + å¯è¯†åˆ«æ–‡å­—1åˆ†")
        logger.info("ğŸ¯ åˆ†ç±»æ ‡å‡†: >5åˆ†(ç¬¦åˆè¦æ±‚) | 1-5åˆ†(éƒ¨åˆ†ç¬¦åˆ) | 0åˆ†(ä¸ç¬¦åˆ)")
        logger.info("")
        logger.info(f"âœ… é«˜åˆ†å›¾ç‰‡(>5åˆ†): {self.stats['high_score']:,} å¼ ")
        logger.info(f"ğŸ“Š ä½åˆ†å›¾ç‰‡(1-5åˆ†): {self.stats['low_score']:,} å¼ ")
        logger.info(f"âŒ é›¶åˆ†å›¾ç‰‡(0åˆ†): {self.stats['zero_score']:,} å¼ ")
        logger.info(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed']:,} å¼ ")
        logger.info(f"ğŸš« é¢„è¿‡æ»¤è·³è¿‡: {self.stats['prefiltered']:,} å¼ ")
        logger.info(f"ğŸ“Š æ€»å¤„ç†æ•°é‡: {total_processed:,} å¼ ")
        logger.info(f"â° æ€»è€—æ—¶: {processing_time:.1f}ç§’")
        
        if total_processed > 0:
            avg_speed = total_processed / processing_time
            logger.info(f"ğŸš€ å¹³å‡é€Ÿåº¦: {avg_speed:.1f} å¼ /ç§’")
            
            # è®¡ç®—ç¬¦åˆè¦æ±‚çš„æ¯”ä¾‹ï¼ˆé«˜åˆ†å›¾ç‰‡ï¼‰
            success_rate = (self.stats['high_score'] / total_processed) * 100
            logger.info(f"ğŸ“ˆ ç¬¦åˆè¦æ±‚æ¯”ä¾‹: {success_rate:.1f}% (>5åˆ†)")
            
            # è®¡ç®—æœ‰ä»·å€¼å›¾ç‰‡æ¯”ä¾‹ï¼ˆé«˜åˆ†+ä½åˆ†ï¼‰
            valuable_rate = ((self.stats['high_score'] + self.stats['low_score']) / total_processed) * 100
            logger.info(f"ï¿½ æœ‰ä»·å€¼å›¾ç‰‡æ¯”ä¾‹: {valuable_rate:.1f}% (â‰¥1åˆ†)")
        
        # æ˜¾ç¤ºå„ç›®å½•æ–‡ä»¶æ•°é‡
        logger.info("\nğŸ“‚ å„åˆ†ç±»ç›®å½•ç»Ÿè®¡:")
        categories = [
            ("é«˜åˆ†å›¾ç‰‡(>5åˆ†)", self.output_dirs['high_score']),
            ("ä½åˆ†å›¾ç‰‡(1-5åˆ†)", self.output_dirs['low_score']),
            ("é›¶åˆ†å›¾ç‰‡(0åˆ†)", self.output_dirs['zero_score'])
        ]
        
        for name, dir_path in categories:
            if os.path.exists(dir_path):
                count = len([f for f in os.listdir(dir_path) 
                           if f.lower().endswith(tuple(self.config.SUPPORTED_FORMATS))])
                logger.info(f"  ğŸ“ {name}: {count} å¼ å›¾ç‰‡")
        
        logger.info("="*80)
    
    def run(self):
        """è¿è¡Œä¼˜åŒ–æ£€æµ‹å™¨"""
        logger.info("ğŸš€ å¯åŠ¨åŸºäºè¯„åˆ†ç³»ç»Ÿçš„å›¾ç‰‡åˆ†ç±»å™¨...")
        logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {self.config.INPUT_DIR}")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.config.OUTPUT_BASE_DIR}")
        logger.info(f"ğŸ’» å¤„ç†æ¨¡å¼: å•è¿›ç¨‹æ‰¹å¤„ç† (é¿å…CUDAå¤šè¿›ç¨‹å†²çª)")
        logger.info(f"ğŸ“Š è¯„åˆ†è§„åˆ™:")
        logger.info(f"  ğŸ‘¤ æ¸…æ™°æ­£è„¸: {self.config.SCORE_PER_CLEAR_FRONTAL_FACE}åˆ†/å¼ ")
        logger.info(f"  ğŸš— æ¸…æ™°è½¦ç‰Œ: {self.config.SCORE_PER_CLEAR_PLATE}åˆ†/å¼ ")
        logger.info(f"  ğŸ“ å¯è¯†åˆ«æ–‡å­—: {self.config.SCORE_PER_TEXT}åˆ†/ä¸ª")
        logger.info(f"ğŸ¯ åˆ†ç±»æ ‡å‡†: >{self.config.REQUIRED_TOTAL_SCORE}åˆ†ä¸ºç¬¦åˆè¦æ±‚")
        logger.info(f"âš¡ ä¼˜åŒ–é…ç½®:")
        logger.info(f"  ğŸ“¦ æ‰¹å¤„ç†å¤§å°: {self.config.BATCH_SIZE}")
        logger.info(f"  ğŸ¯ é¢„è¿‡æ»¤: {'å¯ç”¨' if self.config.PREFILTER_ENABLED else 'ç¦ç”¨'}")
        logger.info(f"  ğŸ§  æ™ºèƒ½åˆ†ç»„: {'å¯ç”¨' if self.config.SMART_GROUPING else 'ç¦ç”¨'}")
        
        # è·å–å›¾åƒæ–‡ä»¶
        logger.info("ğŸ” æ­£åœ¨æ‰«æå›¾åƒæ–‡ä»¶...")
        image_files = self.get_image_files()
        if not image_files:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return
        
        total_files = len(image_files)
        logger.info(f"ğŸ“Š æ‰¾åˆ° {total_files} å¼ å›¾ç‰‡å¾…å¤„ç†")
        
        # è®¾ç½®è¿›åº¦è·Ÿè¸ª
        self.progress_tracker.add_stage("å›¾åƒåˆ†ç»„", total_files, "ğŸ“¦ æ™ºèƒ½åˆ†ç»„")
        self.progress_tracker.add_stage("å›¾åƒå¤„ç†", total_files, "ğŸ”„ å¤„ç†å›¾åƒ")
        self.progress_tracker.add_stage("æ–‡ä»¶ç§»åŠ¨", total_files, "ğŸ“‚ ç§»åŠ¨æ–‡ä»¶")
        
        # åˆ›å»ºåˆ†ç»„ï¼ˆç°åœ¨åªç”¨äºæ‰¹å¤„ç†ï¼Œä¸ç”¨äºå¤šè¿›ç¨‹ï¼‰
        self.progress_tracker.start_stage("å›¾åƒåˆ†ç»„")
        logger.info("ğŸ“Š å‡†å¤‡æ‰¹å¤„ç†åˆ†ç»„...")
        
        # ç®€å•æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼Œå¤§æ–‡ä»¶å…ˆå¤„ç†
        try:
            image_files_with_size = []
            for image_path in image_files:
                try:
                    size = os.path.getsize(image_path)
                    image_files_with_size.append((image_path, size))
                except:
                    image_files_with_size.append((image_path, 0))
            
            # æŒ‰æ–‡ä»¶å¤§å°å€’åºæ’åºï¼ˆå¤§æ–‡ä»¶å…ˆå¤„ç†ï¼‰
            image_files_with_size.sort(key=lambda x: x[1], reverse=True)
            image_files = [item[0] for item in image_files_with_size]
            
            logger.info(f"ğŸ“Š æŒ‰æ–‡ä»¶å¤§å°æ’åºå®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸  æ–‡ä»¶æ’åºå¤±è´¥ï¼Œä½¿ç”¨åŸé¡ºåº: {e}")
        
        self.progress_tracker.finish_stage("å›¾åƒåˆ†ç»„")
        
        # å¤„ç†å›¾ç‰‡ - ä½¿ç”¨å•è¿›ç¨‹æ‰¹å¤„ç†é¿å…CUDAå¤šè¿›ç¨‹é—®é¢˜
        try:
            start_time = time.time()
            all_results = []
            
            self.progress_tracker.start_stage("å›¾åƒå¤„ç†")
            logger.info(f"ğŸ”„ å¯åŠ¨å•è¿›ç¨‹æ‰¹å¤„ç†æ¨¡å¼...")
            
            # åˆå§‹åŒ–å•ä¸ªå¤„ç†å™¨
            processor = BatchProcessor(self.config)
            if not processor.initialize_models('cuda:0'):
                logger.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
                return
            
            # é¢„è¿‡æ»¤
            prefilter = PreFilter(self.config)
            filtered_images = []
            
            if self.config.PREFILTER_ENABLED:
                logger.info("ğŸ¯ å¼€å§‹é¢„è¿‡æ»¤...")
                for image_path in image_files:
                    should_process, reason = prefilter.quick_face_check(image_path)
                    if should_process:
                        filtered_images.append(image_path)
                    else:
                        self.stats['prefiltered'] += 1
                        logger.debug(f"é¢„è¿‡æ»¤è·³è¿‡ {os.path.basename(image_path)}: {reason}")
                
                logger.info(f"ğŸ“Š é¢„è¿‡æ»¤åå‰©ä½™ {len(filtered_images)} å¼ å›¾ç‰‡ (è·³è¿‡ {self.stats['prefiltered']} å¼ )")
            else:
                filtered_images = image_files
            
            # æ‰¹é‡å¤„ç†
            grouper = ImageGrouper(self.config)
            batches = grouper.group_by_batch(filtered_images, self.config.BATCH_SIZE)
            
            logger.info(f"ğŸ“¦ åˆ›å»º {len(batches)} ä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æœ€å¤š {self.config.BATCH_SIZE} å¼ å›¾ç‰‡")
            
            processed_count = 0
            for batch_id, batch in enumerate(batches):
                try:
                    logger.info(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_id + 1}/{len(batches)} ({len(batch)} å¼ å›¾ç‰‡)")
                    
                    batch_results = processor.process_batch(batch)
                    all_results.extend(batch_results)
                    processed_count += len(batch_results)
                    
                    # æ›´æ–°è¿›åº¦
                    self.progress_tracker.update_stage("å›¾åƒå¤„ç†", processed_count)
                    
                    # å®šæœŸæ¸…ç†GPUç¼“å­˜
                    if processor.device and 'cuda' in processor.device and (batch_id + 1) % 5 == 0:
                        torch.cuda.empty_cache()
                        logger.debug(f"ğŸ§¹ æ¸…ç†GPUç¼“å­˜ (æ‰¹æ¬¡ {batch_id + 1})")
                    
                    # å®šæœŸåƒåœ¾å›æ”¶
                    if (batch_id + 1) % 10 == 0:
                        gc.collect()
                        
                except Exception as e:
                    logger.error(f"âŒ æ‰¹æ¬¡ {batch_id + 1} å¤„ç†å¤±è´¥: {e}")
                    # å°è¯•å•ç‹¬å¤„ç†è¯¥æ‰¹æ¬¡ä¸­çš„æ¯å¼ å›¾ç‰‡
                    for image_path in batch:
                        try:
                            result = processor.process_single_image(image_path, None)
                            all_results.append((image_path, result))
                            processed_count += 1
                        except Exception as e2:
                            logger.error(f"âŒ å•å¼ å›¾ç‰‡å¤„ç†å¤±è´¥ {image_path}: {e2}")
                            all_results.append((image_path, {'error': str(e2)}))
                            processed_count += 1
                    
                    self.progress_tracker.update_stage("å›¾åƒå¤„ç†", processed_count)
            
            self.progress_tracker.finish_stage("å›¾åƒå¤„ç†")
            processing_time = time.time() - start_time
            logger.info(f"ğŸ‰ å•è¿›ç¨‹æ‰¹å¤„ç†å®Œæˆï¼Œè€—æ—¶ {processing_time:.1f}ç§’")
            
            # å¤„ç†ç»“æœ
            self.progress_tracker.start_stage("æ–‡ä»¶ç§»åŠ¨")
            logger.info("ğŸ“‚ å¼€å§‹ç§»åŠ¨æ–‡ä»¶åˆ°åˆ†ç±»ç›®å½•...")
            
            moved_count = 0
            for image_path, result in all_results:
                try:
                    if 'error' in result:
                        self.stats['failed'] += 1
                        continue
                    
                    category = result.get('category', 'failed')
                    if self.move_image_to_category(image_path, category):
                        self.stats[category] += 1
                    else:
                        self.stats['failed'] += 1
                    
                    self.analysis_results.append(result)
                    moved_count += 1
                    
                    # æ›´æ–°ç§»åŠ¨è¿›åº¦
                    self.progress_tracker.update_stage("æ–‡ä»¶ç§»åŠ¨", moved_count)
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†ç»“æœå¤±è´¥ {image_path}: {e}")
                    self.stats['failed'] += 1
            
            self.progress_tracker.finish_stage("æ–‡ä»¶ç§»åŠ¨")
        
        except KeyboardInterrupt:
            logger.info("\nâš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            logger.error(f"âŒ å¤šè¿›ç¨‹å¤„ç†å¤±è´¥: {e}")
        
        finally:
            # ä¿å­˜ç»“æœå’Œç»Ÿè®¡
            self.progress_tracker.print_summary()
            self.save_analysis_results()
            self.print_final_statistics()

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºé…ç½®
        config = OptimizedConfig()
        
        # æ£€æŸ¥è¾“å…¥ç›®å½•
        if not os.path.exists(config.INPUT_DIR):
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {config.INPUT_DIR}")
            return
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(config.YOLOV8S_MODEL_PATH):
            logger.error(f"âŒ YOLOv8sæ¨¡å‹ä¸å­˜åœ¨: {config.YOLOV8S_MODEL_PATH}")
            return
        
        if not os.path.exists(config.LICENSE_PLATE_MODEL_PATH):
            logger.error(f"âŒ è½¦ç‰Œæ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨: {config.LICENSE_PLATE_MODEL_PATH}")
            return
        
        # åˆ›å»ºæ£€æµ‹å™¨å¹¶è¿è¡Œ
        detector = OptimizedFacePlateDetector(config)
        detector.run()
        
    except KeyboardInterrupt:
        logger.info("âš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
