#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import gc
import re
import time
import shutil
import logging
import subprocess
import tempfile
from pathlib import Path
from typing import Optional, Dict, List, Tuple


import importlib.util
import numpy as np
import cv2
# ========= åˆ†ç±»å™¨åŠ¨æ€åŠ è½½ä¸è°ƒç”¨ =========
def load_classifier_module(module_path: Path):
    """æŠŠ face_plate_classifier.py å½“æ¨¡å—åŠ è½½ï¼ˆä¸éœ€è¦æ”¹ä½ åŸæ–‡ä»¶ï¼‰"""
    if not module_path.exists():
        print(f"âŒ åˆ†ç±»å™¨æ¨¡å—ä¸å­˜åœ¨: {module_path}"); sys.exit(1)
    spec = importlib.util.spec_from_file_location("face_plate_classifier", str(module_path))
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)
    return mod

def run_classifier(mod, frames_dir: Path, plate_model_path: Path):
    """
    å…³é”®ç‚¹ï¼šåœ¨å®ä¾‹åŒ– FacePlateClassifier ä¹‹å‰ï¼Œç›´æ¥é‡å†™å®ƒæ¨¡å—çº§å…¨å±€å¸¸é‡ï¼Œ
    è§£å†³ä½ åŸè„šæœ¬é‡Œ INPUT_DIR/OUTPUT_BASE_DIR/æ¨¡å‹è·¯å¾„å†™æ­»çš„é—®é¢˜ã€‚
    """
    # 1) æ”¹å†™è¾“å…¥/è¾“å‡ºä¸æ¨¡å‹è·¯å¾„
    mod.INPUT_DIR = str(frames_dir)
    mod.OUTPUT_BASE_DIR = str(frames_dir)
    mod.PLATE_MODEL_PATH = str(plate_model_path)

    # 2) åŒæ­¥ç›®å½•å¸¸é‡ï¼ˆå®ƒä»¬åœ¨åŸæ¨¡å—é‡Œæ˜¯åŸºäº OUTPUT_BASE_DIR å®šä¹‰çš„ï¼‰
    mod.QUALIFIED_DIR = os.path.join(mod.OUTPUT_BASE_DIR, "qualified")
    mod.INSUFFICIENT_SCORE_DIR = os.path.join(mod.OUTPUT_BASE_DIR, "insufficient_score")
    mod.NO_CONTENT_DIR = os.path.join(mod.OUTPUT_BASE_DIR, "no_content")
    mod.ANALYSIS_DIR = os.path.join(mod.OUTPUT_BASE_DIR, "analysis")
    for d in [mod.QUALIFIED_DIR, mod.INSUFFICIENT_SCORE_DIR, mod.NO_CONTENT_DIR, mod.ANALYSIS_DIR]:
        os.makedirs(d, exist_ok=True)

    # 3) è¿è¡Œ
    clf = mod.FacePlateClassifier()
    clf.run()

# ========= é€šç”¨å·¥å…· =========
def which_or_die(bin_name: str):
    path = shutil.which(bin_name)
    if not path:
        print(f"âŒ æœªæ‰¾åˆ°ä¾èµ–ï¼š{bin_name}ï¼ˆè¯·å…ˆå®‰è£…ï¼‰")
        sys.exit(1)
    return path

def run(cmd, timeout=None, check=False, capture=False):
    """ç»Ÿä¸€æ‰§è¡Œå‘½ä»¤ï¼›å¯¹ ffmpeg/ffprobe é™å™ªä½†ä¿ç•™ statsã€‚"""
    if isinstance(cmd, (list, tuple)) and cmd:
        head = str(cmd[0])
        if head.endswith("ffmpeg") or head.endswith("ffprobe") or head in ("ffmpeg", "ffprobe"):
            if "-hide_banner" not in cmd:
                cmd.insert(1, "-hide_banner")
            if "-loglevel" not in cmd:
                cmd.insert(1, "-loglevel"); cmd.insert(2, "error")
            if (head.endswith("ffmpeg") or head == "ffmpeg") and "-stats" not in cmd:
                cmd.insert(3, "-stats")
    print("ğŸš€", " ".join(str(x) for x in cmd))
    return subprocess.run(cmd, timeout=timeout, check=check, text=True, capture_output=capture)

def atomic_move(src: Path, dst: Path):
    dst.parent.mkdir(parents=True, exist_ok=True)
    try:
        os.replace(src, dst)
    except OSError as e:
        if e.errno == 18:  # cross-device
            shutil.copy2(src, dst); src.unlink()
        else:
            raise

# ========= ffmpeg å…¼å®¹å…œåº•ï¼ˆH.264/MP4ï¼‰ =========
def ffprobe_json(path: Path):
    which_or_die("ffprobe")
    res = run([
        "ffprobe", "-v", "error",
        "-select_streams", "v:0",
        "-show_entries", "format=format_name:stream=codec_name,avg_frame_rate,nb_frames",
        "-of", "json", str(path)
    ], capture=True)
    if res.returncode != 0:
        return None
    try:
        return json.loads(res.stdout or "{}")
    except Exception:
        return None

def _transcode_to_h264(path: Path):
    which_or_die("ffmpeg")
    out = path.with_suffix(".h264.mp4")
    res = run([
        "ffmpeg", "-i", str(path),
        "-c:v", "libx264", "-pix_fmt", "yuv420p", "-preset", "veryfast",
        "-c:a", "aac", "-b:a", "192k",
        "-movflags", "+faststart", "-y", str(out)
    ])
    if res.returncode != 0 or (not out.exists()) or out.stat().st_size == 0:
        print("âŒ è½¬ç å¤±è´¥"); sys.exit(1)
    atomic_move(out, path)
    print("ğŸ§© å·²è½¬ç ä¸º H.264 MP4")

def ensure_ffmpeg_compatible(path: Path):
    info = ffprobe_json(path)
    if not info or "streams" not in info or not info["streams"]:
        print("âš ï¸ ffprobe å¤±è´¥ï¼Œç›´æ¥è½¬ç åˆ° H.264â€¦")
        _transcode_to_h264(path); return
    fmt = (info.get("format", {}) or {}).get("format_name", "") or ""
    vcodec = (info["streams"][0] or {}).get("codec_name", "")
    is_mp4 = "mp4" in fmt
    is_h264 = (vcodec == "h264")
    if is_mp4 and is_h264:
        print("âœ… å·²å…¼å®¹ï¼šMP4 + H.264"); return
    if (not is_mp4) and is_h264:
        fixed = path.with_suffix(".repack.mp4")
        res = run(["ffmpeg", "-i", str(path), "-c", "copy", "-movflags", "+faststart", "-y", str(fixed)])
        if res.returncode == 0 and fixed.exists() and fixed.stat().st_size > 0:
            atomic_move(fixed, path)
            print("ğŸ” å·²é‡å°è£…ä¸º MP4ï¼ˆæ— é‡å‹ç¼©ï¼‰")
            return ensure_ffmpeg_compatible(path)
    _transcode_to_h264(path)

# ========= ä¸‹è½½ï¼ˆä¸¤é˜¶æ®µï¼šä¼˜å…ˆ MP4+M4Aï¼Œå…¶æ¬¡ä»»æ„éŸ³é¢‘â†’AACï¼‰ =========
def download_video(url: str, out_dir: Path, video_number: str) -> Path:
    which_or_die("yt-dlp"); which_or_die("ffmpeg")
    out_dir.mkdir(parents=True, exist_ok=True)

    tmp_dir = Path(tempfile.mkdtemp(prefix="yt_"))
    stem = f"downloaded_video{video_number}"
    out_tmpl = str(tmp_dir / (stem + ".%(ext)s"))
    out_final = out_dir / f"{stem}.mp4"

    attempts = [
        ("bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]", None, "ä¼˜å…ˆ MP4+M4A"),
        ("bv*+ba/b", "ffmpeg:-c:v copy -c:a aac -b:a 192k -movflags +faststart", "å…œåº•ï¼šä»»æ„éŸ³é¢‘â†’AAC")
    ]
    for i, (fmt, pp, desc) in enumerate(attempts, 1):
        print(f"ğŸ¯ å°è¯• {i}/{len(attempts)}ï¼š{desc}")
        cmd = [
            "yt-dlp", "-N", "8",
            "--no-part", "--continue", "--restrict-filenames",
            "--merge-output-format", "mp4",
            "-o", out_tmpl, "-f", fmt, url
        ]
        if pp:
            cmd += ["--postprocessor-args", pp]
        res = run(cmd)
        if res.returncode == 0:
            cand = None
            for f in tmp_dir.iterdir():
                if f.is_file() and f.suffix.lower() in (".mp4", ".mkv", ".mov"):
                    if ".f" in f.name or f.name.endswith(".ytdl"):  # è¿‡æ»¤åˆ†è½¨ä¸´æ—¶æ–‡ä»¶
                        continue
                    cand = f
            if cand:
                atomic_move(cand, out_final)
                print(f"âœ… ä¸‹è½½å®Œæˆï¼š{out_final}")
                shutil.rmtree(tmp_dir, ignore_errors=True)
                ensure_ffmpeg_compatible(out_final)
                return out_final
        print("âš ï¸ æœ¬æ¬¡æ–¹æ¡ˆå¤±è´¥ï¼Œåˆ‡æ¢ä¸‹ä¸€ç§â€¦")

    shutil.rmtree(tmp_dir, ignore_errors=True)
    print("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥"); sys.exit(1)

# ========= æŠ½å¸§ =========
def extract_frames_ffmpeg(video_path: Path, output_dir: Path, fps: float, jpg_q: int, video_number: str) -> bool:
    which_or_die("ffmpeg")
    output_dir.mkdir(parents=True, exist_ok=True)
    pattern = output_dir / f"video{video_number}_frame_%06d.jpg"
    cmd = [
        "ffmpeg",
        "-i", str(video_path),
        "-vsync", "vfr",
        "-vf", f"fps={fps}",
        "-q:v", str(jpg_q),
        "-vcodec", "mjpeg",
        "-y", str(pattern)
    ]
    res = run(cmd)
    if res.returncode == 0:
        print(f"âœ… æŠ½å¸§å®Œæˆï¼š{output_dir}")
        return True
    else:
        print("âŒ æŠ½å¸§å¤±è´¥")
        return False

# ========= åˆ†ç±»ä¾èµ–æ£€æŸ¥ =========
def check_py_deps() -> bool:
    missing = []
    try:
        import torch  # noqa
    except Exception:
        missing.append("torch")
    try:
        from retinaface import RetinaFace  # noqa
    except Exception:
        missing.append("retina-face")
    try:
        from ultralytics import YOLO  # noqa
    except Exception:
        missing.append("ultralytics")
    try:
        import easyocr  # noqa
    except Exception:
        missing.append("easyocr")

    if missing:
        print("âŒ ç¼ºå°‘ä¾èµ–åº“ï¼š", ", ".join(missing))
        print("è¯·å®‰è£…ï¼š")
        for dep in missing:
            print(f"  pip install {dep}")
        return False
    return True

# ========= æ­£è„¸/è½¦ç‰Œ/OCR è¯„åˆ†åˆ†ç±»å™¨ =========
class FacePlateClassifier:
    SUPPORTED_FORMATS = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')

    def __init__(self,
                 input_dir: str,
                 output_base: str,
                 plate_model_path: str,
                 score_threshold: int = 5,
                 clear_face_score: int = 2,
                 clear_plate_score: int = 2,
                 text_score: int = 2,
                 text_fields_threshold: int = 10,
                 yaw_thresh: float = 35.0,
                 min_face_conf: float = 0.8,
                 min_plate_conf: float = 0.5,
                 min_face_size: int = 60,
                 min_plate_size: int = 50,
                 min_face_clarity: float = 30.0,
                 face_area_px2: int = 3600,
                 face_dist_ratio: float = 0.3,
                 min_text_conf: float = 0.5,
                 min_text_len: int = 3,
                 use_gpu: bool = True,
                 gpu_id: int = 0,
                 enable_torch_opt: bool = True,
                 gc_frequency: int = 100,
                 progress_update_frequency: int = 50):
        self.cfg = locals().copy()  # ä¿å­˜é…ç½®
        self.cfg.pop('self')

        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        self.logger = logging.getLogger("Classifier")
        self.start_time = time.time()
        self.stats = {'qualified': 0, 'insufficient_score': 0, 'no_content': 0, 'failed': 0}
        self.analysis_results: List[Dict] = []

        self.device = self._setup_gpu()
        self._create_output_dirs()
        self._initialize_models()
        self._initialize_ocr()

    # ----- init helpers -----
    def _setup_gpu(self) -> str:
        import torch
        try:
            if self.cfg["use_gpu"] and torch.cuda.is_available():
                cnt = torch.cuda.device_count()
                if self.cfg["gpu_id"] < cnt:
                    dev = f'cuda:{self.cfg["gpu_id"]}'
                    name = torch.cuda.get_device_name(self.cfg["gpu_id"])
                    mem = torch.cuda.get_device_properties(self.cfg["gpu_id"]).total_memory / 1024**3
                    self.logger.info(f"ğŸš€ GPU: {name} (id {self.cfg['gpu_id']})ï¼Œæ˜¾å­˜ {mem:.1f} GB")
                    torch.cuda.empty_cache()
                    if self.cfg["enable_torch_opt"]:
                        torch.backends.cudnn.benchmark = True
                        torch.backends.cudnn.deterministic = False
                        self.logger.info("âš¡ å·²å¯ç”¨ cuDNN benchmark")
                    return dev
                else:
                    self.logger.warning(f"âš ï¸ æŒ‡å®š GPU_ID {self.cfg['gpu_id']} è¶…èŒƒå›´ï¼ˆå…± {cnt} å—ï¼‰")
                    return 'cpu'
            else:
                if not torch.cuda.is_available():
                    self.logger.info("ğŸ’» æœªæ£€æµ‹åˆ° CUDAï¼Œä½¿ç”¨ CPU")
                else:
                    self.logger.info("ğŸ’» å·²ç¦ç”¨ GPUï¼Œä½¿ç”¨ CPU")
                return 'cpu'
        except Exception as e:
            self.logger.error(f"âŒ GPU è®¾ç½®å¤±è´¥: {e}")
            return 'cpu'

    def _create_output_dirs(self):
        base = Path(self.cfg["output_base"])
        self.qual_dir = base / "qualified"
        self.insuf_dir = base / "insufficient_score"
        self.empty_dir = base / "no_content"
        self.analysis_dir = base / "analysis"
        for d in [self.qual_dir, self.insuf_dir, self.empty_dir, self.analysis_dir]:
            d.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {d}")

    def _initialize_models(self):
        from retinaface import RetinaFace
        from ultralytics import YOLO

        # RetinaFace ç®€æµ‹
        self.logger.info("ğŸ” åˆå§‹åŒ– RetinaFaceâ€¦")
        _ = RetinaFace.detect_faces(np.ones((100, 100, 3), dtype=np.uint8) * 128)
        self.retina = RetinaFace
        self.logger.info("âœ… RetinaFace å°±ç»ª")

        # YOLO è½¦ç‰Œ
        plate_path = self.cfg["plate_model_path"]
        if not Path(plate_path).exists():
            raise FileNotFoundError(f"è½¦ç‰Œæ¨¡å‹ä¸å­˜åœ¨: {plate_path}")
        self.logger.info("ğŸš— åˆå§‹åŒ– YOLO è½¦ç‰Œæ¨¡å‹â€¦")
        self.plate_model = YOLO(plate_path)
        self.logger.info("âœ… YOLO è½¦ç‰Œæ¨¡å‹å°±ç»ª")

    def _initialize_ocr(self):
        import easyocr
        gpu_flag = 'cuda' in self.device
        self.logger.info("ğŸ“ åˆå§‹åŒ– EasyOCRâ€¦")
        self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=gpu_flag)
        self.logger.info(f"âœ… EasyOCR å°±ç»ªï¼ˆ{'GPU' if gpu_flag else 'CPU'}ï¼‰")

    # ----- metrics helpers -----
    def _calc_face_clarity(self, image: np.ndarray, bbox: Tuple[int, int, int, int]) -> float:
        try:
            x1, y1, x2, y2 = bbox
            h, w = image.shape[:2]
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w, int(x2)), min(h, int(y2))
            if x2 <= x1 or y2 <= y1:
                return 0.0
            roi = image[y1:y2, x1:x2]
            if roi.size == 0:
                return 0.0
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape) == 3 else roi
            lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            grad_mean = np.mean(np.sqrt(gx**2 + gy**2))
            return float(lap_var + 0.1 * grad_mean)
        except Exception:
            return 0.0

    def _calc_yaw(self, landmarks: Dict) -> float:
        try:
            left_eye = np.array(landmarks['left_eye'])
            right_eye = np.array(landmarks['right_eye'])
            nose = np.array(landmarks['nose'])
            eye_center = (left_eye + right_eye) / 2
            eye_w = np.linalg.norm(right_eye - left_eye)
            if eye_w < 10:
                return 90.0
            yaw = abs((nose[0] - eye_center[0]) / eye_w) * 60.0
            return float(yaw)
        except Exception:
            return 90.0

    # ----- detectors -----
    def _faces(self, image_path: str) -> Tuple[int, List[Dict]]:
        dets = self.retina.detect_faces(image_path)
        if not isinstance(dets, dict) or len(dets) == 0:
            return 0, []
        img = cv2.imread(image_path)
        if img is None:
            return 0, []
        H, W = img.shape[:2]
        img_area = W * H

        out = []
        for _, fd in dets.items():
            conf = float(fd.get('score', 0.0))
            if conf < self.cfg["min_face_conf"]:
                continue
            if 'facial_area' not in fd or 'landmarks' not in fd:
                continue
            x1, y1, x2, y2 = fd['facial_area']
            fw, fh = x2 - x1, y2 - y1
            if min(fw, fh) < self.cfg["min_face_size"]:
                continue

            clarity = self._calc_face_clarity(img, (x1, y1, x2, y2))
            area = fw * fh
            dist_ratio = area / img_area
            is_clear = clarity >= self.cfg["min_face_clarity"]
            is_close = dist_ratio >= self.cfg["face_dist_ratio"]
            is_big = area >= self.cfg["face_area_px2"]
            if not (is_clear and (is_close or is_big)):
                continue

            yaw = self._calc_yaw(fd['landmarks'])
            is_frontal = yaw <= self.cfg["yaw_thresh"]
            if is_frontal:
                out.append({
                    "confidence": conf,
                    "yaw_angle": yaw,
                    "is_frontal": True,
                    "facial_area": [int(x1), int(y1), int(x2), int(y2)],
                    "face_size": [int(fw), int(fh)],
                    "quality_info": {
                        "clarity_score": clarity,
                        "distance_score": dist_ratio,
                        "face_area": int(area),
                        "is_clear": is_clear, "is_close": is_close, "is_large_enough": is_big
                    }
                })
        return len(out), out

    def _plates(self, image_path: str) -> Tuple[int, List[Dict]]:
        rs = self.plate_model(image_path, verbose=False)
        if not rs or len(rs) == 0:
            return 0, []
        r0 = rs[0]
        if r0.boxes is None or len(r0.boxes) == 0:
            return 0, []
        out = []
        for box in r0.boxes:
            conf = float(box.conf[0])
            if conf < self.cfg["min_plate_conf"]:
                continue
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            w, h = x2 - x1, y2 - y1
            if min(w, h) < self.cfg["min_plate_size"]:
                continue
            out.append({"confidence": conf,
                        "bbox": [float(x1), float(y1), float(x2), float(y2)],
                        "plate_size": [float(w), float(h)]})
        return len(out), out

    def _texts(self, image_path: str) -> Tuple[int, List[Dict]]:
        img = cv2.imread(image_path)
        if img is None:
            return 0, []
        rs = self.ocr_reader.readtext(img)
        if not rs:
            return 0, []
        out = []
        for bbox, text, conf in rs:
            conf = float(conf) if conf is not None else 0.0
            if conf < self.cfg["min_text_conf"]:
                continue
            t = (text or "").strip()
            if len(t) < self.cfg["min_text_len"]:
                continue
            if t.replace(' ', '').replace('.', '').replace('-', '').replace('_', ''):
                out.append({"text": t, "confidence": conf, "bbox": bbox})
        return len(out), out

    def classify_image(self, image_path: str) -> Tuple[str, Dict]:
        try:
            fname = os.path.basename(image_path)
            n_face, face_det = self._faces(image_path)
            n_plate, plate_det = self._plates(image_path)
            n_text, text_det = self._texts(image_path)

            score = 0
            details = []
            if n_face > 0:
                s = n_face * self.cfg["clear_face_score"]; score += s
                details.append(f"æ¸…æ™°æ­£è„¸ {n_face} å¼  Ã— {self.cfg['clear_face_score']} = {s} åˆ†")
            if n_plate > 0:
                s = n_plate * self.cfg["clear_plate_score"]; score += s
                details.append(f"æ¸…æ™°è½¦ç‰Œ {n_plate} å¼  Ã— {self.cfg['clear_plate_score']} = {s} åˆ†")
            if n_text >= self.cfg["text_fields_threshold"]:
                s = self.cfg["text_score"]; score += s
                details.append(f"å¯è¯†åˆ«æ–‡å­— {n_text} ä¸ªå­—æ®µ(>={self.cfg['text_fields_threshold']}) = {s} åˆ†")
            elif n_text > 0:
                details.append(f"å¯è¯†åˆ«æ–‡å­— {n_text} ä¸ªå­—æ®µ(<{self.cfg['text_fields_threshold']}) = 0 åˆ†")

            meets = score > self.cfg["score_threshold"]
            if meets:
                category = "qualified"; reason = f'æ€»åˆ† {score} åˆ† > {self.cfg["score_threshold"]} åˆ†ï¼Œç¬¦åˆè¦æ±‚'
            else:
                if score == 0:
                    category = "no_content"; reason = f'æ€»åˆ† {score} åˆ†ï¼Œæ— ä»»ä½•æœ‰æ•ˆå†…å®¹'
                else:
                    category = "insufficient_score"; reason = f'æ€»åˆ† {score} åˆ† â‰¤ {self.cfg["score_threshold"]} åˆ†ï¼Œä¸ç¬¦åˆè¦æ±‚'

            analysis = {
                "filename": fname,
                "frontal_faces": n_face,
                "license_plates": n_plate,
                "text_count": n_text,
                "total_score": score,
                "score_details": details,
                "meets_requirements": meets,
                "score_threshold": self.cfg["score_threshold"],
                "face_details": face_det,
                "plate_details": plate_det,
                "text_details": text_det,
                "category": category,
                "reason": reason,
                "timestamp": time.time()
            }
            return category, analysis
        except Exception as e:
            return "failed", {"filename": os.path.basename(image_path), "error": str(e)}

    def _move_to(self, image_path: str, category: str) -> bool:
        target_dir = {"qualified": self.qual_dir, "insufficient_score": self.insuf_dir, "no_content": self.empty_dir}.get(category)
        if target_dir is None:
            return False
        name = os.path.basename(image_path)
        dst = target_dir / name
        c = 1
        while dst.exists():
            stem, ext = os.path.splitext(name)
            dst = target_dir / f"{stem}_{c}{ext}"
            c += 1
        try:
            shutil.move(image_path, dst)
            return True
        except Exception as e:
            self.logger.error(f"âŒ ç§»åŠ¨å¤±è´¥ {image_path} -> {dst}: {e}")
            return False

    def _image_files(self) -> List[str]:
        p = Path(self.cfg["input_dir"])
        if not p.exists():
            self.logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {p}")
            return []
        files = []
        for f in sorted(p.iterdir()):
            if f.is_file() and f.suffix.lower() in self.SUPPORTED_FORMATS:
                files.append(str(f))
        self.logger.info(f"ğŸ“Š æ‰¾åˆ° {len(files)} ä¸ªå›¾åƒæ–‡ä»¶")
        return files

    def _save_results(self):
        analysis_file = self.analysis_dir / "classification_analysis.json"
        with open(analysis_file, "w", encoding="utf-8") as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False)

        summary_file = self.analysis_dir / "classification_summary.json"
        total = len(self.analysis_results)
        summary = {
            "total_processed": total,
            "statistics": self.stats.copy(),
            "processing_time": time.time() - self.start_time,
            "scoring_system": {
                "clear_face_score": self.cfg["clear_face_score"],
                "clear_plate_score": self.cfg["clear_plate_score"],
                "text_recognition_score": self.cfg["text_score"],
                "text_fields_threshold": self.cfg["text_fields_threshold"],
                "score_threshold": self.cfg["score_threshold"]
            },
            "configuration": {
                "yaw_angle_threshold": self.cfg["yaw_thresh"],
                "min_face_confidence": self.cfg["min_face_conf"],
                "min_plate_confidence": self.cfg["min_plate_conf"],
                "min_text_confidence": self.cfg["min_text_conf"]
            },
            "timestamp": time.time()
        }
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        self.logger.info(f"ğŸ“Š åˆ†æç»“æœ: {analysis_file}")
        self.logger.info(f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦: {summary_file}")

    def _print_final(self):
        dt = time.time() - self.start_time
        total = sum(self.stats.values())
        self.logger.info("="*80)
        self.logger.info("ğŸ‰ åˆ†ç±»å®Œæˆï¼ˆæ–°è®¡åˆ†ç³»ç»Ÿï¼‰")
        self.logger.info(f"âœ… åˆæ ¼: {self.stats['qualified']} | âŒ ä¸è¶³: {self.stats['insufficient_score']} | â­• æ— å†…å®¹: {self.stats['no_content']} | ğŸ’¥ å¤±è´¥: {self.stats['failed']}")
        self.logger.info(f"ğŸ“Š æ€»å¤„ç†: {total}  | â° ç”¨æ—¶: {dt:.1f}s")
        if total:
            self.logger.info(f"ğŸš€ é€Ÿåº¦: {total/dt:.1f} å¼ /ç§’")
        for name, d in [("ç¬¦åˆæ¡ä»¶", self.qual_dir), ("åˆ†æ•°ä¸å¤Ÿ", self.insuf_dir), ("æ— ä»»ä½•å†…å®¹", self.empty_dir)]:
            if d.exists():
                c = len([f for f in d.iterdir() if f.is_file() and f.suffix.lower() in self.SUPPORTED_FORMATS])
                self.logger.info(f"  ğŸ“ {name}: {c}")
        self.logger.info("="*80)

    def run(self):
        from tqdm import tqdm
        import torch

        self.logger.info("ğŸš€ å¯åŠ¨åˆ†ç±»å™¨â€¦")
        self.logger.info(f"ğŸ“ è¾“å…¥: {self.cfg['input_dir']} / è¾“å‡ºåŸºå‡†: {self.cfg['output_base']} / è®¾å¤‡: {self.device}")

        files = self._image_files()
        if not files:
            self.logger.warning("âŒ æœªæ‰¾åˆ°å›¾åƒ"); return

        with tqdm(total=len(files), desc="åˆ†ç±»è¿›åº¦", ncols=120,
                  bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
            for i, imgp in enumerate(files):
                cat, ana = self.classify_image(imgp)
                if cat != "failed":
                    if self._move_to(imgp, cat):
                        self.stats[cat] += 1
                    else:
                        self.stats["failed"] += 1
                        ana["move_failed"] = True
                else:
                    self.stats["failed"] += 1
                self.analysis_results.append(ana)
                pbar.update(1)

                if i % self.cfg["progress_update_frequency"] == 0 and i > 0:
                    s = f"âœ…{self.stats['qualified']} âŒ{self.stats['insufficient_score']} â­•{self.stats['no_content']}"
                    pbar.set_description(f"åˆ†ç±»è¿›åº¦ ({s})")
                if i % self.cfg["gc_frequency"] == 0 and i > 0 and 'cuda' in self.device:
                    torch.cuda.empty_cache(); gc.collect()

        self._save_results()
        self._print_final()

# ========= äº¤äº’å¼å…¥å£ =========
def main():
    print("===== ğŸ¬ äº¤äº’å¼ä¸‹è½½â†’æŠ½å¸§â†’åˆ†ç±» å·¥å…· =====")
    url = input("è¯·è¾“å…¥è§†é¢‘é“¾æ¥æˆ–æœ¬åœ°æ–‡ä»¶è·¯å¾„: ").strip()
    if not url:
        print("âŒ å¿…é¡»è¾“å…¥é“¾æ¥æˆ–æœ¬åœ°è·¯å¾„"); sys.exit(1)

    video_number = input("è¯·è¾“å…¥è§†é¢‘ç¼–å·ï¼ˆç”¨äºå‘½åï¼Œå¦‚ 38ï¼‰: ").strip()
    if not video_number or not re.fullmatch(r"\d+", video_number):
        print("âŒ è§†é¢‘ç¼–å·å¿…é¡»æ˜¯æ•°å­—"); sys.exit(1)

    fps_in = input("æ¯ç§’æŠ½å¸§æ•°ï¼ˆé»˜è®¤=3ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ï¼‰: ").strip()
    fps = float(fps_in) if fps_in else 3.0

    jpg_in = input("JPGè´¨é‡ï¼ˆé»˜è®¤=1ï¼Œè¶Šå°è¶Šæ¸…æ™°ï¼Œ2-31ï¼›ç›´æ¥å›è½¦=1ï¼‰: ").strip()
    jpg_q = int(jpg_in) if jpg_in else 1

    # ç”¨ä½ çš„è·¯å¾„å¸ƒå±€
    base_dir = Path("/home/zhiqics/sanjian/predata")
    video_dir = base_dir / "videos"
    frames_dir = base_dir / f"output_frames{video_number}"

    # 1) è·å–è§†é¢‘
    downloaded = False
    if url.startswith("http"):
        video_path = download_video(url, video_dir, video_number)
        downloaded = True
    else:
        video_path = Path(url)
        if not video_path.exists():
            print(f"âŒ æœ¬åœ°è§†é¢‘ä¸å­˜åœ¨ï¼š{video_path}"); sys.exit(1)
        ensure_ffmpeg_compatible(video_path)

    # 2) æŠ½å¸§
    ok = extract_frames_ffmpeg(
        video_path=video_path,
        output_dir=frames_dir,
        fps=fps,
        jpg_q=jpg_q,
        video_number=video_number
    )
    if not ok:
        sys.exit(1)

    # 3) æˆåŠŸååˆ é™¤â€œæœ¬æ¬¡ä¸‹è½½â€çš„è§†é¢‘æ–‡ä»¶
    if downloaded:
        try:
            video_path.unlink(missing_ok=True)
            print(f"ğŸ§¹ å·²åˆ é™¤ä¸‹è½½è§†é¢‘ï¼š{video_path}")
            try:
                if video_dir.exists() and not any(video_dir.iterdir()):
                    video_dir.rmdir()
                    print(f"ğŸ§¼ å·²æ¸…ç†ç©ºç›®å½•ï¼š{video_dir}")
            except Exception:
                pass
        except Exception as e:
            print(f"âš ï¸ åˆ é™¤ä¸‹è½½è§†é¢‘å¤±è´¥ï¼š{e}")

    # 4) ç»§ç»­æ‰§è¡Œï¼šæ­£è„¸/è½¦ç‰Œ/OCR åˆ†ç±»
    print("\n===== ğŸ§  å¼€å§‹å›¾åƒåˆ†ç±»ï¼ˆæ­£è„¸/è½¦ç‰Œ/OCRï¼‰ =====")
    default_model = str(base_dir / "models/license_plate_detector.pt")
    model_path_in = input(f"è¯·è¾“å…¥è½¦ç‰Œæ£€æµ‹æ¨¡å‹è·¯å¾„ï¼ˆå›è½¦é»˜è®¤: {default_model}ï¼‰: ").strip()
    plate_model = model_path_in if model_path_in else default_model

    use_gpu_in = input("æ˜¯å¦å¯ç”¨GPU? (Y/nï¼Œé»˜è®¤Y): ").strip().lower()
    use_gpu = False if use_gpu_in == "n" else True
    gpu_id_in = input("GPUè®¾å¤‡IDï¼ˆé»˜è®¤=0ï¼‰: ").strip()
    gpu_id = int(gpu_id_in) if gpu_id_in else 0

    # ä¾èµ–æ£€æŸ¥
    if not check_py_deps():
        sys.exit(1)

    # ä¼˜å…ˆå°è¯•åŠ¨æ€åŠ è½½ face_plate_classifier.py
    classifier_py = Path(__file__).parent / "face_plate_classifier.py"
    try:
        if classifier_py.exists():
            print(f"ğŸ§© åŠ¨æ€åŠ è½½åˆ†ç±»å™¨æ¨¡å—: {classifier_py}")
            mod = load_classifier_module(classifier_py)
            run_classifier(mod, frames_dir, Path(plate_model))
        else:
            print("âš ï¸ æœªæ‰¾åˆ° face_plate_classifier.pyï¼Œä½¿ç”¨å†…ç½® FacePlateClassifier ç±»")
            clf = FacePlateClassifier(
                input_dir=str(frames_dir),
                output_base=str(frames_dir),
                plate_model_path=plate_model,
                score_threshold=5,
                clear_face_score=2,
                clear_plate_score=2,
                text_score=2,
                text_fields_threshold=10,
                yaw_thresh=35.0,
                min_face_conf=0.8,
                min_plate_conf=0.5,
                min_face_size=60,
                min_plate_size=50,
                min_face_clarity=30.0,
                face_area_px2=3600,
                face_dist_ratio=0.3,
                min_text_conf=0.5,
                min_text_len=3,
                use_gpu=use_gpu,
                gpu_id=gpu_id,
                enable_torch_opt=True,
                gc_frequency=100,
                progress_update_frequency=50
            )
            clf.run()
    except KeyboardInterrupt:
        print("âš¡ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ åˆ†ç±»æµç¨‹å¼‚å¸¸ï¼š{e}")
        import traceback; print(traceback.format_exc())

if __name__ == "__main__":
    main()
