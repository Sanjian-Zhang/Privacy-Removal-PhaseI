#!/usr/bin/env python3
"""
Face Anonymization Made Simple - æ‰¹é‡åŒ¿ååŒ–å¤„ç†è„šæœ¬
ç”¨äºæ‰¹é‡å¤„ç†å¤§é‡å›¾åƒçš„åŒ¿ååŒ–
"""

import os
import argparse
import glob
import torch
from tqdm import tqdm
from pathlib import Path
from transformers import CLIPImageProcessor, CLIPVisionModel
from diffusers import AutoencoderKL, DDPMScheduler
from diffusers.utils import load_image
from src.diffusers.models.referencenet.referencenet_unet_2d_condition import (
    ReferenceNetModel,
)
from src.diffusers.models.referencenet.unet_2d_condition import UNet2DConditionModel
from src.diffusers.pipelines.referencenet.pipeline_referencenet import (
    StableDiffusionReferenceNetPipeline,
)

def setup_pipeline():
    """è®¾ç½®äººè„¸åŒ¿ååŒ–å¤„ç†ç®¡é“"""
    print("ğŸ”§ è®¾ç½®å¤„ç†ç®¡é“...")
    
    face_model_id = "hkung/face-anon-simple"
    clip_model_id = "openai/clip-vit-large-patch14"
    sd_model_id = "stabilityai/stable-diffusion-2-1"

    # åŠ è½½æ¨¡å‹
    unet = UNet2DConditionModel.from_pretrained(
        face_model_id, subfolder="unet", use_safetensors=True
    )
    referencenet = ReferenceNetModel.from_pretrained(
        face_model_id, subfolder="referencenet", use_safetensors=True
    )
    conditioning_referencenet = ReferenceNetModel.from_pretrained(
        face_model_id, subfolder="conditioning_referencenet", use_safetensors=True
    )
    vae = AutoencoderKL.from_pretrained(sd_model_id, subfolder="vae", use_safetensors=True)
    scheduler = DDPMScheduler.from_pretrained(
        sd_model_id, subfolder="scheduler", use_safetensors=True
    )
    feature_extractor = CLIPImageProcessor.from_pretrained(
        clip_model_id, use_safetensors=True
    )
    image_encoder = CLIPVisionModel.from_pretrained(clip_model_id, use_safetensors=True)

    # åˆ›å»ºç®¡é“
    pipe = StableDiffusionReferenceNetPipeline(
        unet=unet,
        referencenet=referencenet,
        conditioning_referencenet=conditioning_referencenet,
        vae=vae,
        feature_extractor=feature_extractor,
        image_encoder=image_encoder,
        scheduler=scheduler,
    )
    pipe = pipe.to("cuda")
    
    return pipe

def anonymize_image(pipe, image_path, output_path, anonymization_degree=1.25):
    """å¯¹å•ä¸ªå›¾åƒè¿›è¡ŒåŒ¿ååŒ–å¤„ç†"""
    try:
        # åŠ è½½å›¾åƒ
        original_image = load_image(image_path)
        original_width, original_height = original_image.size
        
        # ç”ŸæˆåŒ¿ååŒ–å›¾åƒ
        generator = torch.manual_seed(42)  # ä½¿ç”¨å›ºå®šç§å­ä»¥ä¿æŒä¸€è‡´æ€§
        anon_image = pipe(
            source_image=original_image,
            conditioning_image=original_image,
            num_inference_steps=100,  # å‡å°‘æ­¥æ•°ä»¥æé«˜æ‰¹å¤„ç†é€Ÿåº¦
            guidance_scale=4.0,
            generator=generator,
            anonymization_degree=anonymization_degree,
            width=original_width,
            height=original_height,
        ).images[0]
        
        # ä¿å­˜ç»“æœ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        anon_image.save(output_path)
        return True
    except Exception as e:
        print(f"âŒ å¤„ç† {image_path} å¤±è´¥: {str(e)}")
        return False

def process_batch(args):
    """æ‰¹é‡å¤„ç†å›¾åƒ"""
    # è·å–æ‰€æœ‰è¾“å…¥æ–‡ä»¶
    input_pattern = os.path.join(args.input_dir, args.pattern)
    image_files = glob.glob(input_pattern)
    
    if not image_files:
        print(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å›¾åƒæ–‡ä»¶: {input_pattern}")
        return
    
    print(f"ğŸ” æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶è¿›è¡Œå¤„ç†")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è®¾ç½®å¤„ç†ç®¡é“
    pipe = setup_pipeline()
    
    # æ‰¹é‡å¤„ç†å›¾åƒ
    success_count = 0
    failed_count = 0
    
    for image_path in tqdm(image_files, desc="å¤„ç†å›¾åƒ"):
        # æ„å»ºè¾“å‡ºè·¯å¾„
        rel_path = os.path.relpath(image_path, args.input_dir)
        output_path = os.path.join(args.output_dir, rel_path)
        
        # å¤„ç†å›¾åƒ
        if anonymize_image(pipe, image_path, output_path, args.anonymization_degree):
            success_count += 1
        else:
            failed_count += 1
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"  - æˆåŠŸ: {success_count}")
    print(f"  - å¤±è´¥: {failed_count}")
    print(f"  - æ€»è®¡: {len(image_files)}")
    print(f"ğŸ‰ å¤„ç†å®Œæˆ! ç»“æœä¿å­˜åœ¨: {args.output_dir}")

def main():
    parser = argparse.ArgumentParser(description="Face Anonymization Made Simple - æ‰¹é‡å¤„ç†å·¥å…·")
    parser.add_argument("--input_dir", required=True, help="è¾“å…¥å›¾åƒç›®å½•")
    parser.add_argument("--output_dir", required=True, help="è¾“å‡ºå›¾åƒç›®å½•")
    parser.add_argument("--pattern", default="*.jpg", help="å›¾åƒæ–‡ä»¶åŒ¹é…æ¨¡å¼ (é»˜è®¤: '*.jpg')")
    parser.add_argument("--anonymization_degree", type=float, default=1.25, help="åŒ¿ååŒ–ç¨‹åº¦ (é»˜è®¤: 1.25)")
    
    args = parser.parse_args()
    
    print("ğŸ­ Face Anonymization Made Simple - æ‰¹é‡å¤„ç†å·¥å…·")
    print("=" * 50)
    print(f"âš™ï¸ é…ç½®:")
    print(f"  - è¾“å…¥ç›®å½•: {args.input_dir}")
    print(f"  - è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  - åŒ¹é…æ¨¡å¼: {args.pattern}")
    print(f"  - åŒ¿ååŒ–ç¨‹åº¦: {args.anonymization_degree}")
    print("=" * 50)
    
    try:
        process_batch(args)
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
