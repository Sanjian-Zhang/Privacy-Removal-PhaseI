#!/usr/bin/env python3
"""
Face Anonymization Made Simple - å•å¼ å›¾ç‰‡å¤„ç†è„šæœ¬
ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå¤„ç†å•å¼ å›¾ç‰‡
"""

import os
import torch
import gc
from transformers import CLIPImageProcessor, CLIPVisionModel
from diffusers import AutoencoderKL, DDPMScheduler
from diffusers.utils import load_image
from src.diffusers.models.referencenet.referencenet_unet_2d_condition import (
    ReferenceNetModel,
)
from src.diffusers.models.referencenet.unet_2d_condition import UNet2DConditionModel
from src.diffusers.pipelines.referencenet.pipeline_referencenet import (
    StableDiffusionReferenceNetPipeline,
)

def clear_cuda_memory():
    """æ¸…ç† CUDA å†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()

def setup_pipeline():
    """è®¾ç½®äººè„¸åŒ¿ååŒ–å¤„ç†ç®¡é“"""
    print("ğŸ”§ è®¾ç½®å¤„ç†ç®¡é“...")
    
    # æ¸…ç†å†…å­˜
    clear_cuda_memory()
    
    face_model_id = "hkung/face-anon-simple"
    clip_model_id = "openai/clip-vit-large-patch14"
    sd_model_id = "stabilityai/stable-diffusion-2-1"

    # åŠ è½½æ¨¡å‹
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    unet = UNet2DConditionModel.from_pretrained(
        face_model_id, subfolder="unet", use_safetensors=True
    )
    referencenet = ReferenceNetModel.from_pretrained(
        face_model_id, subfolder="referencenet", use_safetensors=True
    )
    conditioning_referencenet = ReferenceNetModel.from_pretrained(
        face_model_id, subfolder="conditioning_referencenet", use_safetensors=True
    )
    vae = AutoencoderKL.from_pretrained(sd_model_id, subfolder="vae", use_safetensors=True)
    scheduler = DDPMScheduler.from_pretrained(
        sd_model_id, subfolder="scheduler", use_safetensors=True
    )
    feature_extractor = CLIPImageProcessor.from_pretrained(
        clip_model_id, use_safetensors=True
    )
    image_encoder = CLIPVisionModel.from_pretrained(clip_model_id, use_safetensors=True)

    # åˆ›å»ºç®¡é“
    print("ğŸ”— åˆ›å»ºå¤„ç†ç®¡é“...")
    pipe = StableDiffusionReferenceNetPipeline(
        unet=unet,
        referencenet=referencenet,
        conditioning_referencenet=conditioning_referencenet,
        vae=vae,
        feature_extractor=feature_extractor,
        image_encoder=image_encoder,
        scheduler=scheduler,
    )
    
    # å¯ç”¨å†…å­˜é«˜æ•ˆæ³¨æ„åŠ›
    if hasattr(pipe, 'enable_xformers_memory_efficient_attention'):
        pipe.enable_xformers_memory_efficient_attention()
    
    pipe = pipe.to("cuda")
    
    return pipe

def anonymize_single_image(input_path, output_path, anonymization_degree=1.25):
    """å¤„ç†å•å¼ å›¾åƒ"""
    try:
        print(f"ğŸ“¸ å¤„ç†å›¾åƒ: {input_path}")
        
        # è®¾ç½®ç®¡é“
        pipe = setup_pipeline()
        
        # åŠ è½½å›¾åƒ
        original_image = load_image(input_path)
        print(f"ğŸ–¼ï¸ å›¾åƒå°ºå¯¸: {original_image.size}")
        
        # ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œä½¿ç”¨è¾ƒå°çš„å°ºå¯¸
        max_size = 512
        width, height = original_image.size
        if width > max_size or height > max_size:
            if width > height:
                new_width = max_size
                new_height = int(height * max_size / width)
            else:
                new_height = max_size
                new_width = int(width * max_size / height)
        else:
            new_width, new_height = width, height
        
        print(f"ğŸ”„ è°ƒæ•´åå°ºå¯¸: {new_width}x{new_height}")
        
        # ç”ŸæˆåŒ¿ååŒ–å›¾åƒ
        generator = torch.manual_seed(42)
        
        # å‡å°‘æ¨ç†æ­¥æ•°ä»¥èŠ‚çœå†…å­˜
        anon_image = pipe(
            source_image=original_image,
            conditioning_image=original_image,
            num_inference_steps=50,  # å‡å°‘æ­¥æ•°
            guidance_scale=4.0,
            generator=generator,
            anonymization_degree=anonymization_degree,
            width=new_width,
            height=new_height,
        ).images[0]
        
        # ä¿å­˜ç»“æœ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        anon_image.save(output_path)
        
        print(f"âœ… å¤„ç†å®Œæˆ: {output_path}")
        
        # æ¸…ç†å†…å­˜
        del pipe, anon_image, original_image
        clear_cuda_memory()
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        clear_cuda_memory()
        return False

def main():
    # å¤„ç†ç¬¬ä¸€å¼ å›¾ç‰‡
    input_path = "/home/zhiqics/sanjian/dataset/test_images/images/frame_00032.jpg"
    output_path = "/home/zhiqics/sanjian/dataset/test_images/anon/frame_00032_anon.jpg"
    
    print("ğŸ­ Face Anonymization Made Simple - å•å›¾å¤„ç†")
    print("=" * 50)
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("=" * 50)
    
    if not os.path.exists(input_path):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return
    
    success = anonymize_single_image(input_path, output_path)
    
    if success:
        print("ğŸ‰ å¤„ç†æˆåŠŸå®Œæˆ!")
    else:
        print("âŒ å¤„ç†å¤±è´¥!")

if __name__ == "__main__":
    main()
