#!/usr/bin/env python3
"""
face_anon_simpleäººè„¸åŒ¿ååŒ–æ¼”ç¤º
"""

import torch
import os
from transformers import CLIPImageProcessor, CLIPVisionModel
from diffusers import AutoencoderKL, DDPMScheduler
from diffusers.utils import load_image
from src.diffusers.models.referencenet.referencenet_unet_2d_condition import (
    ReferenceNetModel,
)
from src.diffusers.models.referencenet.unet_2d_condition import UNet2DConditionModel
from src.diffusers.pipelines.referencenet.pipeline_referencenet import (
    StableDiffusionReferenceNetPipeline,
)

def setup_pipeline():
    """è®¾ç½®äººè„¸åŒ¿ååŒ–å¤„ç†ç®¡é“"""
    print("ğŸ”§ è®¾ç½®å¤„ç†ç®¡é“...")
    
    face_model_id = "hkung/face-anon-simple"
    clip_model_id = "openai/clip-vit-large-patch14"
    sd_model_id = "stabilityai/stable-diffusion-2-1"

    # åŠ è½½æ¨¡å‹
    unet = UNet2DConditionModel.from_pretrained(
        face_model_id, subfolder="unet", use_safetensors=True
    )
    referencenet = ReferenceNetModel.from_pretrained(
        face_model_id, subfolder="referencenet", use_safetensors=True
    )
    conditioning_referencenet = ReferenceNetModel.from_pretrained(
        face_model_id, subfolder="conditioning_referencenet", use_safetensors=True
    )
    vae = AutoencoderKL.from_pretrained(sd_model_id, subfolder="vae", use_safetensors=True)
    scheduler = DDPMScheduler.from_pretrained(
        sd_model_id, subfolder="scheduler", use_safetensors=True
    )
    feature_extractor = CLIPImageProcessor.from_pretrained(
        clip_model_id, use_safetensors=True
    )
    image_encoder = CLIPVisionModel.from_pretrained(clip_model_id, use_safetensors=True)

    # åˆ›å»ºç®¡é“
    pipe = StableDiffusionReferenceNetPipeline(
        unet=unet,
        referencenet=referencenet,
        conditioning_referencenet=conditioning_referencenet,
        vae=vae,
        feature_extractor=feature_extractor,
        image_encoder=image_encoder,
        scheduler=scheduler,
    )
    pipe = pipe.to("cuda")
    
    return pipe

def anonymize_single_face(pipe, image_path, output_path, anonymization_degree=1.25):
    """å¯¹å•ä¸ªå¯¹é½çš„äººè„¸è¿›è¡ŒåŒ¿ååŒ–å¤„ç†"""
    print(f"ğŸ­ å¤„ç†å›¾åƒ: {image_path}")
    
    # åŠ è½½å›¾åƒ
    original_image = load_image(image_path)
    original_width, original_height = original_image.size
    print(f"  - åŸå§‹å›¾åƒå°ºå¯¸: {original_image.size}")
    
    # ç”ŸæˆåŒ¿ååŒ–å›¾åƒ
    generator = torch.manual_seed(1)
    anon_image = pipe(
        source_image=original_image,
        conditioning_image=original_image,
        num_inference_steps=200,
        guidance_scale=4.0,
        generator=generator,
        anonymization_degree=anonymization_degree,
        width=original_width,
        height=original_height,
    ).images[0]
    
    # ä¿å­˜ç»“æœ
    anon_image.save(output_path)
    print(f"  - åŒ¿ååŒ–å›¾åƒå·²ä¿å­˜è‡³: {output_path}")
    
    return original_image, anon_image

def face_swap(pipe, source_path, target_path, output_path):
    """åœ¨ä¸¤å¼ å›¾åƒä¹‹é—´è¿›è¡Œäººè„¸äº¤æ¢"""
    print(f"ğŸ”„ äººè„¸äº¤æ¢: {source_path} -> {target_path}")
    
    # åŠ è½½å›¾åƒ
    source_image = load_image(source_path)
    target_image = load_image(target_path)
    target_width, target_height = target_image.size
    
    # ç”Ÿæˆäº¤æ¢ç»“æœ
    generator = torch.manual_seed(1)
    swap_image = pipe(
        source_image=source_image,
        conditioning_image=target_image,
        num_inference_steps=200,
        guidance_scale=4.0,
        generator=generator,
        anonymization_degree=0.0,
        width=target_width,
        height=target_height,
    ).images[0]
    
    # ä¿å­˜ç»“æœ
    swap_image.save(output_path)
    print(f"  - äº¤æ¢ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    
    return source_image, target_image, swap_image

def main():
    print("ğŸ­ Face Anonymization Made Simple - æ¼”ç¤ºç¨‹åº")
    print("=" * 50)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "results"
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # è®¾ç½®ç®¡é“
        pipe = setup_pipeline()
        
        # æµ‹è¯•1: å•äººè„¸åŒ¿ååŒ–
        print("\nğŸ“ æµ‹è¯•1: å•äººè„¸åŒ¿ååŒ–")
        original, anon = anonymize_single_face(
            pipe, 
            "my_dataset/test/14795.png", 
            f"{output_dir}/anon_14795.png"
        )
        
        # æµ‹è¯•2: äººè„¸äº¤æ¢
        print("\nğŸ“ æµ‹è¯•2: äººè„¸äº¤æ¢")
        source, target, swapped = face_swap(
            pipe,
            "my_dataset/test/00482.png",
            "my_dataset/test/14795.png", 
            f"{output_dir}/swap_result.png"
        )
        
        print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åœ¨ '{output_dir}' ç›®å½•ä¸­")
        print("ğŸ‰ face_anon_simpleé¡¹ç›®è¿è¡ŒæˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        raise

if __name__ == "__main__":
    main()
